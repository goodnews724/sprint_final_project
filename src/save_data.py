"""
ë°ì´í„° ì €ì¥ í•¨ìˆ˜
ë‹´ë‹¹: ê¹€í˜¸ì¬
"""

import pandas as pd
import os
import logging
from google.cloud import storage

logger = logging.getLogger(__name__)

def save_to_gcs(df: pd.DataFrame, table_name: str, dataset: str = 'processed') -> dict:
    """ì „ì²˜ë¦¬ëœ ë°ì´í„°ë¥¼ GCSì— parquetìœ¼ë¡œ ì €ì¥ (ê°œì„  ë²„ì „)"""
    
    if df.empty:
        raise ValueError(f"ë¹ˆ DataFrameì„ ì €ì¥í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {table_name}")

    # ì „ì²˜ë¦¬ëœ ë°ì´í„°ì„ì„ ëª…í™•íˆ í‘œì‹œ
    processed_table_name = f"{table_name}_processed"
    bucket_name = 'sprintda05_final_project'
    blob_path = f"{dataset}/{processed_table_name}.parquet"
    gcs_path = f"gs://{bucket_name}/{blob_path}"
    
    try:
        logger.info(f"ğŸ’¾ {processed_table_name} ì €ì¥ ì‹œì‘...")
        logger.info(f"   ì €ì¥í•  ë°ì´í„°: {len(df):,}í–‰, {df.shape[1]}ì—´")
        
        # ë¡œì»¬ì— ì„ì‹œ ì €ì¥ - ì••ì¶• ì˜µì…˜ ì¶”ê°€
        local_path = f"/tmp/{processed_table_name}_{os.getpid()}.parquet"
        df.to_parquet(
            local_path, 
            engine='pyarrow', 
            index=False,
            compression='snappy'  # ì••ì¶•ìœ¼ë¡œ íŒŒì¼ í¬ê¸° ìµœì í™”
        )
        
        # íŒŒì¼ í¬ê¸° í™•ì¸
        file_size_mb = os.path.getsize(local_path) / 1024**2
        logger.info(f"   íŒŒì¼ í¬ê¸°: {file_size_mb:.1f}MB")
        
        # GCSì— ì—…ë¡œë“œ
        client = storage.Client()
        bucket = client.bucket(bucket_name)
        blob = bucket.blob(blob_path)
        
        blob.upload_from_filename(local_path, timeout=300)  # 5ë¶„ íƒ€ì„ì•„ì›ƒ
        
        # ì—…ë¡œë“œ ê²€ì¦
        blob.reload()
        if not blob.exists():
            raise RuntimeError("GCS ì—…ë¡œë“œ ê²€ì¦ ì‹¤íŒ¨")
        
        result = {
            'table_name': processed_table_name,
            'rows': len(df),
            'columns': df.shape[1],
            'file_size_mb': round(file_size_mb, 1),
            'gcs_path': gcs_path
        }
        
        logger.info(f"âœ… {processed_table_name} ì €ì¥ ì™„ë£Œ")
        logger.info(f"   ì €ì¥ ê²½ë¡œ: {gcs_path}")
        
        return result

    except MemoryError:
        raise MemoryError(f"ë©”ëª¨ë¦¬ ë¶€ì¡±ìœ¼ë¡œ {table_name} ì €ì¥ ì‹¤íŒ¨")
    except Exception as e:
        logger.error(f"âŒ {processed_table_name} ì €ì¥ ì‹¤íŒ¨: {str(e)}")
        raise
    finally:
        # ì•ˆì „í•œ ì„ì‹œ íŒŒì¼ ì •ë¦¬
        if 'local_path' in locals() and os.path.exists(local_path):
            try:
                os.remove(local_path)
                logger.debug(f"ì„ì‹œ íŒŒì¼ ì •ë¦¬: {local_path}")
            except OSError as e:
                logger.warning(f"ì„ì‹œ íŒŒì¼ ì •ë¦¬ ì‹¤íŒ¨: {e}")

# ì‚¬ìš© ì˜ˆì‹œ
if __name__ == "__main__":
    # ì˜ˆì‹œ ë°ì´í„°í”„ë ˆì„ ì €ì¥
    df = pd.DataFrame({'test': [1, 2, 3]})
    try:
        result = save_to_gcs(df, 'test_table', 'processed')
        print(f"ì €ì¥ ì™„ë£Œ: {result}")
    except Exception as e:
        print(f"í…ŒìŠ¤íŠ¸ ì‹¤íŒ¨: {e}")