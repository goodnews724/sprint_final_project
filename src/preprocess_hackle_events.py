"""
hackle_events ì „ì²˜ë¦¬
ë‹´ë‹¹: ì¡°ìˆ˜ì§„
"""

import pandas as pd
import logging
import gc

logger = logging.getLogger(__name__)

def preprocess_hackle_events(df: pd.DataFrame) -> pd.DataFrame:
    """hackle_events ì „ì²˜ë¦¬: ì¤‘ë³µ ì´ë²¤íŠ¸ ì œê±° + ë¶ˆí•„ìš” ì´ë²¤íŠ¸ ì‚­ì œ (ê°œì„  ë²„ì „)"""

    logger.info("ğŸ”§ ì¡°ìˆ˜ì§„: hackle_events ì „ì²˜ë¦¬ ì‹œì‘...")
    
    try:
        original_count = len(df)
        
        # ë°ì´í„° ê²€ì¦
        required_columns = ['session_id', 'event_datetime', 'event_key']
        missing_columns = [col for col in required_columns if col not in df.columns]
        if missing_columns:
            raise ValueError(f"í•„ìˆ˜ ì»¬ëŸ¼ ëˆ„ë½: {missing_columns}")

        # 1. ë¶ˆí•„ìš”í•œ ì´ë²¤íŠ¸ ì‚­ì œ
        exclude_events = ['button', 'click_appbar_setting']
        before_filter_count = len(df)
        
        # ì‚­ì œí•  ì´ë²¤íŠ¸ê°€ ëª‡ ê°œë‚˜ ìˆëŠ”ì§€ í™•ì¸
        excluded_counts = {}
        for event in exclude_events:
            count = (df['event_key'] == event).sum()
            excluded_counts[event] = count
            logger.info(f"   ì‚­ì œ ëŒ€ìƒ '{event}': {count:,}ê±´")
        
        # í•„í„°ë§ ì‹¤í–‰
        df_filtered = df[~df['event_key'].isin(exclude_events)].copy()
        after_filter_count = len(df_filtered)
        
        filtered_out = before_filter_count - after_filter_count
        logger.info(f"   ì´ë²¤íŠ¸ í•„í„°ë§: {filtered_out:,}ê±´ ì‚­ì œ ({filtered_out/before_filter_count*100:.2f}%)")

        # 2. ì¤‘ë³µ ì œê±° ì „ ë¶„ì„
        logger.info(f"   ì¤‘ë³µ ê²€ì‚¬ ê¸°ì¤€: {required_columns}")
        duplicate_check = df_filtered.duplicated(subset=required_columns)
        duplicate_count = duplicate_check.sum()
        logger.info(f"   ë°œê²¬ëœ ì¤‘ë³µ: {duplicate_count:,}ê±´")

        # 3. ì¤‘ë³µ ì œê±° (session_id, event_datetime, event_key ê¸°ì¤€)
        before_count = len(df_filtered)
        df_clean = df_filtered.drop_duplicates(subset=required_columns, keep='first')
        after_count = len(df_clean)

        removed = before_count - after_count
        removal_rate = removed / before_count * 100 if before_count > 0 else 0
        
        logger.info(f"âœ… ì¡°ìˆ˜ì§„: ì „ì²˜ë¦¬ ì™„ë£Œ")
        logger.info(f"   ì›ë³¸ ë°ì´í„°: {original_count:,}ê±´")
        logger.info(f"   ì´ë²¤íŠ¸ í•„í„°ë§ í›„: {after_filter_count:,}ê±´")
        logger.info(f"   ì¤‘ë³µ ì œê±° í›„: {after_count:,}ê±´")
        logger.info(f"   ì´ ì œê±°ìœ¨: {(original_count-after_count)/original_count*100:.2f}%")
        
        # ê²°ê³¼ ê²€ì¦
        if len(df_clean) == 0:
            raise ValueError("ì „ì²˜ë¦¬ í›„ ë°ì´í„°ê°€ ë¹„ì–´ìˆìŠµë‹ˆë‹¤")
        
        # ìµœì¢… ì´ë²¤íŠ¸ ì¢…ë¥˜ í™•ì¸
        final_events = df_clean['event_key'].value_counts()
        logger.info(f"   ìµœì¢… ì´ë²¤íŠ¸ ì¢…ë¥˜: {len(final_events)}ê°œ")
        logger.info(f"   ìƒìœ„ 5ê°œ ì´ë²¤íŠ¸: {final_events.head().to_dict()}")
        
        # ë©”ëª¨ë¦¬ ì •ë¦¬
        del df, df_filtered
        gc.collect()

        return df_clean
        
    except Exception as e:
        logger.error(f"âŒ ì¡°ìˆ˜ì§„: hackle_events ì „ì²˜ë¦¬ ì‹¤íŒ¨ - {str(e)}")
        gc.collect()
        raise

# ì‚¬ìš© ì˜ˆì‹œ
if __name__ == "__main__":
    from load_data import load_table
    
    try:
        df = load_table('hackle_events', 'hackle')
        df_processed = preprocess_hackle_events(df)
        print(f"ì „ì²˜ë¦¬ ì™„ë£Œ: {len(df_processed):,}í–‰")
        
        # ì´ë²¤íŠ¸ ì¢…ë¥˜ í™•ì¸
        print("\nì´ë²¤íŠ¸ ì¢…ë¥˜ë³„ ê°œìˆ˜:")
        print(df_processed['event_key'].value_counts().head(10))
        
    except Exception as e:
        print(f"í…ŒìŠ¤íŠ¸ ì‹¤íŒ¨: {e}")