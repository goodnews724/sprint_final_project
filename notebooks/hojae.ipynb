{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a81b2b6a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pandas in /opt/conda/lib/python3.11/site-packages (2.1.4)\n",
      "Collecting google-cloud-storage\n",
      "  Downloading google_cloud_storage-3.1.0-py2.py3-none-any.whl.metadata (12 kB)\n",
      "Collecting pyarrow\n",
      "  Downloading pyarrow-20.0.0-cp311-cp311-manylinux_2_28_aarch64.whl.metadata (3.3 kB)\n",
      "Collecting fsspec\n",
      "  Downloading fsspec-2025.5.1-py3-none-any.whl.metadata (11 kB)\n",
      "Collecting gcsfs\n",
      "  Downloading gcsfs-2025.5.1-py2.py3-none-any.whl.metadata (1.9 kB)\n",
      "Requirement already satisfied: numpy<2,>=1.23.2 in /opt/conda/lib/python3.11/site-packages (from pandas) (1.26.2)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /opt/conda/lib/python3.11/site-packages (from pandas) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in /opt/conda/lib/python3.11/site-packages (from pandas) (2023.3.post1)\n",
      "Requirement already satisfied: tzdata>=2022.1 in /opt/conda/lib/python3.11/site-packages (from pandas) (2025.2)\n",
      "Collecting google-auth<3.0dev,>=2.26.1 (from google-cloud-storage)\n",
      "  Downloading google_auth-2.40.2-py2.py3-none-any.whl.metadata (6.2 kB)\n",
      "Collecting google-api-core<3.0.0dev,>=2.15.0 (from google-cloud-storage)\n",
      "  Downloading google_api_core-2.24.2-py3-none-any.whl.metadata (3.0 kB)\n",
      "Collecting google-cloud-core<3.0dev,>=2.4.2 (from google-cloud-storage)\n",
      "  Downloading google_cloud_core-2.4.3-py2.py3-none-any.whl.metadata (2.7 kB)\n",
      "Collecting google-resumable-media>=2.7.2 (from google-cloud-storage)\n",
      "  Downloading google_resumable_media-2.7.2-py2.py3-none-any.whl.metadata (2.2 kB)\n",
      "Requirement already satisfied: requests<3.0.0dev,>=2.18.0 in /opt/conda/lib/python3.11/site-packages (from google-cloud-storage) (2.31.0)\n",
      "Collecting google-crc32c<2.0dev,>=1.0 (from google-cloud-storage)\n",
      "  Downloading google_crc32c-1.7.1-cp311-cp311-manylinux_2_17_aarch64.manylinux2014_aarch64.whl.metadata (2.3 kB)\n",
      "Collecting aiohttp!=4.0.0a0,!=4.0.0a1 (from gcsfs)\n",
      "  Downloading aiohttp-3.12.2-cp311-cp311-manylinux_2_17_aarch64.manylinux2014_aarch64.whl.metadata (7.6 kB)\n",
      "Requirement already satisfied: decorator>4.1.2 in /opt/conda/lib/python3.11/site-packages (from gcsfs) (5.1.1)\n",
      "Collecting google-auth-oauthlib (from gcsfs)\n",
      "  Downloading google_auth_oauthlib-1.2.2-py3-none-any.whl.metadata (2.7 kB)\n",
      "Collecting aiohappyeyeballs>=2.5.0 (from aiohttp!=4.0.0a0,!=4.0.0a1->gcsfs)\n",
      "  Downloading aiohappyeyeballs-2.6.1-py3-none-any.whl.metadata (5.9 kB)\n",
      "Collecting aiosignal>=1.1.2 (from aiohttp!=4.0.0a0,!=4.0.0a1->gcsfs)\n",
      "  Downloading aiosignal-1.3.2-py2.py3-none-any.whl.metadata (3.8 kB)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /opt/conda/lib/python3.11/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->gcsfs) (23.1.0)\n",
      "Collecting frozenlist>=1.1.1 (from aiohttp!=4.0.0a0,!=4.0.0a1->gcsfs)\n",
      "  Downloading frozenlist-1.6.0-cp311-cp311-manylinux_2_17_aarch64.manylinux2014_aarch64.whl.metadata (16 kB)\n",
      "Collecting multidict<7.0,>=4.5 (from aiohttp!=4.0.0a0,!=4.0.0a1->gcsfs)\n",
      "  Downloading multidict-6.4.4-cp311-cp311-manylinux_2_17_aarch64.manylinux2014_aarch64.whl.metadata (5.3 kB)\n",
      "Collecting propcache>=0.2.0 (from aiohttp!=4.0.0a0,!=4.0.0a1->gcsfs)\n",
      "  Downloading propcache-0.3.1-cp311-cp311-manylinux_2_17_aarch64.manylinux2014_aarch64.whl.metadata (10 kB)\n",
      "Collecting yarl<2.0,>=1.17.0 (from aiohttp!=4.0.0a0,!=4.0.0a1->gcsfs)\n",
      "  Downloading yarl-1.20.0-cp311-cp311-manylinux_2_17_aarch64.manylinux2014_aarch64.whl.metadata (72 kB)\n",
      "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m72.4/72.4 kB\u001b[0m \u001b[31m2.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting googleapis-common-protos<2.0.0,>=1.56.2 (from google-api-core<3.0.0dev,>=2.15.0->google-cloud-storage)\n",
      "  Downloading googleapis_common_protos-1.70.0-py3-none-any.whl.metadata (9.3 kB)\n",
      "Collecting protobuf!=3.20.0,!=3.20.1,!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<7.0.0,>=3.19.5 (from google-api-core<3.0.0dev,>=2.15.0->google-cloud-storage)\n",
      "  Downloading protobuf-6.31.0-cp39-abi3-manylinux2014_aarch64.whl.metadata (593 bytes)\n",
      "Collecting proto-plus<2.0.0,>=1.22.3 (from google-api-core<3.0.0dev,>=2.15.0->google-cloud-storage)\n",
      "  Downloading proto_plus-1.26.1-py3-none-any.whl.metadata (2.2 kB)\n",
      "Collecting cachetools<6.0,>=2.0.0 (from google-auth<3.0dev,>=2.26.1->google-cloud-storage)\n",
      "  Downloading cachetools-5.5.2-py3-none-any.whl.metadata (5.4 kB)\n",
      "Collecting pyasn1-modules>=0.2.1 (from google-auth<3.0dev,>=2.26.1->google-cloud-storage)\n",
      "  Downloading pyasn1_modules-0.4.2-py3-none-any.whl.metadata (3.5 kB)\n",
      "Collecting rsa<5,>=3.1.4 (from google-auth<3.0dev,>=2.26.1->google-cloud-storage)\n",
      "  Downloading rsa-4.9.1-py3-none-any.whl.metadata (5.6 kB)\n",
      "Requirement already satisfied: six>=1.5 in /opt/conda/lib/python3.11/site-packages (from python-dateutil>=2.8.2->pandas) (1.16.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.11/site-packages (from requests<3.0.0dev,>=2.18.0->google-cloud-storage) (3.3.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.11/site-packages (from requests<3.0.0dev,>=2.18.0->google-cloud-storage) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.11/site-packages (from requests<3.0.0dev,>=2.18.0->google-cloud-storage) (2.0.7)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.11/site-packages (from requests<3.0.0dev,>=2.18.0->google-cloud-storage) (2023.7.22)\n",
      "Collecting requests-oauthlib>=0.7.0 (from google-auth-oauthlib->gcsfs)\n",
      "  Downloading requests_oauthlib-2.0.0-py2.py3-none-any.whl.metadata (11 kB)\n",
      "Collecting pyasn1<0.7.0,>=0.6.1 (from pyasn1-modules>=0.2.1->google-auth<3.0dev,>=2.26.1->google-cloud-storage)\n",
      "  Downloading pyasn1-0.6.1-py3-none-any.whl.metadata (8.4 kB)\n",
      "Requirement already satisfied: oauthlib>=3.0.0 in /opt/conda/lib/python3.11/site-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib->gcsfs) (3.2.2)\n",
      "Downloading google_cloud_storage-3.1.0-py2.py3-none-any.whl (174 kB)\n",
      "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m174.9/174.9 kB\u001b[0m \u001b[31m4.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading pyarrow-20.0.0-cp311-cp311-manylinux_2_28_aarch64.whl (40.7 MB)\n",
      "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m40.7/40.7 MB\u001b[0m \u001b[31m4.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading fsspec-2025.5.1-py3-none-any.whl (199 kB)\n",
      "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m199.1/199.1 kB\u001b[0m \u001b[31m4.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading gcsfs-2025.5.1-py2.py3-none-any.whl (36 kB)\n",
      "Downloading aiohttp-3.12.2-cp311-cp311-manylinux_2_17_aarch64.manylinux2014_aarch64.whl (1.7 MB)\n",
      "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m1.7/1.7 MB\u001b[0m \u001b[31m5.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading google_api_core-2.24.2-py3-none-any.whl (160 kB)\n",
      "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m160.1/160.1 kB\u001b[0m \u001b[31m6.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading google_auth-2.40.2-py2.py3-none-any.whl (216 kB)\n",
      "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m216.1/216.1 kB\u001b[0m \u001b[31m6.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading google_cloud_core-2.4.3-py2.py3-none-any.whl (29 kB)\n",
      "Downloading google_crc32c-1.7.1-cp311-cp311-manylinux_2_17_aarch64.manylinux2014_aarch64.whl (33 kB)\n",
      "Downloading google_resumable_media-2.7.2-py2.py3-none-any.whl (81 kB)\n",
      "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m81.3/81.3 kB\u001b[0m \u001b[31m5.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading google_auth_oauthlib-1.2.2-py3-none-any.whl (19 kB)\n",
      "Downloading aiohappyeyeballs-2.6.1-py3-none-any.whl (15 kB)\n",
      "Downloading aiosignal-1.3.2-py2.py3-none-any.whl (7.6 kB)\n",
      "Downloading cachetools-5.5.2-py3-none-any.whl (10 kB)\n",
      "Downloading frozenlist-1.6.0-cp311-cp311-manylinux_2_17_aarch64.manylinux2014_aarch64.whl (314 kB)\n",
      "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m314.8/314.8 kB\u001b[0m \u001b[31m3.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading googleapis_common_protos-1.70.0-py3-none-any.whl (294 kB)\n",
      "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m294.5/294.5 kB\u001b[0m \u001b[31m3.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading multidict-6.4.4-cp311-cp311-manylinux_2_17_aarch64.manylinux2014_aarch64.whl (226 kB)\n",
      "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m226.7/226.7 kB\u001b[0m \u001b[31m3.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading propcache-0.3.1-cp311-cp311-manylinux_2_17_aarch64.manylinux2014_aarch64.whl (233 kB)\n",
      "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m233.6/233.6 kB\u001b[0m \u001b[31m4.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading proto_plus-1.26.1-py3-none-any.whl (50 kB)\n",
      "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m50.2/50.2 kB\u001b[0m \u001b[31m4.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading protobuf-6.31.0-cp39-abi3-manylinux2014_aarch64.whl (321 kB)\n",
      "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m321.9/321.9 kB\u001b[0m \u001b[31m4.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading pyasn1_modules-0.4.2-py3-none-any.whl (181 kB)\n",
      "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m181.3/181.3 kB\u001b[0m \u001b[31m4.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading requests_oauthlib-2.0.0-py2.py3-none-any.whl (24 kB)\n",
      "Downloading rsa-4.9.1-py3-none-any.whl (34 kB)\n",
      "Downloading yarl-1.20.0-cp311-cp311-manylinux_2_17_aarch64.manylinux2014_aarch64.whl (355 kB)\n",
      "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m355.8/355.8 kB\u001b[0m \u001b[31m5.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading pyasn1-0.6.1-py3-none-any.whl (83 kB)\n",
      "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m83.1/83.1 kB\u001b[0m \u001b[31m3.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: pyasn1, pyarrow, protobuf, propcache, multidict, google-crc32c, fsspec, frozenlist, cachetools, aiohappyeyeballs, yarl, rsa, requests-oauthlib, pyasn1-modules, proto-plus, googleapis-common-protos, google-resumable-media, aiosignal, google-auth, aiohttp, google-auth-oauthlib, google-api-core, google-cloud-core, google-cloud-storage, gcsfs\n",
      "Successfully installed aiohappyeyeballs-2.6.1 aiohttp-3.12.2 aiosignal-1.3.2 cachetools-5.5.2 frozenlist-1.6.0 fsspec-2025.5.1 gcsfs-2025.5.1 google-api-core-2.24.2 google-auth-2.40.2 google-auth-oauthlib-1.2.2 google-cloud-core-2.4.3 google-cloud-storage-3.1.0 google-crc32c-1.7.1 google-resumable-media-2.7.2 googleapis-common-protos-1.70.0 multidict-6.4.4 propcache-0.3.1 proto-plus-1.26.1 protobuf-6.31.0 pyarrow-20.0.0 pyasn1-0.6.1 pyasn1-modules-0.4.2 requests-oauthlib-2.0.0 rsa-4.9.1 yarl-1.20.0\n"
     ]
    }
   ],
   "source": [
    "!pip install pandas google-cloud-storage pyarrow fsspec gcsfs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3ed0400c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "í‚¤ íŒŒì¼ ê²½ë¡œ: /home/jovyan/work/secrets/google_cloud_storage_hojae.json\n",
      "âœ… ì—°ê²° ì„±ê³µ! í”„ë¡œì íŠ¸: sprintda05-hojae2\n",
      "ë²„í‚· ê°œìˆ˜: 1\n",
      "  - sprintda05_final_project\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "# ë¹ ë¥¸ ì—°ê²° í…ŒìŠ¤íŠ¸ìš©\n",
    "import os\n",
    "from google.cloud import storage\n",
    "\n",
    "# .env íŒŒì¼ì´ docker-compose.yamlì˜ env_fileë¡œ ë¡œë“œë˜ë¯€ë¡œ\n",
    "# í™˜ê²½ ë³€ìˆ˜ê°€ ì´ë¯¸ ì„¤ì •ë˜ì–´ ìˆìŒ!\n",
    "\n",
    "try:\n",
    "    # í™˜ê²½ ë³€ìˆ˜ í™•ì¸\n",
    "    print(f\"í‚¤ íŒŒì¼ ê²½ë¡œ: {os.environ.get('GOOGLE_APPLICATION_CREDENTIALS')}\")\n",
    "    \n",
    "    # ë°”ë¡œ ì‚¬ìš© ê°€ëŠ¥\n",
    "    client = storage.Client()\n",
    "    print(f\"âœ… ì—°ê²° ì„±ê³µ! í”„ë¡œì íŠ¸: {client.project}\")\n",
    "    \n",
    "    buckets = list(client.list_buckets())\n",
    "    print(f\"ë²„í‚· ê°œìˆ˜: {len(buckets)}\")\n",
    "    \n",
    "    # ë²„í‚· ëª©ë¡\n",
    "    for bucket in buckets:\n",
    "        print(f\"  - {bucket.name}\")\n",
    "        \n",
    "except Exception as e:\n",
    "    print(f\"âŒ ì—°ê²° ì‹¤íŒ¨: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "ddf4dcd8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- 2. GCS Parquet íŒŒì¼ ë¡œë“œ ë° í˜•ì‹ í™•ì¸ ---\n",
      "ğŸ“‚ ë‹¤ìŒ Parquet íŒŒì¼ì„ ë¶ˆëŸ¬ì˜µë‹ˆë‹¤: gs://sprintda05_final_project/hackle/hackle_events.parquet\n",
      "\n",
      "âœ… Parquet íŒŒì¼ ë¡œë“œ ì„±ê³µ!\n",
      "\n",
      "--- ë°ì´í„°í”„ë ˆì„ ìƒìœ„ 5ê°œ í–‰ (hackle_events.head()) ---\n",
      "                               event_id      event_datetime  \\\n",
      "0  00000533-3f1c-4b3b-81f1-0c8f35754b4e 2023-07-18 19:40:17   \n",
      "1  00000716-27e9-4e72-a602-d0ce61784b06 2023-07-18 21:07:24   \n",
      "2  000007c8-68ce-40e6-9b1e-f0e34e8ff9cc 2023-08-06 20:18:03   \n",
      "3  00000981-5e2a-4111-993e-4f1891ad9a53 2023-08-05 01:46:10   \n",
      "4  00000a7a-ba72-4332-b4a9-7910670aaeb2 2023-07-24 15:03:37   \n",
      "\n",
      "                         event_key                            session_id  \\\n",
      "0                   $session_start          4OzYh3seq3VKytpSn5pvQkZNQii1   \n",
      "1              click_question_open          8QXy31PQxbW9qLzq0Y1dhR8Ypm52   \n",
      "2  click_bottom_navigation_profile  6bcea65d-9f40-46fc-888c-700fe707483f   \n",
      "3                        view_shop          XVYNT6zfhFWqIg9omwg2AHDjTLx2   \n",
      "4      click_bottom_navigation_lab          XFB2SPiGfjbVhvJ3Q3DBsaT3m2B3   \n",
      "\n",
      "                                     id item_name page_name  friend_count  \\\n",
      "0  00000533-3f1c-4b3b-81f1-0c8f35754b4e                               NaN   \n",
      "1  00000716-27e9-4e72-a602-d0ce61784b06                              64.0   \n",
      "2  000007c8-68ce-40e6-9b1e-f0e34e8ff9cc                              26.0   \n",
      "3  00000981-5e2a-4111-993e-4f1891ad9a53                              61.0   \n",
      "4  00000a7a-ba72-4332-b4a9-7910670aaeb2                             119.0   \n",
      "\n",
      "   votes_count  heart_balance  question_id  \n",
      "0          NaN            NaN          NaN  \n",
      "1        436.0         4830.0          NaN  \n",
      "2        174.0         4729.0          NaN  \n",
      "3         44.0          142.0          NaN  \n",
      "4        545.0         3287.0          NaN  \n",
      "\n",
      "--- ë°ì´í„°í”„ë ˆì„ ì •ë³´ (hackle_events.info()) ---\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 11441319 entries, 0 to 11441318\n",
      "Data columns (total 11 columns):\n",
      " #   Column          Dtype         \n",
      "---  ------          -----         \n",
      " 0   event_id        object        \n",
      " 1   event_datetime  datetime64[ms]\n",
      " 2   event_key       object        \n",
      " 3   session_id      object        \n",
      " 4   id              object        \n",
      " 5   item_name       object        \n",
      " 6   page_name       object        \n",
      " 7   friend_count    float64       \n",
      " 8   votes_count     float64       \n",
      " 9   heart_balance   float64       \n",
      " 10  question_id     float64       \n",
      "dtypes: datetime64[ms](1), float64(4), object(6)\n",
      "memory usage: 960.2+ MB\n",
      "\n",
      "--- ë°ì´í„°í”„ë ˆì„ ê¸°ìˆ  í†µê³„ (hackle_events.describe()) ---\n",
      "                                    event_id              event_datetime  \\\n",
      "count                               11441319                    11441319   \n",
      "unique                              11441319                         NaN   \n",
      "top     00000533-3f1c-4b3b-81f1-0c8f35754b4e                         NaN   \n",
      "freq                                       1                         NaN   \n",
      "mean                                     NaN  2023-07-29 01:58:17.236000   \n",
      "min                                      NaN         2023-07-18 00:00:00   \n",
      "25%                                      NaN         2023-07-22 21:31:17   \n",
      "50%                                      NaN         2023-07-28 17:08:58   \n",
      "75%                                      NaN         2023-08-04 17:59:10   \n",
      "max                                      NaN         2023-08-10 23:59:59   \n",
      "std                                      NaN                         NaN   \n",
      "\n",
      "           event_key                            session_id  \\\n",
      "count       11441319                              11441319   \n",
      "unique            44                                253616   \n",
      "top     view_lab_tap  A40CA2FA-CEB6-4E94-857D-7C229ECC2598   \n",
      "freq         1266665                                  8157   \n",
      "mean             NaN                                   NaN   \n",
      "min              NaN                                   NaN   \n",
      "25%              NaN                                   NaN   \n",
      "50%              NaN                                   NaN   \n",
      "75%              NaN                                   NaN   \n",
      "max              NaN                                   NaN   \n",
      "std              NaN                                   NaN   \n",
      "\n",
      "                                          id item_name page_name  \\\n",
      "count                               11441319  11441319  11441319   \n",
      "unique                              11441319         6        13   \n",
      "top     00000533-3f1c-4b3b-81f1-0c8f35754b4e                       \n",
      "freq                                       1  11428280  10652540   \n",
      "mean                                     NaN       NaN       NaN   \n",
      "min                                      NaN       NaN       NaN   \n",
      "25%                                      NaN       NaN       NaN   \n",
      "50%                                      NaN       NaN       NaN   \n",
      "75%                                      NaN       NaN       NaN   \n",
      "max                                      NaN       NaN       NaN   \n",
      "std                                      NaN       NaN       NaN   \n",
      "\n",
      "        friend_count   votes_count  heart_balance    question_id  \n",
      "count   1.068876e+07  1.068676e+07   1.071268e+07  449484.000000  \n",
      "unique           NaN           NaN            NaN            NaN  \n",
      "top              NaN           NaN            NaN            NaN  \n",
      "freq             NaN           NaN            NaN            NaN  \n",
      "mean    5.434357e+01  2.572742e+02   1.626929e+04    2766.385262  \n",
      "min     0.000000e+00  0.000000e+00   0.000000e+00      99.000000  \n",
      "25%     3.200000e+01  9.700000e+01   4.340000e+02    1393.000000  \n",
      "50%     4.900000e+01  2.100000e+02   1.249000e+03    2569.000000  \n",
      "75%     7.100000e+01  3.620000e+02   3.188000e+03    4459.000000  \n",
      "max     1.365000e+03  3.017000e+03   8.849998e+08    5133.000000  \n",
      "std     3.350798e+01  2.180682e+02   3.317340e+06    1599.967343  \n",
      "\n",
      "--- ë°ì´í„°í”„ë ˆì„ í–‰ê³¼ ì—´ ê°œìˆ˜ (hackle_events.shape): (11441319, 11) ---\n",
      "\n",
      "--- ë°ì´í„°í”„ë ˆì„ ì»¬ëŸ¼ ëª©ë¡ (hackle_events.columns) ---\n",
      "['event_id', 'event_datetime', 'event_key', 'session_id', 'id', 'item_name', 'page_name', 'friend_count', 'votes_count', 'heart_balance', 'question_id']\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "from google.cloud import storage\n",
    "\n",
    "# GCSì—ì„œ Parquet íŒŒì¼ ë¶ˆëŸ¬ì˜¤ê¸° ë° í˜•ì‹ í™•ì¸\n",
    "print(\"\\n--- 2. GCS Parquet íŒŒì¼ ë¡œë“œ ë° í˜•ì‹ í™•ì¸ ---\")\n",
    "gcs_parquet_path = \"gs://sprintda05_final_project/hackle/hackle_events.parquet\"\n",
    "\n",
    "print(f\"ğŸ“‚ ë‹¤ìŒ Parquet íŒŒì¼ì„ ë¶ˆëŸ¬ì˜µë‹ˆë‹¤: {gcs_parquet_path}\")\n",
    "\n",
    "# pandasë¥¼ ì‚¬ìš©í•˜ì—¬ Parquet íŒŒì¼ ë¶ˆëŸ¬ì˜¤ê¸°\n",
    "# 'engine'ì„ 'pyarrow'ë¡œ ëª…ì‹œí•˜ì—¬ í™•ì‹¤í•˜ê²Œ pyarrow ì‚¬ìš©\n",
    "# gcsfsê°€ ì„¤ì¹˜ë˜ì–´ ìˆë‹¤ë©´ pandasëŠ” gs:// ê²½ë¡œë¥¼ ìë™ìœ¼ë¡œ ì²˜ë¦¬\n",
    "hackle_events = pd.read_parquet(gcs_parquet_path, engine='pyarrow')\n",
    "\n",
    "print(\"\\nâœ… Parquet íŒŒì¼ ë¡œë“œ ì„±ê³µ!\")\n",
    "\n",
    "print(\"\\n--- ë°ì´í„°í”„ë ˆì„ ìƒìœ„ 5ê°œ í–‰ (hackle_events.head()) ---\")\n",
    "print(hackle_events.head())\n",
    "\n",
    "print(\"\\n--- ë°ì´í„°í”„ë ˆì„ ì •ë³´ (hackle_events.info()) ---\")\n",
    "# ê° ì»¬ëŸ¼ì˜ ì´ë¦„, Non-Null ê°œìˆ˜, ë°ì´í„° íƒ€ì…(Dtype) í™•ì¸\n",
    "hackle_events.info()\n",
    "\n",
    "print(\"\\n--- ë°ì´í„°í”„ë ˆì„ ê¸°ìˆ  í†µê³„ (hackle_events.describe()) ---\")\n",
    "# ìˆ«ìí˜• ì»¬ëŸ¼ì— ëŒ€í•œ í†µê³„ ì •ë³´ í™•ì¸\n",
    "print(hackle_events.describe(include='all')) # ëª¨ë“  ì»¬ëŸ¼ íƒ€ì… í¬í•¨\n",
    "\n",
    "print(f\"\\n--- ë°ì´í„°í”„ë ˆì„ í–‰ê³¼ ì—´ ê°œìˆ˜ (hackle_events.shape): {hackle_events.shape} ---\")\n",
    "\n",
    "print(\"\\n--- ë°ì´í„°í”„ë ˆì„ ì»¬ëŸ¼ ëª©ë¡ (hackle_events.columns) ---\")\n",
    "print(hackle_events.columns.tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "bf1f55da",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- 2. GCS Parquet íŒŒì¼ ë¡œë“œ ë° í˜•ì‹ í™•ì¸ ---\n",
      "ğŸ“‚ ë‹¤ìŒ Parquet íŒŒì¼ì„ ë¶ˆëŸ¬ì˜µë‹ˆë‹¤: gs://sprintda05_final_project/hackle/user_properties.parquet\n",
      "\n",
      "âœ… Parquet íŒŒì¼ ë¡œë“œ ì„±ê³µ!\n",
      "\n",
      "--- ë°ì´í„°í”„ë ˆì„ ìƒìœ„ 5ê°œ í–‰ (user_properties.head()) ---\n",
      "   user_id  class gender  grade  school_id\n",
      "0  1000000      1      M      1       1885\n",
      "1  1000009     10      F      2       3869\n",
      "2  1000012     10      F      1       5091\n",
      "3  1000013      8      F      2       1743\n",
      "4  1000015      2      F      3       5078\n",
      "\n",
      "--- ë°ì´í„°í”„ë ˆì„ ì •ë³´ (user_properties.info()) ---\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 230819 entries, 0 to 230818\n",
      "Data columns (total 5 columns):\n",
      " #   Column     Non-Null Count   Dtype \n",
      "---  ------     --------------   ----- \n",
      " 0   user_id    230819 non-null  object\n",
      " 1   class      230819 non-null  int64 \n",
      " 2   gender     230819 non-null  object\n",
      " 3   grade      230819 non-null  int64 \n",
      " 4   school_id  230819 non-null  int64 \n",
      "dtypes: int64(3), object(2)\n",
      "memory usage: 8.8+ MB\n",
      "\n",
      "--- ë°ì´í„°í”„ë ˆì„ ê¸°ìˆ  í†µê³„ (user_properties.describe()) ---\n",
      "        user_id          class  gender          grade      school_id\n",
      "count    230819  230819.000000  230819  230819.000000  230819.000000\n",
      "unique   230819            NaN       2            NaN            NaN\n",
      "top     1000000            NaN       F            NaN            NaN\n",
      "freq          1            NaN  132610            NaN            NaN\n",
      "mean        NaN       4.594999     NaN       2.002197    3083.383335\n",
      "std         NaN       3.151979     NaN       0.762048    1711.671162\n",
      "min         NaN       1.000000     NaN       1.000000       1.000000\n",
      "25%         NaN       2.000000     NaN       1.000000    1594.000000\n",
      "50%         NaN       4.000000     NaN       2.000000    3138.000000\n",
      "75%         NaN       6.000000     NaN       3.000000    4640.000000\n",
      "max         NaN      20.000000     NaN       3.000000    5964.000000\n",
      "\n",
      "--- ë°ì´í„°í”„ë ˆì„ í–‰ê³¼ ì—´ ê°œìˆ˜ (user_properties.shape): (230819, 5) ---\n",
      "\n",
      "--- ë°ì´í„°í”„ë ˆì„ ì»¬ëŸ¼ ëª©ë¡ (user_properties.columns) ---\n",
      "['user_id', 'class', 'gender', 'grade', 'school_id']\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "from google.cloud import storage\n",
    "\n",
    "# GCSì—ì„œ Parquet íŒŒì¼ ë¶ˆëŸ¬ì˜¤ê¸° ë° í˜•ì‹ í™•ì¸\n",
    "print(\"\\n--- 2. GCS Parquet íŒŒì¼ ë¡œë“œ ë° í˜•ì‹ í™•ì¸ ---\")\n",
    "gcs_parquet_path = \"gs://sprintda05_final_project/hackle/user_properties.parquet\"\n",
    "\n",
    "print(f\"ğŸ“‚ ë‹¤ìŒ Parquet íŒŒì¼ì„ ë¶ˆëŸ¬ì˜µë‹ˆë‹¤: {gcs_parquet_path}\")\n",
    "\n",
    "# pandasë¥¼ ì‚¬ìš©í•˜ì—¬ Parquet íŒŒì¼ ë¶ˆëŸ¬ì˜¤ê¸°\n",
    "# 'engine'ì„ 'pyarrow'ë¡œ ëª…ì‹œí•˜ì—¬ í™•ì‹¤í•˜ê²Œ pyarrow ì‚¬ìš©\n",
    "# gcsfsê°€ ì„¤ì¹˜ë˜ì–´ ìˆë‹¤ë©´ pandasëŠ” gs:// ê²½ë¡œë¥¼ ìë™ìœ¼ë¡œ ì²˜ë¦¬\n",
    "user_properties = pd.read_parquet(gcs_parquet_path, engine='pyarrow')\n",
    "\n",
    "print(\"\\nâœ… Parquet íŒŒì¼ ë¡œë“œ ì„±ê³µ!\")\n",
    "\n",
    "print(\"\\n--- ë°ì´í„°í”„ë ˆì„ ìƒìœ„ 5ê°œ í–‰ (user_properties.head()) ---\")\n",
    "print(user_properties.head())\n",
    "\n",
    "print(\"\\n--- ë°ì´í„°í”„ë ˆì„ ì •ë³´ (user_properties.info()) ---\")\n",
    "# ê° ì»¬ëŸ¼ì˜ ì´ë¦„, Non-Null ê°œìˆ˜, ë°ì´í„° íƒ€ì…(Dtype) í™•ì¸\n",
    "user_properties.info()\n",
    "\n",
    "print(\"\\n--- ë°ì´í„°í”„ë ˆì„ ê¸°ìˆ  í†µê³„ (user_properties.describe()) ---\")\n",
    "# ìˆ«ìí˜• ì»¬ëŸ¼ì— ëŒ€í•œ í†µê³„ ì •ë³´ í™•ì¸\n",
    "print(user_properties.describe(include='all')) # ëª¨ë“  ì»¬ëŸ¼ íƒ€ì… í¬í•¨\n",
    "\n",
    "print(f\"\\n--- ë°ì´í„°í”„ë ˆì„ í–‰ê³¼ ì—´ ê°œìˆ˜ (user_properties.shape): {user_properties.shape} ---\")\n",
    "\n",
    "print(\"\\n--- ë°ì´í„°í”„ë ˆì„ ì»¬ëŸ¼ ëª©ë¡ (user_properties.columns) ---\")\n",
    "print(user_properties.columns.tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efadb76e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>class</th>\n",
       "      <th>gender</th>\n",
       "      <th>grade</th>\n",
       "      <th>school_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1000000</td>\n",
       "      <td>1</td>\n",
       "      <td>M</td>\n",
       "      <td>1</td>\n",
       "      <td>1885</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1000009</td>\n",
       "      <td>10</td>\n",
       "      <td>F</td>\n",
       "      <td>2</td>\n",
       "      <td>3869</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1000012</td>\n",
       "      <td>10</td>\n",
       "      <td>F</td>\n",
       "      <td>1</td>\n",
       "      <td>5091</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1000013</td>\n",
       "      <td>8</td>\n",
       "      <td>F</td>\n",
       "      <td>2</td>\n",
       "      <td>1743</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1000015</td>\n",
       "      <td>2</td>\n",
       "      <td>F</td>\n",
       "      <td>3</td>\n",
       "      <td>5078</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>230814</th>\n",
       "      <td>999992</td>\n",
       "      <td>1</td>\n",
       "      <td>M</td>\n",
       "      <td>2</td>\n",
       "      <td>2240</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>230815</th>\n",
       "      <td>999996</td>\n",
       "      <td>5</td>\n",
       "      <td>M</td>\n",
       "      <td>2</td>\n",
       "      <td>365</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>230816</th>\n",
       "      <td>999997</td>\n",
       "      <td>2</td>\n",
       "      <td>M</td>\n",
       "      <td>3</td>\n",
       "      <td>2502</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>230817</th>\n",
       "      <td>nhj4wh46MAf5K0IHDu4DGyRsdWn2</td>\n",
       "      <td>5</td>\n",
       "      <td>F</td>\n",
       "      <td>2</td>\n",
       "      <td>3499</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>230818</th>\n",
       "      <td>nmbzA4awkiRGXX26fT6wpoxURY43</td>\n",
       "      <td>1</td>\n",
       "      <td>F</td>\n",
       "      <td>1</td>\n",
       "      <td>5407</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>230819 rows Ã— 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                             user_id  class gender  grade  school_id\n",
       "0                            1000000      1      M      1       1885\n",
       "1                            1000009     10      F      2       3869\n",
       "2                            1000012     10      F      1       5091\n",
       "3                            1000013      8      F      2       1743\n",
       "4                            1000015      2      F      3       5078\n",
       "...                              ...    ...    ...    ...        ...\n",
       "230814                        999992      1      M      2       2240\n",
       "230815                        999996      5      M      2        365\n",
       "230816                        999997      2      M      3       2502\n",
       "230817  nhj4wh46MAf5K0IHDu4DGyRsdWn2      5      F      2       3499\n",
       "230818  nmbzA4awkiRGXX26fT6wpoxURY43      1      F      1       5407\n",
       "\n",
       "[230819 rows x 5 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(user_properties)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c65ce9d6",
   "metadata": {},
   "source": [
    "# ğŸ” ëª…ì„¸ì„œ ëª¨í˜¸ ë¶€ë¶„ ì •ì˜\n",
    "\n",
    "## í•´ê²°í•  ëª¨í˜¸í•œ ì ë“¤\n",
    "\n",
    "### accounts_blockrecord\n",
    "- â“ \"ì°¨ë‹¨ í›„ ì°¨ë‹¨ í•´ì œëŠ” ì—†ë‹¤. ì™œ?\" â†’ **ì‹¤ì œë¡œ í•´ì œ ê¸°ëŠ¥ì´ ì—†ëŠ”ì§€ í™•ì¸**\n",
    "- â“ ì°¨ë‹¨ ì´ìœ  ëª©ë¡ì´ ì •í™•í•œê°€? â†’ **ì‹¤ì œ ë°ì´í„°ì˜ reason ê°’ë“¤ í™•ì¸**\n",
    "\n",
    "### accounts_nearbyschool  \n",
    "- â“ \"ê±°ë¦¬ ê¸°ì¤€ì´ ë­”ì§€?\" â†’ **distance ë‹¨ìœ„ì™€ ìµœëŒ€ê°’ í™•ì •**\n",
    "- â“ \"ë°˜ê²½ 50km ë‚´ë¶€ ì¶”ì¸¡\" â†’ **ì‹¤ì œë¡œ 50kmê°€ ê¸°ì¤€ì¸ì§€ í™•ì¸**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19e8764d",
   "metadata": {},
   "source": [
    "## ë°ì´í„° ë¡œë“œ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f473f20f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# ë°ì´í„° ë¡œë“œ\n",
    "df_block = pd.read_parquet(\"gs://sprintda05_final_project/votes/accounts_blockrecord.parquet\")\n",
    "df_nearby = pd.read_parquet(\"gs://sprintda05_final_project/votes/accounts_nearbyschool.parquet\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b56a79dc",
   "metadata": {},
   "source": [
    "### ì°¨ë‹¨ í•´ì œ ì—¬ë¶€ í™•ì •"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "06bfd247",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==================================================\n",
      "ğŸ” ì°¨ë‹¨ í•´ì œ ê¸°ëŠ¥ ì¡´ì¬ ì—¬ë¶€\n",
      "==================================================\n",
      "ì´ ì°¨ë‹¨ ê´€ê³„: 19,482ê±´\n",
      "ê³ ìœ  ì°¨ë‹¨ ìŒ: 18,505ìŒ\n",
      "ì¤‘ë³µ ì°¨ë‹¨ ìŒ: 548ìŒ\n",
      "\n",
      "âš ï¸  ê²°ë¡ : ì°¨ë‹¨ í•´ì œ í›„ ì¬ì°¨ë‹¨ ê°€ëŠ¥\n",
      "   â†’ 548ìŒì´ ì—¬ëŸ¬ ë²ˆ ì°¨ë‹¨ë¨\n",
      "   â†’ ìµœëŒ€ 20ë²ˆ ì°¨ë‹¨\n"
     ]
    }
   ],
   "source": [
    "# ğŸš« ì°¨ë‹¨ í•´ì œ ê¸°ëŠ¥ ì¡´ì¬ ì—¬ë¶€ í™•ì •\n",
    "print(\"=\" * 50)\n",
    "print(\"ğŸ” ì°¨ë‹¨ í•´ì œ ê¸°ëŠ¥ ì¡´ì¬ ì—¬ë¶€\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "# ë™ì¼ ì‚¬ìš©ì ìŒì˜ ì¤‘ë³µ ì°¨ë‹¨ í™•ì¸\n",
    "duplicate_pairs = df_block.groupby(['user_id', 'block_user_id']).size()\n",
    "repeated_blocks = duplicate_pairs[duplicate_pairs > 1]\n",
    "\n",
    "print(f\"ì´ ì°¨ë‹¨ ê´€ê³„: {len(df_block):,}ê±´\")\n",
    "print(f\"ê³ ìœ  ì°¨ë‹¨ ìŒ: {len(duplicate_pairs):,}ìŒ\")\n",
    "print(f\"ì¤‘ë³µ ì°¨ë‹¨ ìŒ: {len(repeated_blocks):,}ìŒ\")\n",
    "\n",
    "if len(repeated_blocks) == 0:\n",
    "    print(\"\\nâœ… ê²°ë¡ : ì°¨ë‹¨ í•´ì œ ê¸°ëŠ¥ ì—†ìŒ (ë˜ëŠ” í•´ì œ ì‹œ ê¸°ë¡ ì‚­ì œ)\")\n",
    "    print(\"   â†’ ë™ì¼ ì‚¬ìš©ì ìŒì˜ ì¤‘ë³µ ì°¨ë‹¨ì´ ì „í˜€ ì—†ìŒ\")\n",
    "else:\n",
    "    print(f\"\\nâš ï¸  ê²°ë¡ : ì°¨ë‹¨ í•´ì œ í›„ ì¬ì°¨ë‹¨ ê°€ëŠ¥\")\n",
    "    print(f\"   â†’ {len(repeated_blocks)}ìŒì´ ì—¬ëŸ¬ ë²ˆ ì°¨ë‹¨ë¨\")\n",
    "    print(f\"   â†’ ìµœëŒ€ {repeated_blocks.max()}ë²ˆ ì°¨ë‹¨\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e56ec49",
   "metadata": {},
   "source": [
    "## ì°¨ë‹¨ ì‚¬ìœ  ì •í™•í•œ ëª©ë¡ í™•ì •"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "08d578c7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==================================================\n",
      "ğŸ” ì°¨ë‹¨ ì‚¬ìœ  ì •í™•í•œ ëª©ë¡\n",
      "==================================================\n",
      "ğŸ“‹ ì‹¤ì œ ë°ì´í„°ì˜ ì°¨ë‹¨ ì‚¬ìœ :\n",
      " 1. 'ê·¸ëƒ¥...' - 6ê±´ (0.0%)\n",
      " 2. 'ì¹œêµ¬ ì‚¬ì´ê°€ ì–´ìƒ‰í•´ì§' - 5,805ê±´ (29.8%)\n",
      " 3. 'ë‚˜ë‘ ê´€ë ¨ ì—†ëŠ” ì§ˆë¬¸ì„ ìê¾¸ ë³´ëƒ„' - 1,083ê±´ (5.6%)\n",
      " 4. 'ê¸°íƒ€' - 7ê±´ (0.0%)\n",
      " 5. 'ëª¨ë¥´ëŠ” ì‚¬ëŒì„' - 9,640ê±´ (49.5%)\n",
      " 6. 'ë„ˆë¬´ ë§ì€ ì–‘ì˜ ì§ˆë¬¸ì„ ë³´ëƒ„' - 919ê±´ (4.7%)\n",
      " 7. 'ì‚¬ì¹­ ê³„ì •' - 2,022ê±´ (10.4%)\n",
      "\n",
      "ì´ 7ê°œ ì‚¬ìœ \n",
      "\n",
      "ğŸ” ëª…ì„¸ì„œ ì‚¬ìœ  ê°œìˆ˜: 7ê°œ\n",
      "ì‹¤ì œ ë°ì´í„° ì‚¬ìœ  ê°œìˆ˜: 7ê°œ\n",
      "\n",
      "âœ… ëª…ì„¸ì„œì™€ ì‹¤ì œ ë°ì´í„° ì¼ì¹˜\n"
     ]
    }
   ],
   "source": [
    "# ğŸš« ì°¨ë‹¨ ì‚¬ìœ  ì •í™•í•œ ëª©ë¡ í™•ì •  \n",
    "print(\"=\" * 50)\n",
    "print(\"ğŸ” ì°¨ë‹¨ ì‚¬ìœ  ì •í™•í•œ ëª©ë¡\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "actual_reasons = df_block['reason'].unique()\n",
    "reason_counts = df_block['reason'].value_counts()\n",
    "\n",
    "print(\"ğŸ“‹ ì‹¤ì œ ë°ì´í„°ì˜ ì°¨ë‹¨ ì‚¬ìœ :\")\n",
    "for i, reason in enumerate(actual_reasons, 1):\n",
    "    count = reason_counts[reason]\n",
    "    pct = count / len(df_block) * 100\n",
    "    print(f\"{i:2d}. '{reason}' - {count:,}ê±´ ({pct:.1f}%)\")\n",
    "\n",
    "print(f\"\\nì´ {len(actual_reasons)}ê°œ ì‚¬ìœ \")\n",
    "\n",
    "# ëª…ì„¸ì„œì™€ ë¹„êµ\n",
    "spec_reasons = ['ê·¸ëƒ¥...', 'ì¹œêµ¬ ì‚¬ì´ê°€ ì–´ìƒ‰í•´ì§', 'ë‚˜ë‘ ê´€ë ¨ ì—†ëŠ” ì§ˆë¬¸ì„ ìê¾¸ ë³´ëƒ„', \n",
    "                'ê¸°íƒ€', 'ëª¨ë¥´ëŠ” ì‚¬ëŒì„', 'ë„ˆë¬´ ë§ì€ ì–‘ì˜ ì§ˆë¬¸ì„ ë³´ëƒ„', 'ì‚¬ì¹­ ê³„ì •']\n",
    "\n",
    "print(f\"\\nğŸ” ëª…ì„¸ì„œ ì‚¬ìœ  ê°œìˆ˜: {len(spec_reasons)}ê°œ\")\n",
    "print(f\"ì‹¤ì œ ë°ì´í„° ì‚¬ìœ  ê°œìˆ˜: {len(actual_reasons)}ê°œ\")\n",
    "\n",
    "missing_in_spec = set(actual_reasons) - set(spec_reasons)\n",
    "missing_in_data = set(spec_reasons) - set(actual_reasons) \n",
    "\n",
    "if missing_in_spec:\n",
    "    print(f\"\\nâš ï¸  ëª…ì„¸ì„œì— ì—†ëŠ” ì‚¬ìœ : {list(missing_in_spec)}\")\n",
    "if missing_in_data:\n",
    "    print(f\"âš ï¸  ë°ì´í„°ì— ì—†ëŠ” ì‚¬ìœ : {list(missing_in_data)}\")\n",
    "if not missing_in_spec and not missing_in_data:\n",
    "    print(\"\\nâœ… ëª…ì„¸ì„œì™€ ì‹¤ì œ ë°ì´í„° ì¼ì¹˜\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eef67e0c",
   "metadata": {},
   "source": [
    "### ê°€ê¹Œìš´ í•™êµ ê±°ë¦¬ ê¸°ì¤€ í™•ì •"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5d2551df",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==================================================\n",
      "ğŸ” ê°€ê¹Œìš´ í•™êµ ê±°ë¦¬ ê¸°ì¤€ í™•ì •\n",
      "==================================================\n",
      "ğŸ“ ê±°ë¦¬ í†µê³„:\n",
      "ìµœì†Œê°’: 0.000000\n",
      "ìµœëŒ€ê°’: 49.296594\n",
      "í‰ê· ê°’: 0.055338\n",
      "\n",
      "âœ… ê±°ë¦¬ ë‹¨ìœ„: í‚¬ë¡œë¯¸í„°(km)\n",
      "\n",
      "ğŸ¯ 50km ê¸°ì¤€ ë¶„ì„:\n",
      "50km ì´í•˜ ê´€ê³„: 59,500ìŒ (100.0%)\n",
      "ì „ì²´ ê´€ê³„: 59,500ìŒ\n",
      "\n",
      "âœ… ê²°ë¡ : 50kmê°€ ê°€ê¹Œìš´ í•™êµ ê¸°ì¤€ìœ¼ë¡œ í™•ì •\n",
      "   â†’ ëª¨ë“  ê´€ê³„ê°€ 50km ì´í•˜\n"
     ]
    }
   ],
   "source": [
    "# ğŸ« ê°€ê¹Œìš´ í•™êµ ê±°ë¦¬ ê¸°ì¤€ í™•ì •\n",
    "print(\"=\" * 50) \n",
    "print(\"ğŸ” ê°€ê¹Œìš´ í•™êµ ê±°ë¦¬ ê¸°ì¤€ í™•ì •\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "distances = df_nearby['distance']\n",
    "\n",
    "print(\"ğŸ“ ê±°ë¦¬ í†µê³„:\")\n",
    "print(f\"ìµœì†Œê°’: {distances.min():.6f}\")\n",
    "print(f\"ìµœëŒ€ê°’: {distances.max():.6f}\")\n",
    "print(f\"í‰ê· ê°’: {distances.mean():.6f}\")\n",
    "\n",
    "# ê±°ë¦¬ ë‹¨ìœ„ í™•ì •\n",
    "max_dist = distances.max()\n",
    "if max_dist < 100:\n",
    "    unit = \"km\"\n",
    "    print(f\"\\nâœ… ê±°ë¦¬ ë‹¨ìœ„: í‚¬ë¡œë¯¸í„°(km)\")\n",
    "else:\n",
    "    unit = \"m\" \n",
    "    print(f\"\\nâœ… ê±°ë¦¬ ë‹¨ìœ„: ë¯¸í„°(m)\")\n",
    "    print(f\"   â†’ ìµœëŒ€ ê±°ë¦¬: {max_dist/1000:.1f}km\")\n",
    "\n",
    "# 50km ê¸°ì¤€ í™•ì •\n",
    "if unit == \"km\":\n",
    "    within_50km = (distances <= 50).sum()\n",
    "    exactly_50km = (distances > 49.9) & (distances <= 50.0)\n",
    "else:\n",
    "    within_50km = (distances <= 50000).sum()\n",
    "    exactly_50km = (distances > 49900) & (distances <= 50000)\n",
    "\n",
    "print(f\"\\nğŸ¯ 50km ê¸°ì¤€ ë¶„ì„:\")\n",
    "print(f\"50km ì´í•˜ ê´€ê³„: {within_50km:,}ìŒ ({within_50km/len(df_nearby)*100:.1f}%)\")\n",
    "print(f\"ì „ì²´ ê´€ê³„: {len(df_nearby):,}ìŒ\")\n",
    "\n",
    "if within_50km == len(df_nearby):\n",
    "    print(\"\\nâœ… ê²°ë¡ : 50kmê°€ ê°€ê¹Œìš´ í•™êµ ê¸°ì¤€ìœ¼ë¡œ í™•ì •\")\n",
    "    print(\"   â†’ ëª¨ë“  ê´€ê³„ê°€ 50km ì´í•˜\")\n",
    "else:\n",
    "    over_50km = len(df_nearby) - within_50km\n",
    "    print(f\"\\nâš ï¸  50km ì´ˆê³¼ ê´€ê³„: {over_50km:,}ìŒ\")\n",
    "    print(f\"   â†’ ì‹¤ì œ ê¸°ì¤€: ì•½ {distances.max():.1f}{unit}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87da2169",
   "metadata": {},
   "source": [
    "### 50km ê¸°ì¤€ ìƒì„¸ ê²€ì¦"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1029997f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==================================================\n",
      "ğŸ” 50km ê¸°ì¤€ ìƒì„¸ ê²€ì¦\n",
      "==================================================\n",
      "ìµœëŒ€ ê±°ë¦¬: 49.296594\n",
      "ìµœëŒ€ ê±°ë¦¬ì˜ 99% ì´ìƒì¸ ê°’ë“¤:\n",
      "ê°œìˆ˜: 6ê°œ\n",
      "ë²”ìœ„: 49.149385 ~ 49.296594\n",
      "\n",
      "ğŸ“Š ìµœëŒ€ê°’ ê·¼ì²˜ ê±°ë¦¬ë³„ ê°œìˆ˜:\n",
      "0km: 59,403ê°œ\n",
      "1km: 33ê°œ\n",
      "2km: 46ê°œ\n",
      "6km: 9ê°œ\n",
      "43km: 1ê°œ\n",
      "48km: 2ê°œ\n",
      "49km: 6ê°œ\n",
      "\n",
      "âœ… ìµœì¢… ê²°ë¡ :\n",
      "ê°€ê¹Œìš´ í•™êµ ì •ì˜: ê¸°ì¤€ í•™êµë¡œë¶€í„° 50km ì´ë‚´\n"
     ]
    }
   ],
   "source": [
    "# ğŸ« 50km ê¸°ì¤€ ìƒì„¸ ê²€ì¦\n",
    "print(\"=\" * 50)\n",
    "print(\"ğŸ” 50km ê¸°ì¤€ ìƒì„¸ ê²€ì¦\") \n",
    "print(\"=\" * 50)\n",
    "\n",
    "# ìµœëŒ€ê°’ ê·¼ì²˜ ë¶„í¬ í™•ì¸\n",
    "max_distance = distances.max()\n",
    "near_max = distances[distances > max_distance * 0.99]\n",
    "\n",
    "print(f\"ìµœëŒ€ ê±°ë¦¬: {max_distance:.6f}\")\n",
    "print(f\"ìµœëŒ€ ê±°ë¦¬ì˜ 99% ì´ìƒì¸ ê°’ë“¤:\")\n",
    "print(f\"ê°œìˆ˜: {len(near_max):,}ê°œ\")\n",
    "print(f\"ë²”ìœ„: {near_max.min():.6f} ~ {near_max.max():.6f}\")\n",
    "\n",
    "# ì •í™•íˆ 49.xxë‚˜ 50.xx ê°™ì€ ê°’ì´ ë§ì€ì§€ í™•ì¸\n",
    "rounded_distances = distances.round(0)\n",
    "rounded_counts = rounded_distances.value_counts().sort_index().tail(10)\n",
    "\n",
    "print(f\"\\nğŸ“Š ìµœëŒ€ê°’ ê·¼ì²˜ ê±°ë¦¬ë³„ ê°œìˆ˜:\")\n",
    "for dist, count in rounded_counts.items():\n",
    "    print(f\"{int(dist)}{unit}: {count:,}ê°œ\")\n",
    "\n",
    "# ì„ê³„ê°’ ì¶”ì •\n",
    "if unit == \"km\":\n",
    "    if max_distance > 49.9 and max_distance <= 50.1:\n",
    "        threshold = 50\n",
    "    else:\n",
    "        threshold = int(max_distance) + 1\n",
    "else:\n",
    "    if max_distance > 49900 and max_distance <= 50100:\n",
    "        threshold = 50000  \n",
    "    else:\n",
    "        threshold = int(max_distance/1000) * 1000 + 1000\n",
    "\n",
    "print(f\"\\nâœ… ìµœì¢… ê²°ë¡ :\")\n",
    "print(f\"ê°€ê¹Œìš´ í•™êµ ì •ì˜: ê¸°ì¤€ í•™êµë¡œë¶€í„° {threshold}{unit if unit=='km' else 'm'} ì´ë‚´\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b06a1c3",
   "metadata": {},
   "source": [
    "### ì •ì˜ ì™„ë£Œ ìš”ì•½"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "549b0f45",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "ğŸ¯ ëª¨í˜¸í•œ ë¶€ë¶„ ì •ì˜ ì™„ë£Œ\n",
      "============================================================\n",
      "âœ… accounts_blockrecord:\n",
      "   â€¢ ì°¨ë‹¨ í•´ì œ ê¸°ëŠ¥: ìˆìŒ (ì¤‘ë³µ ì°¨ë‹¨ 548ìŒ)\n",
      "   â€¢ ì°¨ë‹¨ ì‚¬ìœ : 7ê°œ í™•ì •\n",
      "\n",
      "âœ… accounts_nearbyschool:\n",
      "   â€¢ ê±°ë¦¬ ë‹¨ìœ„: km\n",
      "   â€¢ ê°€ê¹Œìš´ í•™êµ ê¸°ì¤€: 50km ì´ë‚´\n",
      "   â€¢ ì „ì²´ ê´€ê³„ ìˆ˜: 59,500ìŒ\n",
      "\n",
      "ğŸ” í™•ì •ëœ ëª…ì„¸:\n",
      "   â€¢ ì°¨ë‹¨ì€ í•´ì œ ê°€ëŠ¥\n",
      "   â€¢ ê°€ê¹Œìš´ í•™êµëŠ” 50km ë°˜ê²½ ë‚´ ëª¨ë“  í•™êµ\n"
     ]
    }
   ],
   "source": [
    "# ğŸ“‹ ëª¨í˜¸í•œ ë¶€ë¶„ ì •ì˜ ì™„ë£Œ ìš”ì•½\n",
    "print(\"=\" * 60)\n",
    "print(\"ğŸ¯ ëª¨í˜¸í•œ ë¶€ë¶„ ì •ì˜ ì™„ë£Œ\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "print(\"âœ… accounts_blockrecord:\")\n",
    "duplicate_pairs = df_block.groupby(['user_id', 'block_user_id']).size()\n",
    "repeated_blocks = duplicate_pairs[duplicate_pairs > 1]\n",
    "\n",
    "if len(repeated_blocks) == 0:\n",
    "    print(\"   â€¢ ì°¨ë‹¨ í•´ì œ ê¸°ëŠ¥: ì—†ìŒ (ì¤‘ë³µ ì°¨ë‹¨ 0ê±´)\")\n",
    "else:\n",
    "    print(f\"   â€¢ ì°¨ë‹¨ í•´ì œ ê¸°ëŠ¥: ìˆìŒ (ì¤‘ë³µ ì°¨ë‹¨ {len(repeated_blocks)}ìŒ)\")\n",
    "\n",
    "actual_reasons = df_block['reason'].unique()\n",
    "print(f\"   â€¢ ì°¨ë‹¨ ì‚¬ìœ : {len(actual_reasons)}ê°œ í™•ì •\")\n",
    "\n",
    "print(f\"\\nâœ… accounts_nearbyschool:\")\n",
    "max_distance = df_nearby['distance'].max()\n",
    "if max_distance < 100:\n",
    "    unit_str = \"km\"\n",
    "    threshold = 50 if max_distance <= 50.1 else int(max_distance) + 1\n",
    "else:\n",
    "    unit_str = \"m\"  \n",
    "    threshold = 50000 if max_distance <= 50100 else int(max_distance/1000)*1000 + 1000\n",
    "    \n",
    "print(f\"   â€¢ ê±°ë¦¬ ë‹¨ìœ„: {unit_str}\")\n",
    "print(f\"   â€¢ ê°€ê¹Œìš´ í•™êµ ê¸°ì¤€: {threshold}{unit_str} ì´ë‚´\")\n",
    "print(f\"   â€¢ ì „ì²´ ê´€ê³„ ìˆ˜: {len(df_nearby):,}ìŒ\")\n",
    "\n",
    "print(f\"\\nğŸ” í™•ì •ëœ ëª…ì„¸:\")\n",
    "print(f\"   â€¢ ì°¨ë‹¨ì€ í•´ì œ {'ë¶ˆê°€ëŠ¥' if len(repeated_blocks) == 0 else 'ê°€ëŠ¥'}\")\n",
    "print(f\"   â€¢ ê°€ê¹Œìš´ í•™êµëŠ” {threshold}{unit_str} ë°˜ê²½ ë‚´ ëª¨ë“  í•™êµ\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d73fde0",
   "metadata": {},
   "source": [
    "## ì§ˆë¬¸ ì†¡ìˆ˜ì‹  ê°œë… ì •ë¦¬"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ef4db55",
   "metadata": {},
   "source": [
    "## ğŸ¤” \"ì§ˆë¬¸ì„ ë³´ëƒˆë‹¤\"ì˜ ì •í™•í•œ ì˜ë¯¸\n",
    "\n",
    "### í˜¼ë€ìŠ¤ëŸ¬ìš´ í‘œí˜„ë“¤\n",
    "- ì°¨ë‹¨ ì‚¬ìœ : \"ë‚˜ë‘ ê´€ë ¨ ì—†ëŠ” ì§ˆë¬¸ì„ ìê¾¸ **ë³´ëƒ„**\"\n",
    "- ì°¨ë‹¨ ì‚¬ìœ : \"ë„ˆë¬´ ë§ì€ ì–‘ì˜ ì§ˆë¬¸ì„ **ë³´ëƒ„**\"  \n",
    "- í•˜ì§€ë§Œ ì´ ì•±ì€ **ìµëª… íˆ¬í‘œ ì•±**ì¸ë° ì§ˆë¬¸ì„ ì§ì ‘ ë³´ë‚´ë‚˜?\n",
    "\n",
    "### ê°€ì„¤\n",
    "1. **íˆ¬í‘œ = ì§ˆë¬¸ ë³´ë‚´ê¸°**: Aê°€ ì§ˆë¬¸ì—ì„œ Bë¥¼ ì„ íƒ â†’ Bê°€ \"ì§ˆë¬¸ì„ ë°›ìŒ\"\n",
    "2. **ë³„ë„ ì§ˆë¬¸ ê¸°ëŠ¥**: íˆ¬í‘œ ì™¸ì— ì§ì ‘ ì§ˆë¬¸ì„ ë³´ë‚´ëŠ” ê¸°ëŠ¥ì´ ìˆìŒã…¡\n",
    "3. **í‘œí˜„ìƒ í˜¼ë™**: ì‹¤ì œë¡œëŠ” íˆ¬í‘œì¸ë° \"ì§ˆë¬¸\"ì´ë¼ê³  í‘œí˜„"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d5b18b8",
   "metadata": {},
   "source": [
    "### íˆ¬í‘œ ê¸°ë¡ ë¶„ì„"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f8582281",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ—³ï¸ íˆ¬í‘œ ê¸°ë¡ í…Œì´ë¸” ë¶„ì„\n",
      "==================================================\n",
      "ë°ì´í„° í˜•íƒœ: (1217558, 12)\n",
      "ì»¬ëŸ¼: ['id', 'status', 'created_at', 'chosen_user_id', 'question_id', 'user_id', 'question_piece_id', 'has_read', 'answer_status', 'answer_updated_at', 'report_count', 'opened_times']\n",
      "\n",
      "ìƒìœ„ 5ê°œ í–‰:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>status</th>\n",
       "      <th>created_at</th>\n",
       "      <th>chosen_user_id</th>\n",
       "      <th>question_id</th>\n",
       "      <th>user_id</th>\n",
       "      <th>question_piece_id</th>\n",
       "      <th>has_read</th>\n",
       "      <th>answer_status</th>\n",
       "      <th>answer_updated_at</th>\n",
       "      <th>report_count</th>\n",
       "      <th>opened_times</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>771777</td>\n",
       "      <td>C</td>\n",
       "      <td>2023-04-28 12:27:49</td>\n",
       "      <td>849469</td>\n",
       "      <td>252</td>\n",
       "      <td>849436</td>\n",
       "      <td>998458</td>\n",
       "      <td>0</td>\n",
       "      <td>N</td>\n",
       "      <td>2023-04-28 12:27:49</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>771800</td>\n",
       "      <td>C</td>\n",
       "      <td>2023-04-28 12:28:02</td>\n",
       "      <td>849446</td>\n",
       "      <td>244</td>\n",
       "      <td>849436</td>\n",
       "      <td>998459</td>\n",
       "      <td>0</td>\n",
       "      <td>N</td>\n",
       "      <td>2023-04-28 12:28:02</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>771812</td>\n",
       "      <td>C</td>\n",
       "      <td>2023-04-28 12:28:09</td>\n",
       "      <td>849454</td>\n",
       "      <td>183</td>\n",
       "      <td>849436</td>\n",
       "      <td>998460</td>\n",
       "      <td>1</td>\n",
       "      <td>N</td>\n",
       "      <td>2023-04-28 12:28:09</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>771828</td>\n",
       "      <td>C</td>\n",
       "      <td>2023-04-28 12:28:16</td>\n",
       "      <td>847375</td>\n",
       "      <td>101</td>\n",
       "      <td>849436</td>\n",
       "      <td>998461</td>\n",
       "      <td>0</td>\n",
       "      <td>N</td>\n",
       "      <td>2023-04-28 12:28:16</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>771851</td>\n",
       "      <td>C</td>\n",
       "      <td>2023-04-28 12:28:26</td>\n",
       "      <td>849477</td>\n",
       "      <td>209</td>\n",
       "      <td>849436</td>\n",
       "      <td>998462</td>\n",
       "      <td>1</td>\n",
       "      <td>N</td>\n",
       "      <td>2023-04-28 12:28:26</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       id status          created_at  chosen_user_id  question_id  user_id  \\\n",
       "0  771777      C 2023-04-28 12:27:49          849469          252   849436   \n",
       "1  771800      C 2023-04-28 12:28:02          849446          244   849436   \n",
       "2  771812      C 2023-04-28 12:28:09          849454          183   849436   \n",
       "3  771828      C 2023-04-28 12:28:16          847375          101   849436   \n",
       "4  771851      C 2023-04-28 12:28:26          849477          209   849436   \n",
       "\n",
       "   question_piece_id  has_read answer_status   answer_updated_at  \\\n",
       "0             998458         0             N 2023-04-28 12:27:49   \n",
       "1             998459         0             N 2023-04-28 12:28:02   \n",
       "2             998460         1             N 2023-04-28 12:28:09   \n",
       "3             998461         0             N 2023-04-28 12:28:16   \n",
       "4             998462         1             N 2023-04-28 12:28:26   \n",
       "\n",
       "   report_count  opened_times  \n",
       "0             0             0  \n",
       "1             0             0  \n",
       "2             0             0  \n",
       "3             0             0  \n",
       "4             0             0  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# íˆ¬í‘œ ê¸°ë¡ í…Œì´ë¸” ë¡œë“œ (í•µì‹¬ í…Œì´ë¸”)\n",
    "df_vote = pd.read_parquet(\"gs://sprintda05_final_project/votes/accounts_userquestionrecord.parquet\")\n",
    "\n",
    "print(\"ğŸ—³ï¸ íˆ¬í‘œ ê¸°ë¡ í…Œì´ë¸” ë¶„ì„\")\n",
    "print(\"=\" * 50)\n",
    "print(f\"ë°ì´í„° í˜•íƒœ: {df_vote.shape}\")\n",
    "print(f\"ì»¬ëŸ¼: {list(df_vote.columns)}\")\n",
    "print(\"\\nìƒìœ„ 5ê°œ í–‰:\")\n",
    "df_vote.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c74342a",
   "metadata": {},
   "source": [
    "### íˆ¬í‘œ â†’ ì§ˆë¬¸ ë°›ê¸° ê´€ê³„ í™•ì¸"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "8efcf53c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ“¨ íˆ¬í‘œ = ì§ˆë¬¸ ë³´ë‚´ê¸° ê´€ê³„ ë¶„ì„\n",
      "==================================================\n",
      "ê°€ì¥ ë§ì´ íˆ¬í‘œí•œ ì‚¬ìš©ì: 2786ë²ˆ\n",
      "í‰ê·  íˆ¬í‘œ íšŸìˆ˜: 251.1ë²ˆ\n",
      "ê°€ì¥ ë§ì´ íˆ¬í‘œ ë°›ì€ ì‚¬ìš©ì: 1239ë²ˆ\n",
      "í‰ê·  íˆ¬í‘œ ë°›ì€ íšŸìˆ˜: 78.9ë²ˆ\n",
      "\n",
      "ğŸ“Š íˆ¬í‘œ íŒ¨í„´:\n",
      "ì´ íˆ¬í‘œ ê¸°ë¡: 1,217,558ê±´\n",
      "íˆ¬í‘œí•œ ì‚¬ìš©ì ìˆ˜: 4,849ëª…\n",
      "íˆ¬í‘œ ë°›ì€ ì‚¬ìš©ì ìˆ˜: 15,426ëª…\n"
     ]
    }
   ],
   "source": [
    "# íˆ¬í‘œ ê¸°ë¡ì—ì„œ \"ì§ˆë¬¸ ë³´ë‚´ê¸°\" íŒ¨í„´ ë¶„ì„\n",
    "print(\"ğŸ“¨ íˆ¬í‘œ = ì§ˆë¬¸ ë³´ë‚´ê¸° ê´€ê³„ ë¶„ì„\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "# ì‚¬ìš©ìë³„ íˆ¬í‘œí•œ íšŸìˆ˜ (= ì§ˆë¬¸ ë³´ë‚¸ íšŸìˆ˜?)\n",
    "vote_sent = df_vote['user_id'].value_counts()\n",
    "print(f\"ê°€ì¥ ë§ì´ íˆ¬í‘œí•œ ì‚¬ìš©ì: {vote_sent.max()}ë²ˆ\")\n",
    "print(f\"í‰ê·  íˆ¬í‘œ íšŸìˆ˜: {vote_sent.mean():.1f}ë²ˆ\")\n",
    "\n",
    "# ì‚¬ìš©ìë³„ íˆ¬í‘œ ë°›ì€ íšŸìˆ˜ (= ì§ˆë¬¸ ë°›ì€ íšŸìˆ˜?)  \n",
    "vote_received = df_vote['chosen_user_id'].value_counts()\n",
    "print(f\"ê°€ì¥ ë§ì´ íˆ¬í‘œ ë°›ì€ ì‚¬ìš©ì: {vote_received.max()}ë²ˆ\")\n",
    "print(f\"í‰ê·  íˆ¬í‘œ ë°›ì€ íšŸìˆ˜: {vote_received.mean():.1f}ë²ˆ\")\n",
    "\n",
    "print(f\"\\nğŸ“Š íˆ¬í‘œ íŒ¨í„´:\")\n",
    "print(f\"ì´ íˆ¬í‘œ ê¸°ë¡: {len(df_vote):,}ê±´\")\n",
    "print(f\"íˆ¬í‘œí•œ ì‚¬ìš©ì ìˆ˜: {df_vote['user_id'].nunique():,}ëª…\")\n",
    "print(f\"íˆ¬í‘œ ë°›ì€ ì‚¬ìš©ì ìˆ˜: {df_vote['chosen_user_id'].nunique():,}ëª…\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "972c90aa",
   "metadata": {},
   "source": [
    "### ì°¨ë‹¨ ì‚¬ìœ ì™€ íˆ¬í‘œ íŒ¨í„´ ì—°ê´€ì„±"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "7dfb8082",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸš« ì°¨ë‹¨ ì‚¬ìœ ì™€ íˆ¬í‘œ íŒ¨í„´ ì—°ê´€ ë¶„ì„\n",
      "==================================================\n",
      "ì§ˆë¬¸ ê´€ë ¨ ì°¨ë‹¨ ì‚¬ìœ :\n",
      "â€¢ 'ë‚˜ë‘ ê´€ë ¨ ì—†ëŠ” ì§ˆë¬¸ì„ ìê¾¸ ë³´ëƒ„': 1,083ê±´\n",
      "â€¢ 'ë„ˆë¬´ ë§ì€ ì–‘ì˜ ì§ˆë¬¸ì„ ë³´ëƒ„': 919ê±´\n",
      "\n",
      "ğŸ“ˆ ìƒê´€ê´€ê³„ ë¶„ì„:\n",
      "íˆ¬í‘œ ë§ì´ ë°›ì€ ìƒìœ„ 10% ì‚¬ìš©ì: 1542ëª…\n",
      "ì´ ì¤‘ ì°¨ë‹¨ë‹¹í•œ ì‚¬ìš©ì: 45ëª…\n",
      "ì°¨ë‹¨ë‹¹í•œ ë¹„ìœ¨: 2.9%\n"
     ]
    }
   ],
   "source": [
    "# ì°¨ë‹¨ ì‚¬ìœ  ì¬ë¶„ì„\n",
    "df_block = pd.read_parquet(\"gs://sprintda05_final_project/votes/accounts_blockrecord.parquet\")\n",
    "\n",
    "print(\"ğŸš« ì°¨ë‹¨ ì‚¬ìœ ì™€ íˆ¬í‘œ íŒ¨í„´ ì—°ê´€ ë¶„ì„\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "question_related_blocks = df_block[\n",
    "    df_block['reason'].str.contains('ì§ˆë¬¸|ë³´ëƒ„', na=False)\n",
    "]['reason'].value_counts()\n",
    "\n",
    "print(\"ì§ˆë¬¸ ê´€ë ¨ ì°¨ë‹¨ ì‚¬ìœ :\")\n",
    "for reason, count in question_related_blocks.items():\n",
    "    print(f\"â€¢ '{reason}': {count:,}ê±´\")\n",
    "\n",
    "# ì‹¤ì œë¡œ ë§ì´ íˆ¬í‘œë°›ì€ ì‚¬ìš©ìê°€ ë§ì´ ì°¨ë‹¨ë‹¹í–ˆëŠ”ì§€ í™•ì¸\n",
    "if len(vote_received) > 0 and len(df_block) > 0:\n",
    "    # íˆ¬í‘œë¥¼ ë§ì´ ë°›ì€ ìƒìœ„ 10% ì‚¬ìš©ì\n",
    "    top_vote_receivers = vote_received.head(int(len(vote_received) * 0.1)).index\n",
    "    \n",
    "    # ì´ë“¤ì´ ì°¨ë‹¨ë‹¹í•œ ë¹„ìœ¨\n",
    "    blocked_users = df_block['block_user_id'].unique()\n",
    "    top_receivers_blocked = len(set(top_vote_receivers) & set(blocked_users))\n",
    "    \n",
    "    print(f\"\\nğŸ“ˆ ìƒê´€ê´€ê³„ ë¶„ì„:\")\n",
    "    print(f\"íˆ¬í‘œ ë§ì´ ë°›ì€ ìƒìœ„ 10% ì‚¬ìš©ì: {len(top_vote_receivers)}ëª…\")\n",
    "    print(f\"ì´ ì¤‘ ì°¨ë‹¨ë‹¹í•œ ì‚¬ìš©ì: {top_receivers_blocked}ëª…\")\n",
    "    print(f\"ì°¨ë‹¨ë‹¹í•œ ë¹„ìœ¨: {top_receivers_blocked/len(top_vote_receivers)*100:.1f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "517bf777",
   "metadata": {},
   "source": [
    "### ì‚¬ìš©ìë³„ íˆ¬í‘œ ë°œì†¡/ìˆ˜ì‹  íŒ¨í„´"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b38242bd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ‘¤ ì‚¬ìš©ìë³„ íˆ¬í‘œ ë°œì†¡/ìˆ˜ì‹  íŒ¨í„´\n",
      "==================================================\n",
      "íˆ¬í‘œë¥¼ ê°€ì¥ ë§ì´ ë³´ë‚¸ ì‚¬ìš©ìë“¤:\n",
      "ì‚¬ìš©ì 849103: 2786ë²ˆ íˆ¬í‘œ\n",
      "ì‚¬ìš©ì 876509: 1708ë²ˆ íˆ¬í‘œ\n",
      "ì‚¬ìš©ì 856042: 1701ë²ˆ íˆ¬í‘œ\n",
      "ì‚¬ìš©ì 1213990: 1695ë²ˆ íˆ¬í‘œ\n",
      "ì‚¬ìš©ì 1159163: 1656ë²ˆ íˆ¬í‘œ\n",
      "ì‚¬ìš©ì 1058255: 1544ë²ˆ íˆ¬í‘œ\n",
      "ì‚¬ìš©ì 1206529: 1544ë²ˆ íˆ¬í‘œ\n",
      "ì‚¬ìš©ì 952220: 1527ë²ˆ íˆ¬í‘œ\n",
      "ì‚¬ìš©ì 1170559: 1513ë²ˆ íˆ¬í‘œ\n",
      "ì‚¬ìš©ì 1236004: 1482ë²ˆ íˆ¬í‘œ\n",
      "\n",
      "íˆ¬í‘œë¥¼ ê°€ì¥ ë§ì´ ë°›ì€ ì‚¬ìš©ìë“¤:\n",
      "ì‚¬ìš©ì 913265: 1239ë²ˆ íˆ¬í‘œë°›ìŒ\n",
      "ì‚¬ìš©ì 1206668: 1054ë²ˆ íˆ¬í‘œë°›ìŒ\n",
      "ì‚¬ìš©ì 1402487: 1049ë²ˆ íˆ¬í‘œë°›ìŒ\n",
      "ì‚¬ìš©ì 1122686: 1042ë²ˆ íˆ¬í‘œë°›ìŒ\n",
      "ì‚¬ìš©ì 994573: 997ë²ˆ íˆ¬í‘œë°›ìŒ\n",
      "ì‚¬ìš©ì 1017281: 997ë²ˆ íˆ¬í‘œë°›ìŒ\n",
      "ì‚¬ìš©ì 1132932: 993ë²ˆ íˆ¬í‘œë°›ìŒ\n",
      "ì‚¬ìš©ì 873259: 971ë²ˆ íˆ¬í‘œë°›ìŒ\n",
      "ì‚¬ìš©ì 1207784: 948ë²ˆ íˆ¬í‘œë°›ìŒ\n",
      "ì‚¬ìš©ì 1017447: 917ë²ˆ íˆ¬í‘œë°›ìŒ\n",
      "\n",
      "ğŸ’• ê°€ì¥ ë¹ˆë²ˆí•œ íˆ¬í‘œ ê´€ê³„:\n",
      "ì‚¬ìš©ì 1214232 â†’ ì‚¬ìš©ì 1132932: 887ë²ˆ\n",
      "ì‚¬ìš©ì 952220 â†’ ì‚¬ìš©ì 907442: 537ë²ˆ\n",
      "ì‚¬ìš©ì 952220 â†’ ì‚¬ìš©ì 884218: 422ë²ˆ\n",
      "ì‚¬ìš©ì 1401244 â†’ ì‚¬ìš©ì 968333: 404ë²ˆ\n",
      "ì‚¬ìš©ì 1213990 â†’ ì‚¬ìš©ì 1206529: 316ë²ˆ\n",
      "ì‚¬ìš©ì 880602 â†’ ì‚¬ìš©ì 876643: 276ë²ˆ\n",
      "ì‚¬ìš©ì 1170559 â†’ ì‚¬ìš©ì 1136231: 272ë²ˆ\n",
      "ì‚¬ìš©ì 1395767 â†’ ì‚¬ìš©ì 1367561: 264ë²ˆ\n",
      "ì‚¬ìš©ì 952220 â†’ ì‚¬ìš©ì 905351: 262ë²ˆ\n",
      "ì‚¬ìš©ì 1170559 â†’ ì‚¬ìš©ì 916592: 257ë²ˆ\n",
      "\n",
      "âš ï¸  ë™ì¼ ì‚¬ìš©ì ìŒì˜ ê³¼ë„í•œ íˆ¬í‘œ ë°œê²¬!\n",
      "   â†’ ì´ê²ƒì´ 'ë„ˆë¬´ ë§ì€ ì§ˆë¬¸ì„ ë³´ëƒ„' ì°¨ë‹¨ ì‚¬ìœ ì™€ ì—°ê´€ë  ìˆ˜ ìˆìŒ\n"
     ]
    }
   ],
   "source": [
    "# ê°œë³„ ì‚¬ìš©ìì˜ íˆ¬í‘œ ë°œì†¡/ìˆ˜ì‹  íŒ¨í„´ ë¶„ì„\n",
    "print(\"ğŸ‘¤ ì‚¬ìš©ìë³„ íˆ¬í‘œ ë°œì†¡/ìˆ˜ì‹  íŒ¨í„´\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "# íˆ¬í‘œë¥¼ ë§ì´ ë³´ë‚¸ ì‚¬ìš©ì (= ì§ˆë¬¸ì„ ë§ì´ ë³´ë‚¸ ì‚¬ìš©ì?)\n",
    "top_senders = vote_sent.head(10)\n",
    "print(\"íˆ¬í‘œë¥¼ ê°€ì¥ ë§ì´ ë³´ë‚¸ ì‚¬ìš©ìë“¤:\")\n",
    "for user_id, count in top_senders.items():\n",
    "    print(f\"ì‚¬ìš©ì {user_id}: {count}ë²ˆ íˆ¬í‘œ\")\n",
    "\n",
    "# íˆ¬í‘œë¥¼ ë§ì´ ë°›ì€ ì‚¬ìš©ì (= ì§ˆë¬¸ì„ ë§ì´ ë°›ì€ ì‚¬ìš©ì?)\n",
    "top_receivers = vote_received.head(10)\n",
    "print(f\"\\níˆ¬í‘œë¥¼ ê°€ì¥ ë§ì´ ë°›ì€ ì‚¬ìš©ìë“¤:\")\n",
    "for user_id, count in top_receivers.items():\n",
    "    print(f\"ì‚¬ìš©ì {user_id}: {count}ë²ˆ íˆ¬í‘œë°›ìŒ\")\n",
    "\n",
    "# íŠ¹ì • ì‚¬ìš©ì ìŒì˜ ê´€ê³„ ë¶„ì„\n",
    "user_pairs = df_vote.groupby(['user_id', 'chosen_user_id']).size().sort_values(ascending=False)\n",
    "top_pairs = user_pairs.head(10)\n",
    "\n",
    "print(f\"\\nğŸ’• ê°€ì¥ ë¹ˆë²ˆí•œ íˆ¬í‘œ ê´€ê³„:\")\n",
    "for (sender, receiver), count in top_pairs.items():\n",
    "    print(f\"ì‚¬ìš©ì {sender} â†’ ì‚¬ìš©ì {receiver}: {count}ë²ˆ\")\n",
    "    \n",
    "if top_pairs.iloc[0] > 5:\n",
    "    print(\"\\nâš ï¸  ë™ì¼ ì‚¬ìš©ì ìŒì˜ ê³¼ë„í•œ íˆ¬í‘œ ë°œê²¬!\")\n",
    "    print(\"   â†’ ì´ê²ƒì´ 'ë„ˆë¬´ ë§ì€ ì§ˆë¬¸ì„ ë³´ëƒ„' ì°¨ë‹¨ ì‚¬ìœ ì™€ ì—°ê´€ë  ìˆ˜ ìˆìŒ\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5cc4528d",
   "metadata": {},
   "source": [
    "### ì§ˆë¬¸ ì¢…ë¥˜ë³„ ë¶„ì„"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "add89cb3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "â“ ì§ˆë¬¸ ì¢…ë¥˜ì™€ íˆ¬í‘œ íŒ¨í„´\n",
      "==================================================\n",
      "ì´ ì§ˆë¬¸ ìˆ˜: 5025ê°œ\n",
      "\n",
      "ì§ˆë¬¸ ìƒ˜í”Œ:\n",
      "1. ê°€ì¥ ì‹ ë¹„í•œ ë§¤ë ¥ì´ ìˆëŠ” ì‚¬ëŒì€?\n",
      "2. \"ì´ ì‚¬ëŒìœ¼ë¡œ í•œ ë²ˆ ì‚´ì•„ë³´ê³  ì‹¶ë‹¤\" í•˜ëŠ” ì‚¬ëŒì€?\n",
      "3. ë¯¸ë˜ì˜ í‹±í†¡ì»¤ëŠ”?\n",
      "4. ì—¬ê¸°ì„œ ì œì¼ íŠ¹ì´í•œ ì¹œêµ¬ëŠ”?\n",
      "5. ê°€ì¥ ì§€ì¼œì£¼ê³  ì‹¶ì€ ì‚¬ëŒì€?\n",
      "\n",
      "ğŸ“Š ê°€ì¥ ì¸ê¸°ìˆëŠ” ì§ˆë¬¸:\n",
      "â€¢ ì²˜ìŒ ë³´ëŠ” ì‚¬ëŒê³¼ ê°€ì¥ ë¹¨ë¦¬ ì¹œí•´ì§ˆ ê²ƒ ê°™ì€ ì‚¬ëŒì€?: 1,996ë²ˆ íˆ¬í‘œ\n",
      "â€¢ ëª¨ë“  ì‚¬ëŒê³¼ ì˜ ì§€ë‚¼ ê²ƒ ê°™ì€ ì‚¬ëŒì€?: 1,986ë²ˆ íˆ¬í‘œ\n",
      "â€¢ ì¶•ì œì—ì„œ ê³µì—°ì„ ì œì¼ ì˜ í• ê±° ê°™ì€ ì‚¬ëŒì€?: 1,984ë²ˆ íˆ¬í‘œ\n",
      "â€¢ ì•ìœ¼ë¡œì˜ ì¸ìƒì„ ê°€ì¥ ì¬ë¯¸ìˆê²Œ ì‚´ê²ƒ ê°™ì€ ì‚¬ëŒì€?: 1,974ë²ˆ íˆ¬í‘œ\n",
      "â€¢ ë°˜ë ¤ë™ë¬¼ê³¼ ê°€ì¥ ì˜ ì§€ë‚¼ê±° ê°™ì€ ì‚¬ëŒì€?: 1,956ë²ˆ íˆ¬í‘œ\n"
     ]
    }
   ],
   "source": [
    "# ì§ˆë¬¸ í…Œì´ë¸”ê³¼ ì—°ê²°í•˜ì—¬ ë¶„ì„\n",
    "df_question = pd.read_parquet(\"gs://sprintda05_final_project/votes/polls_question.parquet\")\n",
    "\n",
    "print(\"â“ ì§ˆë¬¸ ì¢…ë¥˜ì™€ íˆ¬í‘œ íŒ¨í„´\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "print(f\"ì´ ì§ˆë¬¸ ìˆ˜: {len(df_question)}ê°œ\")\n",
    "print(\"\\nì§ˆë¬¸ ìƒ˜í”Œ:\")\n",
    "for i, question in enumerate(df_question['question_text'].head(5), 1):\n",
    "    print(f\"{i}. {question}\")\n",
    "\n",
    "# ì§ˆë¬¸ë³„ íˆ¬í‘œ ë¹ˆë„\n",
    "if 'question_id' in df_vote.columns:\n",
    "    question_popularity = df_vote['question_id'].value_counts()\n",
    "    print(f\"\\nğŸ“Š ê°€ì¥ ì¸ê¸°ìˆëŠ” ì§ˆë¬¸:\")\n",
    "    \n",
    "    # ìƒìœ„ 5ê°œ ì§ˆë¬¸ì˜ ì‹¤ì œ ë‚´ìš©\n",
    "    top_questions = question_popularity.head(5)\n",
    "    question_dict = df_question.set_index('id')['question_text'].to_dict()\n",
    "    \n",
    "    for question_id, count in top_questions.items():\n",
    "        if question_id in question_dict:\n",
    "            print(f\"â€¢ {question_dict[question_id]}: {count:,}ë²ˆ íˆ¬í‘œ\")\n",
    "        else:\n",
    "            print(f\"â€¢ ì§ˆë¬¸ ID {question_id}: {count:,}ë²ˆ íˆ¬í‘œ\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b57e9cc",
   "metadata": {},
   "source": [
    "### ê²°ë¡  ë„ì¶œ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "5555260a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ¯ 'ì§ˆë¬¸ì„ ë³´ëƒˆë‹¤'ì˜ ì •í™•í•œ ì˜ë¯¸\n",
      "============================================================\n",
      "ğŸ“‹ ë¶„ì„ ê²°ê³¼:\n",
      "â€¢ ì´ íˆ¬í‘œ ê¸°ë¡: 1,217,558ê±´\n",
      "â€¢ ì§ˆë¬¸ ê´€ë ¨ ì°¨ë‹¨: 2,002ê±´\n",
      "â€¢ ì§ˆë¬¸ ê´€ë ¨ ì°¨ë‹¨ ë¹„ìœ¨: 10.3%\n",
      "\n",
      "ğŸ” ê³¼ë„í•œ íˆ¬í‘œ ê´€ê³„:\n",
      "â€¢ 10ë²ˆ ì´ìƒ íˆ¬í‘œí•œ ì‚¬ìš©ì ìŒ: 32621ìŒ\n",
      "â€¢ ìµœëŒ€ íˆ¬í‘œ íšŸìˆ˜: 887ë²ˆ\n",
      "\n",
      "âœ… ìµœì¢… ê²°ë¡ :\n",
      "'ì§ˆë¬¸ì„ ë³´ëƒ„' = Aê°€ íŠ¹ì • ì§ˆë¬¸ì—ì„œ Bë¥¼ ë°˜ë³µì ìœ¼ë¡œ ì„ íƒí•˜ëŠ” íˆ¬í‘œ í–‰ìœ„\n",
      "â€¢ ë™ì¼í•œ ì‚¬ëŒì„ ì—¬ëŸ¬ ì§ˆë¬¸ì—ì„œ ê³„ì† ì„ íƒí•˜ë©´ 'ì§ˆë¬¸ì„ ë§ì´ ë³´ë‚¸ë‹¤'ê³  ì¸ì‹\n",
      "â€¢ ë°›ëŠ” ì‚¬ëŒ ì…ì¥ì—ì„œëŠ” 'ê³„ì† ì§ˆë¬¸ì´ ì˜¨ë‹¤'ê³  ëŠë¼ê²Œ ë¨\n",
      "\n",
      "ğŸ“± ì•±ì—ì„œì˜ ì‹¤ì œ íë¦„:\n",
      "1. Aê°€ 'ê°€ì¥ ì¬ë°Œì„ ê²ƒ ê°™ì€ ì‚¬ëŒì€?'ì—ì„œ B ì„ íƒ (íˆ¬í‘œ)\n",
      "2. Bì—ê²Œ ì•Œë¦¼: 'ëˆ„êµ°ê°€ ë‹¹ì‹ ì„ ì„ íƒí–ˆìŠµë‹ˆë‹¤' (= ì§ˆë¬¸ì„ ë°›ìŒ)\n",
      "3. Bê°€ Aë¥¼ ì°¨ë‹¨í•  ë•Œ: 'Aê°€ ë‚˜í•œí…Œ ì§ˆë¬¸ì„ ë³´ëƒ„'ì´ë¼ê³  ì¸ì‹\n"
     ]
    }
   ],
   "source": [
    "# ìµœì¢… ê²°ë¡  ë„ì¶œ\n",
    "print(\"ğŸ¯ 'ì§ˆë¬¸ì„ ë³´ëƒˆë‹¤'ì˜ ì •í™•í•œ ì˜ë¯¸\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# ë°ì´í„° ê¸°ë°˜ ê²°ë¡ \n",
    "vote_count = len(df_vote)\n",
    "question_blocks = len(df_block[df_block['reason'].str.contains('ì§ˆë¬¸|ë³´ëƒ„', na=False)])\n",
    "\n",
    "print(\"ğŸ“‹ ë¶„ì„ ê²°ê³¼:\")\n",
    "print(f\"â€¢ ì´ íˆ¬í‘œ ê¸°ë¡: {vote_count:,}ê±´\")\n",
    "print(f\"â€¢ ì§ˆë¬¸ ê´€ë ¨ ì°¨ë‹¨: {question_blocks:,}ê±´\")\n",
    "print(f\"â€¢ ì§ˆë¬¸ ê´€ë ¨ ì°¨ë‹¨ ë¹„ìœ¨: {question_blocks/len(df_block)*100:.1f}%\")\n",
    "\n",
    "# ì‚¬ìš©ì ìŒë³„ ê³¼ë„í•œ íˆ¬í‘œ í™•ì¸\n",
    "user_pairs = df_vote.groupby(['user_id', 'chosen_user_id']).size()\n",
    "excessive_pairs = user_pairs[user_pairs > 10]  # 10ë²ˆ ì´ìƒ\n",
    "\n",
    "print(f\"\\nğŸ” ê³¼ë„í•œ íˆ¬í‘œ ê´€ê³„:\")\n",
    "print(f\"â€¢ 10ë²ˆ ì´ìƒ íˆ¬í‘œí•œ ì‚¬ìš©ì ìŒ: {len(excessive_pairs)}ìŒ\")\n",
    "if len(excessive_pairs) > 0:\n",
    "    print(f\"â€¢ ìµœëŒ€ íˆ¬í‘œ íšŸìˆ˜: {excessive_pairs.max()}ë²ˆ\")\n",
    "\n",
    "print(f\"\\nâœ… ìµœì¢… ê²°ë¡ :\")\n",
    "if len(excessive_pairs) > 0:\n",
    "    print(\"'ì§ˆë¬¸ì„ ë³´ëƒ„' = Aê°€ íŠ¹ì • ì§ˆë¬¸ì—ì„œ Bë¥¼ ë°˜ë³µì ìœ¼ë¡œ ì„ íƒí•˜ëŠ” íˆ¬í‘œ í–‰ìœ„\")\n",
    "    print(\"â€¢ ë™ì¼í•œ ì‚¬ëŒì„ ì—¬ëŸ¬ ì§ˆë¬¸ì—ì„œ ê³„ì† ì„ íƒí•˜ë©´ 'ì§ˆë¬¸ì„ ë§ì´ ë³´ë‚¸ë‹¤'ê³  ì¸ì‹\")\n",
    "    print(\"â€¢ ë°›ëŠ” ì‚¬ëŒ ì…ì¥ì—ì„œëŠ” 'ê³„ì† ì§ˆë¬¸ì´ ì˜¨ë‹¤'ê³  ëŠë¼ê²Œ ë¨\")\n",
    "else:\n",
    "    print(\"'ì§ˆë¬¸ì„ ë³´ëƒ„' = ì¼ë°˜ì ì¸ íˆ¬í‘œ í–‰ìœ„ (ê³¼ë„í•œ ë°˜ë³µì€ ê±°ì˜ ì—†ìŒ)\")\n",
    "    \n",
    "print(f\"\\nğŸ“± ì•±ì—ì„œì˜ ì‹¤ì œ íë¦„:\")\n",
    "print(\"1. Aê°€ 'ê°€ì¥ ì¬ë°Œì„ ê²ƒ ê°™ì€ ì‚¬ëŒì€?'ì—ì„œ B ì„ íƒ (íˆ¬í‘œ)\")\n",
    "print(\"2. Bì—ê²Œ ì•Œë¦¼: 'ëˆ„êµ°ê°€ ë‹¹ì‹ ì„ ì„ íƒí–ˆìŠµë‹ˆë‹¤' (= ì§ˆë¬¸ì„ ë°›ìŒ)\")\n",
    "print(\"3. Bê°€ Aë¥¼ ì°¨ë‹¨í•  ë•Œ: 'Aê°€ ë‚˜í•œí…Œ ì§ˆë¬¸ì„ ë³´ëƒ„'ì´ë¼ê³  ì¸ì‹\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d2135db",
   "metadata": {},
   "source": [
    "## ğŸš« ì°¨ë‹¨ ë©”ì»¤ë‹ˆì¦˜ ë¶„ì„\n",
    "\n",
    "### ì˜ë¬¸ì \n",
    "- ì‚¬ìš©ìê°€ **ê°œë³„ ì§ˆë¬¸/íˆ¬í‘œ**ë¥¼ ì°¨ë‹¨í•  ìˆ˜ ìˆëŠ”ê°€?\n",
    "- ê°œë³„ ì§ˆë¬¸ ì°¨ë‹¨ ì‹œ **í•´ë‹¹ íˆ¬í‘œë¥¼ ë³´ë‚¸ ì‚¬ìš©ì ì „ì²´**ê°€ ì°¨ë‹¨ë˜ëŠ”ê°€?\n",
    "- ì•„ë‹ˆë©´ **ê°œë³„ ì§ˆë¬¸ë§Œ** ì°¨ë‹¨ë˜ëŠ”ê°€?\n",
    "\n",
    "### ê´€ë ¨ í…Œì´ë¸”\n",
    "- `accounts_userquestionrecord.status`: **B(Blocked)** ìƒíƒœ ì¡´ì¬\n",
    "- `accounts_blockrecord`: ì‚¬ìš©ì ê°„ **ì „ì²´ ì°¨ë‹¨** ê¸°ë¡\n",
    "- `polls_questionreport`: ì§ˆë¬¸ ìì²´ì— ëŒ€í•œ **ì‹ ê³ ** ê¸°ë¡"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee13cd6f",
   "metadata": {},
   "source": [
    "### ë°ì´í„° ë¡œë“œ ë° ì°¨ë‹¨ ìƒíƒœ í™•ì¸"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "5c3cef7e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ” íˆ¬í‘œ ê¸°ë¡ì˜ ì°¨ë‹¨ ìƒíƒœ ë¶„ì„\n",
      "==================================================\n",
      "ğŸ“Š íˆ¬í‘œ ìƒíƒœë³„ ë¶„í¬:\n",
      "â€¢ C: Closed (ë‹«í˜) - 1,156,322ê±´ (95.0%)\n",
      "â€¢ I: Initial (ì´ˆì„± ì—´ë¦¼) - 60,578ê±´ (5.0%)\n",
      "â€¢ B: Blocked (ì°¨ë‹¨ë¨) - 658ê±´ (0.1%)\n",
      "\n",
      "ğŸš« ì°¨ë‹¨ëœ ê°œë³„ íˆ¬í‘œ: 658ê±´\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# ê´€ë ¨ í…Œì´ë¸” ë¡œë“œ\n",
    "df_vote = pd.read_parquet(\"gs://sprintda05_final_project/votes/accounts_userquestionrecord.parquet\")\n",
    "df_block = pd.read_parquet(\"gs://sprintda05_final_project/votes/accounts_blockrecord.parquet\")\n",
    "\n",
    "print(\"ğŸ” íˆ¬í‘œ ê¸°ë¡ì˜ ì°¨ë‹¨ ìƒíƒœ ë¶„ì„\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "# status ì»¬ëŸ¼ ë¶„ì„\n",
    "if 'status' in df_vote.columns:\n",
    "    status_counts = df_vote['status'].value_counts()\n",
    "    print(\"ğŸ“Š íˆ¬í‘œ ìƒíƒœë³„ ë¶„í¬:\")\n",
    "    for status, count in status_counts.items():\n",
    "        pct = count / len(df_vote) * 100\n",
    "        status_meaning = {\n",
    "            'C': 'Closed (ë‹«í˜)',\n",
    "            'I': 'Initial (ì´ˆì„± ì—´ë¦¼)', \n",
    "            'B': 'Blocked (ì°¨ë‹¨ë¨)'\n",
    "        }.get(status, f'ì•Œ ìˆ˜ ì—†ìŒ ({status})')\n",
    "        print(f\"â€¢ {status}: {status_meaning} - {count:,}ê±´ ({pct:.1f}%)\")\n",
    "\n",
    "    blocked_votes = df_vote[df_vote['status'] == 'B']\n",
    "    print(f\"\\nğŸš« ì°¨ë‹¨ëœ ê°œë³„ íˆ¬í‘œ: {len(blocked_votes):,}ê±´\")\n",
    "else:\n",
    "    print(\"âŒ status ì»¬ëŸ¼ì´ ì—†ìŠµë‹ˆë‹¤.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c56c2963",
   "metadata": {},
   "source": [
    "### ê°œë³„ íˆ¬í‘œ ì°¨ë‹¨ vs ì‚¬ìš©ì ì „ì²´ ì°¨ë‹¨ ê´€ê³„"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "49d53e93",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ”— ê°œë³„ íˆ¬í‘œ ì°¨ë‹¨ê³¼ ì‚¬ìš©ì ì „ì²´ ì°¨ë‹¨ì˜ ê´€ê³„\n",
      "============================================================\n",
      "ì°¨ë‹¨ëœ ê°œë³„ íˆ¬í‘œ ìˆ˜: 658ê±´\n",
      "ì°¨ë‹¨ëœ íˆ¬í‘œì˜ ê³ ìœ  (ë°›ì€ì‚¬ëŒ, ë³´ë‚¸ì‚¬ëŒ) ìŒ: 318ìŒ\n",
      "\n",
      "ğŸ“Š ì¤‘ë³µ ë¶„ì„:\n",
      "â€¢ ê°œë³„ íˆ¬í‘œ ì°¨ë‹¨ ìŒ: 318ìŒ\n",
      "â€¢ ì‚¬ìš©ì ì „ì²´ ì°¨ë‹¨ ìŒ: 19,482ìŒ\n",
      "â€¢ ë‘˜ ë‹¤ í•´ë‹¹í•˜ëŠ” ìŒ: 49ìŒ\n",
      "â€¢ ì¤‘ë³µë¥ : 15.4%\n",
      "\n",
      "âŒ ê²°ë¡ : ê°œë³„ íˆ¬í‘œ ì°¨ë‹¨ê³¼ ì‚¬ìš©ì ì°¨ë‹¨ì€ ë³„ê°œ ê¸°ëŠ¥\n"
     ]
    }
   ],
   "source": [
    "print(\"ğŸ”— ê°œë³„ íˆ¬í‘œ ì°¨ë‹¨ê³¼ ì‚¬ìš©ì ì „ì²´ ì°¨ë‹¨ì˜ ê´€ê³„\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "if 'status' in df_vote.columns:\n",
    "    # B(Blocked) ìƒíƒœì¸ íˆ¬í‘œë“¤\n",
    "    blocked_votes = df_vote[df_vote['status'] == 'B']\n",
    "    \n",
    "    if len(blocked_votes) > 0:\n",
    "        print(f\"ì°¨ë‹¨ëœ ê°œë³„ íˆ¬í‘œ ìˆ˜: {len(blocked_votes):,}ê±´\")\n",
    "        \n",
    "        # ì°¨ë‹¨ëœ íˆ¬í‘œì—ì„œ (ë°›ì€ì‚¬ëŒ, ë³´ë‚¸ì‚¬ëŒ) ìŒ ì¶”ì¶œ\n",
    "        blocked_pairs = blocked_votes[['chosen_user_id', 'user_id']].drop_duplicates()\n",
    "        print(f\"ì°¨ë‹¨ëœ íˆ¬í‘œì˜ ê³ ìœ  (ë°›ì€ì‚¬ëŒ, ë³´ë‚¸ì‚¬ëŒ) ìŒ: {len(blocked_pairs):,}ìŒ\")\n",
    "        \n",
    "        # ì‚¬ìš©ì ì „ì²´ ì°¨ë‹¨ ê¸°ë¡ê³¼ ë¹„êµ\n",
    "        user_block_pairs = df_block[['user_id', 'block_user_id']].copy()\n",
    "        user_block_pairs.columns = ['chosen_user_id', 'user_id']  # ì»¬ëŸ¼ëª… ë§ì¶¤\n",
    "        \n",
    "        # ê°œë³„ íˆ¬í‘œ ì°¨ë‹¨ ìŒì´ ì‚¬ìš©ì ì „ì²´ ì°¨ë‹¨ì—ë„ ìˆëŠ”ì§€ í™•ì¸\n",
    "        merged = blocked_pairs.merge(\n",
    "            user_block_pairs, \n",
    "            on=['chosen_user_id', 'user_id'], \n",
    "            how='inner'\n",
    "        )\n",
    "        \n",
    "        overlap_count = len(merged)\n",
    "        overlap_rate = overlap_count / len(blocked_pairs) * 100\n",
    "        \n",
    "        print(f\"\\nğŸ“Š ì¤‘ë³µ ë¶„ì„:\")\n",
    "        print(f\"â€¢ ê°œë³„ íˆ¬í‘œ ì°¨ë‹¨ ìŒ: {len(blocked_pairs):,}ìŒ\")\n",
    "        print(f\"â€¢ ì‚¬ìš©ì ì „ì²´ ì°¨ë‹¨ ìŒ: {len(user_block_pairs):,}ìŒ\")\n",
    "        print(f\"â€¢ ë‘˜ ë‹¤ í•´ë‹¹í•˜ëŠ” ìŒ: {overlap_count:,}ìŒ\")\n",
    "        print(f\"â€¢ ì¤‘ë³µë¥ : {overlap_rate:.1f}%\")\n",
    "        \n",
    "        if overlap_rate > 80:\n",
    "            print(\"\\nâœ… ê²°ë¡ : ê°œë³„ íˆ¬í‘œ ì°¨ë‹¨ ì‹œ í•´ë‹¹ ì‚¬ìš©ìë„ ì „ì²´ ì°¨ë‹¨ë¨\")\n",
    "        elif overlap_rate > 20:\n",
    "            print(\"\\nâš ï¸  ê²°ë¡ : ê°œë³„ íˆ¬í‘œ ì°¨ë‹¨ê³¼ ì‚¬ìš©ì ì°¨ë‹¨ì´ ë¶€ë¶„ì ìœ¼ë¡œ ì—°ë™\")\n",
    "        else:\n",
    "            print(\"\\nâŒ ê²°ë¡ : ê°œë³„ íˆ¬í‘œ ì°¨ë‹¨ê³¼ ì‚¬ìš©ì ì°¨ë‹¨ì€ ë³„ê°œ ê¸°ëŠ¥\")\n",
    "            \n",
    "    else:\n",
    "        print(\"âŒ ì°¨ë‹¨ëœ ê°œë³„ íˆ¬í‘œê°€ ì—†ìŠµë‹ˆë‹¤.\")\n",
    "else:\n",
    "    print(\"âŒ status ì»¬ëŸ¼ì„ í™•ì¸í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3be540d",
   "metadata": {},
   "source": [
    "### ê°œë³„ íˆ¬í‘œ ì°¨ë‹¨ íŒ¨í„´ ë¶„ì„"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "b90f1681",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ¯ ê°œë³„ íˆ¬í‘œ ì°¨ë‹¨ ìƒì„¸ íŒ¨í„´\n",
      "==================================================\n",
      "ğŸ“¤ ê°œë³„ íˆ¬í‘œë¥¼ ê°€ì¥ ë§ì´ ì°¨ë‹¨ë‹¹í•œ ì‚¬ìš©ì (ë³´ë‚¸ ì‚¬ëŒ):\n",
      "â€¢ ì‚¬ìš©ì 850176: 75ê°œ íˆ¬í‘œ ì°¨ë‹¨ë‹¹í•¨\n",
      "â€¢ ì‚¬ìš©ì 881393: 43ê°œ íˆ¬í‘œ ì°¨ë‹¨ë‹¹í•¨\n",
      "â€¢ ì‚¬ìš©ì 850284: 24ê°œ íˆ¬í‘œ ì°¨ë‹¨ë‹¹í•¨\n",
      "â€¢ ì‚¬ìš©ì 877382: 23ê°œ íˆ¬í‘œ ì°¨ë‹¨ë‹¹í•¨\n",
      "â€¢ ì‚¬ìš©ì 959401: 22ê°œ íˆ¬í‘œ ì°¨ë‹¨ë‹¹í•¨\n",
      "\n",
      "ğŸ“¥ ê°œë³„ íˆ¬í‘œë¥¼ ê°€ì¥ ë§ì´ ì°¨ë‹¨í•œ ì‚¬ìš©ì (ë°›ì€ ì‚¬ëŒ):\n",
      "â€¢ ì‚¬ìš©ì 851717: 24ê°œ íˆ¬í‘œ ì°¨ë‹¨í•¨\n",
      "â€¢ ì‚¬ìš©ì 874009: 22ê°œ íˆ¬í‘œ ì°¨ë‹¨í•¨\n",
      "â€¢ ì‚¬ìš©ì 885409: 22ê°œ íˆ¬í‘œ ì°¨ë‹¨í•¨\n",
      "â€¢ ì‚¬ìš©ì 895204: 21ê°œ íˆ¬í‘œ ì°¨ë‹¨í•¨\n",
      "â€¢ ì‚¬ìš©ì 880093: 17ê°œ íˆ¬í‘œ ì°¨ë‹¨í•¨\n",
      "\n",
      "ğŸ”„ ë™ì¼ ì‚¬ìš©ì ìŒì˜ ë‹¤ì¤‘ íˆ¬í‘œ ì°¨ë‹¨:\n",
      "â€¢ ì—¬ëŸ¬ íˆ¬í‘œê°€ ì°¨ë‹¨ëœ ìŒ: 80ìŒ\n",
      "â€¢ ìµœëŒ€ ì°¨ë‹¨ íˆ¬í‘œ ìˆ˜: 24ê°œ\n",
      "â€¢ í•´ì„: ê°œë³„ íˆ¬í‘œë¥¼ ì—¬ëŸ¬ ë²ˆ ì°¨ë‹¨ â†’ ì‚¬ìš©ì ì „ì²´ ì°¨ë‹¨ìœ¼ë¡œ ì´ì–´ì§ˆ ê°€ëŠ¥ì„±\n"
     ]
    }
   ],
   "source": [
    "print(\"ğŸ¯ ê°œë³„ íˆ¬í‘œ ì°¨ë‹¨ ìƒì„¸ íŒ¨í„´\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "if 'status' in df_vote.columns:\n",
    "    blocked_votes = df_vote[df_vote['status'] == 'B']\n",
    "    \n",
    "    if len(blocked_votes) > 0:\n",
    "        # ëˆ„ê°€ ê°€ì¥ ë§ì´ ê°œë³„ íˆ¬í‘œë¥¼ ì°¨ë‹¨ë‹¹í–ˆëŠ”ì§€\n",
    "        blocked_senders = blocked_votes['user_id'].value_counts()\n",
    "        print(\"ğŸ“¤ ê°œë³„ íˆ¬í‘œë¥¼ ê°€ì¥ ë§ì´ ì°¨ë‹¨ë‹¹í•œ ì‚¬ìš©ì (ë³´ë‚¸ ì‚¬ëŒ):\")\n",
    "        for user_id, count in blocked_senders.head(5).items():\n",
    "            print(f\"â€¢ ì‚¬ìš©ì {user_id}: {count}ê°œ íˆ¬í‘œ ì°¨ë‹¨ë‹¹í•¨\")\n",
    "        \n",
    "        # ëˆ„ê°€ ê°€ì¥ ë§ì´ ê°œë³„ íˆ¬í‘œë¥¼ ì°¨ë‹¨í–ˆëŠ”ì§€  \n",
    "        blocked_receivers = blocked_votes['chosen_user_id'].value_counts()\n",
    "        print(f\"\\nğŸ“¥ ê°œë³„ íˆ¬í‘œë¥¼ ê°€ì¥ ë§ì´ ì°¨ë‹¨í•œ ì‚¬ìš©ì (ë°›ì€ ì‚¬ëŒ):\")\n",
    "        for user_id, count in blocked_receivers.head(5).items():\n",
    "            print(f\"â€¢ ì‚¬ìš©ì {user_id}: {count}ê°œ íˆ¬í‘œ ì°¨ë‹¨í•¨\")\n",
    "        \n",
    "        # ë™ì¼ ì‚¬ìš©ì ìŒì—ì„œ ì—¬ëŸ¬ íˆ¬í‘œê°€ ì°¨ë‹¨ë˜ì—ˆëŠ”ì§€\n",
    "        pair_blocks = blocked_votes.groupby(['chosen_user_id', 'user_id']).size()\n",
    "        multi_blocks = pair_blocks[pair_blocks > 1]\n",
    "        \n",
    "        print(f\"\\nğŸ”„ ë™ì¼ ì‚¬ìš©ì ìŒì˜ ë‹¤ì¤‘ íˆ¬í‘œ ì°¨ë‹¨:\")\n",
    "        print(f\"â€¢ ì—¬ëŸ¬ íˆ¬í‘œê°€ ì°¨ë‹¨ëœ ìŒ: {len(multi_blocks):,}ìŒ\")\n",
    "        if len(multi_blocks) > 0:\n",
    "            print(f\"â€¢ ìµœëŒ€ ì°¨ë‹¨ íˆ¬í‘œ ìˆ˜: {multi_blocks.max()}ê°œ\")\n",
    "            print(\"â€¢ í•´ì„: ê°œë³„ íˆ¬í‘œë¥¼ ì—¬ëŸ¬ ë²ˆ ì°¨ë‹¨ â†’ ì‚¬ìš©ì ì „ì²´ ì°¨ë‹¨ìœ¼ë¡œ ì´ì–´ì§ˆ ê°€ëŠ¥ì„±\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08b03b8e",
   "metadata": {},
   "source": [
    "### ì‹œê°„ìˆœ ì°¨ë‹¨ íŒ¨í„´ ë¶„ì„"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "475d7cf5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "â° ê°œë³„ íˆ¬í‘œ ì°¨ë‹¨ê³¼ ì‚¬ìš©ì ì°¨ë‹¨ì˜ ì‹œê°„ì  ê´€ê³„\n",
      "=======================================================\n",
      "ë™ì‹œì— ë°œìƒí•œ ì°¨ë‹¨ ìŒ: 259ìŒ\n",
      "í‰ê·  ì‹œê°„ ì°¨ì´: -195.7ì‹œê°„\n",
      "ì¤‘ê°„ê°’ ì‹œê°„ ì°¨ì´: -106.7ì‹œê°„\n",
      "\n",
      "ğŸ“Š 1ì‹œê°„ ì´ë‚´ ë™ì‹œ ì°¨ë‹¨: 3ìŒ (1.2%)\n",
      "âš ï¸  ê°œë³„ íˆ¬í‘œ ì°¨ë‹¨ê³¼ ì‚¬ìš©ì ì°¨ë‹¨ì´ ì‹œê°„ì°¨ë¥¼ ë‘ê³  ë°œìƒ\n"
     ]
    }
   ],
   "source": [
    "print(\"â° ê°œë³„ íˆ¬í‘œ ì°¨ë‹¨ê³¼ ì‚¬ìš©ì ì°¨ë‹¨ì˜ ì‹œê°„ì  ê´€ê³„\")\n",
    "print(\"=\" * 55)\n",
    "\n",
    "if 'status' in df_vote.columns and len(blocked_votes) > 0:\n",
    "    # ê°œë³„ íˆ¬í‘œ ì°¨ë‹¨ ì‹œê°„ ë¶„ì„\n",
    "    blocked_votes_time = blocked_votes[['chosen_user_id', 'user_id', 'created_at']].copy()\n",
    "    blocked_votes_time['created_at'] = pd.to_datetime(blocked_votes_time['created_at'])\n",
    "    \n",
    "    # ì‚¬ìš©ì ì „ì²´ ì°¨ë‹¨ ì‹œê°„\n",
    "    user_blocks_time = df_block[['user_id', 'block_user_id', 'created_at']].copy()\n",
    "    user_blocks_time['created_at'] = pd.to_datetime(user_blocks_time['created_at'])\n",
    "    user_blocks_time.columns = ['chosen_user_id', 'user_id', 'block_time']\n",
    "    \n",
    "    # ë™ì¼ ì‚¬ìš©ì ìŒì˜ ê°œë³„ íˆ¬í‘œ ì°¨ë‹¨ê³¼ ì „ì²´ ì°¨ë‹¨ ì‹œê°„ ë¹„êµ\n",
    "    time_comparison = blocked_votes_time.merge(\n",
    "        user_blocks_time,\n",
    "        on=['chosen_user_id', 'user_id'],\n",
    "        how='inner'\n",
    "    )\n",
    "    \n",
    "    if len(time_comparison) > 0:\n",
    "        # ì‹œê°„ ì°¨ì´ ê³„ì‚°\n",
    "        time_comparison['time_diff'] = (\n",
    "            time_comparison['block_time'] - time_comparison['created_at']\n",
    "        ).dt.total_seconds() / 3600  # ì‹œê°„ ë‹¨ìœ„\n",
    "        \n",
    "        print(f\"ë™ì‹œì— ë°œìƒí•œ ì°¨ë‹¨ ìŒ: {len(time_comparison):,}ìŒ\")\n",
    "        print(f\"í‰ê·  ì‹œê°„ ì°¨ì´: {time_comparison['time_diff'].mean():.1f}ì‹œê°„\")\n",
    "        print(f\"ì¤‘ê°„ê°’ ì‹œê°„ ì°¨ì´: {time_comparison['time_diff'].median():.1f}ì‹œê°„\")\n",
    "        \n",
    "        # ë™ì‹œì— ë°œìƒí•œ ë¹„ìœ¨ (1ì‹œê°„ ì´ë‚´)\n",
    "        simultaneous = (time_comparison['time_diff'].abs() <= 1).sum()\n",
    "        simultaneous_rate = simultaneous / len(time_comparison) * 100\n",
    "        \n",
    "        print(f\"\\nğŸ“Š 1ì‹œê°„ ì´ë‚´ ë™ì‹œ ì°¨ë‹¨: {simultaneous}ìŒ ({simultaneous_rate:.1f}%)\")\n",
    "        \n",
    "        if simultaneous_rate > 50:\n",
    "            print(\"âœ… ê°œë³„ íˆ¬í‘œ ì°¨ë‹¨ê³¼ ì‚¬ìš©ì ì°¨ë‹¨ì´ ê±°ì˜ ë™ì‹œì— ë°œìƒ\")\n",
    "            print(\"   â†’ ê°œë³„ íˆ¬í‘œ ì°¨ë‹¨ ì‹œ ìë™ìœ¼ë¡œ ì‚¬ìš©ì ì „ì²´ ì°¨ë‹¨ë˜ëŠ” ê²ƒìœ¼ë¡œ ì¶”ì •\")\n",
    "        else:\n",
    "            print(\"âš ï¸  ê°œë³„ íˆ¬í‘œ ì°¨ë‹¨ê³¼ ì‚¬ìš©ì ì°¨ë‹¨ì´ ì‹œê°„ì°¨ë¥¼ ë‘ê³  ë°œìƒ\")\n",
    "    else:\n",
    "        print(\"âŒ ë™ì¼ ì‚¬ìš©ì ìŒì˜ ì‹œê°„ ë¹„êµ ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f546823a",
   "metadata": {},
   "source": [
    "### ìµœì¢… ê²°ë¡ "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "ff0d50d5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ¯ ì°¨ë‹¨ ë©”ì»¤ë‹ˆì¦˜ ìµœì¢… ê²°ë¡ \n",
      "==================================================\n",
      "ğŸ“‹ ë¶„ì„ ê²°ê³¼ ìš”ì•½:\n",
      "â€¢ ê°œë³„ íˆ¬í‘œ ì°¨ë‹¨ ê±´ìˆ˜: 658ê±´\n",
      "â€¢ ê°œë³„ íˆ¬í‘œ ì°¨ë‹¨ ìŒ: 318ìŒ\n",
      "â€¢ ì‚¬ìš©ì ì „ì²´ ì°¨ë‹¨ ìŒ: 19,482ìŒ\n",
      "â€¢ ì¤‘ë³µë¥ : 15.4%\n",
      "\n",
      "âœ… ìµœì¢… ê²°ë¡ :\n",
      "ğŸ”„ ê°œë³„ íˆ¬í‘œ ì°¨ë‹¨ê³¼ ì‚¬ìš©ì ì°¨ë‹¨ì€ ë…ë¦½ì  ê¸°ëŠ¥\n",
      "   â€¢ íˆ¬í‘œë§Œ ì°¨ë‹¨í•˜ê³  ì‚¬ìš©ìëŠ” ì°¨ë‹¨í•˜ì§€ ì•Šì„ ìˆ˜ ìˆìŒ\n",
      "   â€¢ ë³„ë„ì˜ ì°¨ë‹¨ ì˜µì…˜ ì¡´ì¬\n"
     ]
    }
   ],
   "source": [
    "print(\"ğŸ¯ ì°¨ë‹¨ ë©”ì»¤ë‹ˆì¦˜ ìµœì¢… ê²°ë¡ \")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "# ë°ì´í„° ê¸°ë°˜ ê²°ë¡  ë„ì¶œ\n",
    "if 'status' in df_vote.columns:\n",
    "    blocked_votes = df_vote[df_vote['status'] == 'B']\n",
    "    \n",
    "    if len(blocked_votes) > 0:\n",
    "        # ì¤‘ë³µë¥  ì¬ê³„ì‚°\n",
    "        blocked_pairs = blocked_votes[['chosen_user_id', 'user_id']].drop_duplicates()\n",
    "        user_block_pairs = df_block[['user_id', 'block_user_id']].copy()\n",
    "        user_block_pairs.columns = ['chosen_user_id', 'user_id']\n",
    "        \n",
    "        merged = blocked_pairs.merge(user_block_pairs, on=['chosen_user_id', 'user_id'], how='inner')\n",
    "        overlap_rate = len(merged) / len(blocked_pairs) * 100 if len(blocked_pairs) > 0 else 0\n",
    "        \n",
    "        print(\"ğŸ“‹ ë¶„ì„ ê²°ê³¼ ìš”ì•½:\")\n",
    "        print(f\"â€¢ ê°œë³„ íˆ¬í‘œ ì°¨ë‹¨ ê±´ìˆ˜: {len(blocked_votes):,}ê±´\")\n",
    "        print(f\"â€¢ ê°œë³„ íˆ¬í‘œ ì°¨ë‹¨ ìŒ: {len(blocked_pairs):,}ìŒ\")\n",
    "        print(f\"â€¢ ì‚¬ìš©ì ì „ì²´ ì°¨ë‹¨ ìŒ: {len(user_block_pairs):,}ìŒ\")\n",
    "        print(f\"â€¢ ì¤‘ë³µë¥ : {overlap_rate:.1f}%\")\n",
    "        \n",
    "        print(f\"\\nâœ… ìµœì¢… ê²°ë¡ :\")\n",
    "        if overlap_rate > 80:\n",
    "            print(\"ğŸ”— ê°œë³„ íˆ¬í‘œ ì°¨ë‹¨ â†’ í•´ë‹¹ ì‚¬ìš©ì ì „ì²´ ìë™ ì°¨ë‹¨\")\n",
    "            print(\"   â€¢ ì‚¬ìš©ìê°€ íŠ¹ì • íˆ¬í‘œë¥¼ ì°¨ë‹¨í•˜ë©´\")\n",
    "            print(\"   â€¢ ê·¸ íˆ¬í‘œë¥¼ ë³´ë‚¸ ì‚¬ìš©ì ì „ì²´ê°€ ì°¨ë‹¨ë¨\")\n",
    "            print(\"   â€¢ ë‘ ê¸°ëŠ¥ì´ ì—°ë™ë˜ì–´ ì‘ë™\")\n",
    "        elif overlap_rate > 20:\n",
    "            print(\"ğŸ”€ ê°œë³„ íˆ¬í‘œ ì°¨ë‹¨ê³¼ ì‚¬ìš©ì ì°¨ë‹¨ì´ ë¶€ë¶„ì ìœ¼ë¡œ ì—°ë™\")\n",
    "            print(\"   â€¢ ì¼ë¶€ ê²½ìš°ì—ë§Œ ì—°ë™\")\n",
    "            print(\"   â€¢ ì‚¬ìš©ìê°€ ì„ íƒì ìœ¼ë¡œ ì „ì²´ ì°¨ë‹¨ ê²°ì •\")\n",
    "        else:\n",
    "            print(\"ğŸ”„ ê°œë³„ íˆ¬í‘œ ì°¨ë‹¨ê³¼ ì‚¬ìš©ì ì°¨ë‹¨ì€ ë…ë¦½ì  ê¸°ëŠ¥\")\n",
    "            print(\"   â€¢ íˆ¬í‘œë§Œ ì°¨ë‹¨í•˜ê³  ì‚¬ìš©ìëŠ” ì°¨ë‹¨í•˜ì§€ ì•Šì„ ìˆ˜ ìˆìŒ\")\n",
    "            print(\"   â€¢ ë³„ë„ì˜ ì°¨ë‹¨ ì˜µì…˜ ì¡´ì¬\")\n",
    "            \n",
    "    else:\n",
    "        print(\"âŒ ê°œë³„ íˆ¬í‘œ ì°¨ë‹¨ ë°ì´í„°ê°€ ì—†ì–´ ë¶„ì„ ë¶ˆê°€\")\n",
    "else:\n",
    "    print(\"âŒ íˆ¬í‘œ ìƒíƒœ ë°ì´í„°ê°€ ì—†ì–´ ë¶„ì„ ë¶ˆê°€\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca52bf5a",
   "metadata": {},
   "source": [
    "# ğŸ” ë°ì´í„° í’ˆì§ˆ ì •ì˜ - 1ë‹¨ê³„ (ì „ì²´ ë°ì´í„°ì…‹)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5783844f",
   "metadata": {},
   "source": [
    "## ğŸ“‹ 1ë‹¨ê³„: votes + hackle ì „ì²´ í…Œì´ë¸” ê²°ì¸¡ì¹˜ ì •ì˜"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "f447fd19",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ” 1ë‹¨ê³„: ì „ì²´ ë°ì´í„°ì…‹ ê²°ì¸¡ì¹˜ í˜„í™© ë¶„ì„\n",
      "======================================================================\n",
      "ğŸ“Š ë¶„ì„ ëŒ€ìƒ: votes 21ê°œ + hackle 4ê°œ = ì´ 25ê°œ í…Œì´ë¸”\n",
      "\n",
      "ğŸ—³ï¸  VOTES ë°ì´í„°ì…‹ ë¶„ì„\n",
      "==================================================\n",
      "\n",
      "ğŸ“‹ accounts_attendance (349,637í–‰ Ã— 3ì—´)\n",
      "   âœ… ê²°ì¸¡ì¹˜ ì—†ìŒ\n",
      "\n",
      "ğŸ“‹ accounts_blockrecord (19,482í–‰ Ã— 5ì—´)\n",
      "   âœ… ê²°ì¸¡ì¹˜ ì—†ìŒ\n",
      "\n",
      "ğŸ“‹ accounts_failpaymenthistory (163í–‰ Ã— 5ì—´)\n",
      "   â€¢ productId: 107ê°œ (65.6%)\n",
      "\n",
      "ğŸ“‹ accounts_friendrequest (17,147,175í–‰ Ã— 6ì—´)\n",
      "   âœ… ê²°ì¸¡ì¹˜ ì—†ìŒ\n",
      "\n",
      "ğŸ“‹ accounts_group (84,515í–‰ Ã— 4ì—´)\n",
      "   âœ… ê²°ì¸¡ì¹˜ ì—†ìŒ\n",
      "\n",
      "ğŸ“‹ accounts_nearbyschool (59,500í–‰ Ã— 4ì—´)\n",
      "   âœ… ê²°ì¸¡ì¹˜ ì—†ìŒ\n",
      "\n",
      "ğŸ“‹ accounts_paymenthistory (95,140í–‰ Ã— 5ì—´)\n",
      "   âœ… ê²°ì¸¡ì¹˜ ì—†ìŒ\n",
      "\n",
      "ğŸ“‹ accounts_user_contacts (5,063í–‰ Ã— 4ì—´)\n",
      "   âœ… ê²°ì¸¡ì¹˜ ì—†ìŒ\n",
      "\n",
      "ğŸ“‹ accounts_pointhistory (2,338,918í–‰ Ã— 5ì—´)\n",
      "   â€¢ user_question_record_id: 2,992ê°œ (0.1%)\n",
      "\n",
      "ğŸ“‹ accounts_school (5,951í–‰ Ã— 4ì—´)\n",
      "   âœ… ê²°ì¸¡ì¹˜ ì—†ìŒ\n",
      "\n",
      "ğŸ“‹ accounts_timelinereport (208í–‰ Ã— 6ì—´)\n",
      "   âœ… ê²°ì¸¡ì¹˜ ì—†ìŒ\n",
      "\n",
      "ğŸ“‹ accounts_user (677,085í–‰ Ã— 16ì—´)\n",
      "   â€¢ gender: 2ê°œ (0.0%)\n",
      "   â€¢ group_id: 3ê°œ (0.0%)\n",
      "\n",
      "ğŸ“‹ accounts_userquestionrecord (1,217,558í–‰ Ã— 12ì—´)\n",
      "   âœ… ê²°ì¸¡ì¹˜ ì—†ìŒ\n",
      "\n",
      "ğŸ“‹ accounts_userwithdraw (70,764í–‰ Ã— 3ì—´)\n",
      "   âœ… ê²°ì¸¡ì¹˜ ì—†ìŒ\n",
      "\n",
      "ğŸ“‹ event_receipts (309í–‰ Ã— 5ì—´)\n",
      "   âœ… ê²°ì¸¡ì¹˜ ì—†ìŒ\n",
      "\n",
      "ğŸ“‹ events (3í–‰ Ã— 6ì—´)\n",
      "   âœ… ê²°ì¸¡ì¹˜ ì—†ìŒ\n",
      "\n",
      "ğŸ“‹ polls_question (5,025í–‰ Ã— 3ì—´)\n",
      "   âœ… ê²°ì¸¡ì¹˜ ì—†ìŒ\n",
      "\n",
      "ğŸ“‹ polls_questionpiece (1,265,476í–‰ Ã— 5ì—´)\n",
      "   âœ… ê²°ì¸¡ì¹˜ ì—†ìŒ\n",
      "\n",
      "ğŸ“‹ polls_questionreport (51,424í–‰ Ã— 5ì—´)\n",
      "   âœ… ê²°ì¸¡ì¹˜ ì—†ìŒ\n",
      "\n",
      "ğŸ“‹ polls_questionset (158,384í–‰ Ã— 6ì—´)\n",
      "   âœ… ê²°ì¸¡ì¹˜ ì—†ìŒ\n",
      "\n",
      "ğŸ“‹ polls_usercandidate (4,769,609í–‰ Ã— 4ì—´)\n",
      "   âœ… ê²°ì¸¡ì¹˜ ì—†ìŒ\n",
      "\n",
      "ğŸ“± HACKLE ë°ì´í„°ì…‹ ë¶„ì„\n",
      "==================================================\n",
      "\n",
      "ğŸ“‹ hackle_properties (525,350í–‰ Ã— 8ì—´)\n",
      "   âœ… ê²°ì¸¡ì¹˜ ì—†ìŒ\n",
      "\n",
      "ğŸ“‹ device_properties (252,380í–‰ Ã— 4ì—´)\n",
      "   âœ… ê²°ì¸¡ì¹˜ ì—†ìŒ\n",
      "\n",
      "ğŸ“‹ hackle_events (11,441,319í–‰ Ã— 11ì—´)\n",
      "   â€¢ friend_count: 752,556ê°œ (6.6%)\n",
      "   â€¢ votes_count: 754,554ê°œ (6.6%)\n",
      "   â€¢ heart_balance: 728,643ê°œ (6.4%)\n",
      "   â€¢ question_id: 10,991,835ê°œ (96.1%)\n",
      "\n",
      "ğŸ“‹ user_properties (230,819í–‰ Ã— 5ì—´)\n",
      "   âœ… ê²°ì¸¡ì¹˜ ì—†ìŒ\n",
      "\n",
      "======================================================================\n",
      "ğŸ“Š ê²°ì¸¡ì¹˜ ì „ì²´ ìš”ì•½\n",
      "======================================================================\n",
      "ğŸ”´ ê²°ì¸¡ì¹˜ ë¹„ìœ¨ TOP 15:\n",
      "â€¢ [hackle] hackle_events.question_id: 96.1% (10,991,835/11,441,319)\n",
      "â€¢ [votes] accounts_failpaymenthistory.productId: 65.6% (107/163)\n",
      "â€¢ [hackle] hackle_events.votes_count: 6.6% (754,554/11,441,319)\n",
      "â€¢ [hackle] hackle_events.friend_count: 6.6% (752,556/11,441,319)\n",
      "â€¢ [hackle] hackle_events.heart_balance: 6.4% (728,643/11,441,319)\n",
      "â€¢ [votes] accounts_pointhistory.user_question_record_id: 0.1% (2,992/2,338,918)\n",
      "â€¢ [votes] accounts_user.group_id: 0.0% (3/677,085)\n",
      "â€¢ [votes] accounts_user.gender: 0.0% (2/677,085)\n",
      "\n",
      "ğŸ“‹ ë°ì´í„°ì…‹ë³„ ê²°ì¸¡ì¹˜ í˜„í™©:\n",
      "â€¢ hackle: 1ê°œ í…Œì´ë¸”ì—ì„œ ì´ 13,227,588ê°œ ê²°ì¸¡ì¹˜\n",
      "â€¢ votes: 3ê°œ í…Œì´ë¸”ì—ì„œ ì´ 3,104ê°œ ê²°ì¸¡ì¹˜\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# votes í…Œì´ë¸” ëª©ë¡ (21ê°œ)\n",
    "votes_tables = [\n",
    "    'accounts_attendance', 'accounts_blockrecord', 'accounts_failpaymenthistory',\n",
    "    'accounts_friendrequest', 'accounts_group', 'accounts_nearbyschool', \n",
    "    'accounts_paymenthistory', 'accounts_user_contacts', 'accounts_pointhistory',\n",
    "    'accounts_school', 'accounts_timelinereport', 'accounts_user',\n",
    "    'accounts_userquestionrecord', 'accounts_userwithdraw', 'event_receipts',\n",
    "    'events', 'polls_question', 'polls_questionpiece', 'polls_questionreport',\n",
    "    'polls_questionset', 'polls_usercandidate'\n",
    "]\n",
    "\n",
    "# hackle í…Œì´ë¸” ëª©ë¡ (4ê°œ)\n",
    "hackle_tables = [\n",
    "    'hackle_properties', 'device_properties', 'hackle_events', 'user_properties'\n",
    "]\n",
    "\n",
    "print(\"ğŸ” 1ë‹¨ê³„: ì „ì²´ ë°ì´í„°ì…‹ ê²°ì¸¡ì¹˜ í˜„í™© ë¶„ì„\")\n",
    "print(\"=\" * 70)\n",
    "print(f\"ğŸ“Š ë¶„ì„ ëŒ€ìƒ: votes {len(votes_tables)}ê°œ + hackle {len(hackle_tables)}ê°œ = ì´ {len(votes_tables + hackle_tables)}ê°œ í…Œì´ë¸”\")\n",
    "\n",
    "# ëª¨ë“  í…Œì´ë¸”ì˜ ê²°ì¸¡ì¹˜ í˜„í™© ìˆ˜ì§‘\n",
    "missing_summary = []\n",
    "\n",
    "# votes í…Œì´ë¸” ë¶„ì„\n",
    "print(f\"\\nğŸ—³ï¸  VOTES ë°ì´í„°ì…‹ ë¶„ì„\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "for table_name in votes_tables:\n",
    "    try:\n",
    "        df = pd.read_parquet(f\"gs://sprintda05_final_project/votes/{table_name}.parquet\")\n",
    "        \n",
    "        print(f\"\\nğŸ“‹ {table_name} ({df.shape[0]:,}í–‰ Ã— {df.shape[1]}ì—´)\")\n",
    "        \n",
    "        # ê²°ì¸¡ì¹˜ ê³„ì‚°\n",
    "        nulls = df.isnull().sum()\n",
    "        total_rows = len(df)\n",
    "        \n",
    "        # ê²°ì¸¡ì¹˜ê°€ ìˆëŠ” ì»¬ëŸ¼ë§Œ ì¶œë ¥\n",
    "        has_nulls = False\n",
    "        for col, null_count in nulls.items():\n",
    "            if null_count > 0:\n",
    "                null_pct = (null_count / total_rows) * 100\n",
    "                print(f\"   â€¢ {col}: {null_count:,}ê°œ ({null_pct:.1f}%)\")\n",
    "                has_nulls = True\n",
    "                \n",
    "                missing_summary.append({\n",
    "                    'dataset': 'votes',\n",
    "                    'table': table_name,\n",
    "                    'column': col,\n",
    "                    'missing_count': null_count,\n",
    "                    'missing_pct': null_pct,\n",
    "                    'total_rows': total_rows\n",
    "                })\n",
    "        \n",
    "        if not has_nulls:\n",
    "            print(\"   âœ… ê²°ì¸¡ì¹˜ ì—†ìŒ\")\n",
    "            \n",
    "    except Exception as e:\n",
    "        print(f\"   âŒ ë¡œë“œ ì‹¤íŒ¨: {str(e)[:30]}...\")\n",
    "\n",
    "# hackle í…Œì´ë¸” ë¶„ì„  \n",
    "print(f\"\\nğŸ“± HACKLE ë°ì´í„°ì…‹ ë¶„ì„\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "for table_name in hackle_tables:\n",
    "    try:\n",
    "        df = pd.read_parquet(f\"gs://sprintda05_final_project/hackle/{table_name}.parquet\")\n",
    "        \n",
    "        print(f\"\\nğŸ“‹ {table_name} ({df.shape[0]:,}í–‰ Ã— {df.shape[1]}ì—´)\")\n",
    "        \n",
    "        # ê²°ì¸¡ì¹˜ ê³„ì‚°\n",
    "        nulls = df.isnull().sum()\n",
    "        total_rows = len(df)\n",
    "        \n",
    "        # ê²°ì¸¡ì¹˜ê°€ ìˆëŠ” ì»¬ëŸ¼ë§Œ ì¶œë ¥\n",
    "        has_nulls = False\n",
    "        for col, null_count in nulls.items():\n",
    "            if null_count > 0:\n",
    "                null_pct = (null_count / total_rows) * 100\n",
    "                print(f\"   â€¢ {col}: {null_count:,}ê°œ ({null_pct:.1f}%)\")\n",
    "                has_nulls = True\n",
    "                \n",
    "                missing_summary.append({\n",
    "                    'dataset': 'hackle',\n",
    "                    'table': table_name,\n",
    "                    'column': col,\n",
    "                    'missing_count': null_count,\n",
    "                    'missing_pct': null_pct,\n",
    "                    'total_rows': total_rows\n",
    "                })\n",
    "        \n",
    "        if not has_nulls:\n",
    "            print(\"   âœ… ê²°ì¸¡ì¹˜ ì—†ìŒ\")\n",
    "            \n",
    "    except Exception as e:\n",
    "        print(f\"   âŒ ë¡œë“œ ì‹¤íŒ¨: {str(e)[:30]}...\")\n",
    "\n",
    "# ì „ì²´ ìš”ì•½\n",
    "print(f\"\\n\" + \"=\" * 70)\n",
    "print(\"ğŸ“Š ê²°ì¸¡ì¹˜ ì „ì²´ ìš”ì•½\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "if missing_summary:\n",
    "    missing_df = pd.DataFrame(missing_summary)\n",
    "    \n",
    "    # ê²°ì¸¡ì¹˜ ë¹„ìœ¨ì´ ë†’ì€ ìˆœìœ¼ë¡œ ì •ë ¬\n",
    "    print(\"ğŸ”´ ê²°ì¸¡ì¹˜ ë¹„ìœ¨ TOP 15:\")\n",
    "    top_missing = missing_df.nlargest(15, 'missing_pct')\n",
    "    \n",
    "    for _, row in top_missing.iterrows():\n",
    "        print(f\"â€¢ [{row['dataset']}] {row['table']}.{row['column']}: {row['missing_pct']:.1f}% ({row['missing_count']:,}/{row['total_rows']:,})\")\n",
    "    \n",
    "    # ë°ì´í„°ì…‹ë³„ ìš”ì•½\n",
    "    print(f\"\\nğŸ“‹ ë°ì´í„°ì…‹ë³„ ê²°ì¸¡ì¹˜ í˜„í™©:\")\n",
    "    dataset_summary = missing_df.groupby('dataset').agg({\n",
    "        'missing_count': 'sum',\n",
    "        'table': 'nunique'\n",
    "    }).reset_index()\n",
    "    \n",
    "    for _, row in dataset_summary.iterrows():\n",
    "        print(f\"â€¢ {row['dataset']}: {row['table']}ê°œ í…Œì´ë¸”ì—ì„œ ì´ {row['missing_count']:,}ê°œ ê²°ì¸¡ì¹˜\")\n",
    "        \n",
    "else:\n",
    "    print(\"âœ… ëª¨ë“  í…Œì´ë¸”ì— ê²°ì¸¡ì¹˜ ì—†ìŒ!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d562e65",
   "metadata": {},
   "source": [
    "### ê²°ì¸¡ì¹˜ íŒ¨í„´ ìƒì„¸ ë¶„ì„"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "f96582ce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ” ê²°ì¸¡ì¹˜ ì˜ë¯¸ ìƒì„¸ ë¶„ì„\n",
      "==================================================\n",
      "ğŸ“± hackle_events.question_id ê²°ì¸¡ íŒ¨í„´:\n",
      "â€¢ ì „ì²´ ì´ë²¤íŠ¸: 11,441,319ê±´\n",
      "â€¢ question_id ìˆìŒ: 449,484ê±´ (3.9%)\n",
      "â€¢ question_id ì—†ìŒ: 10,991,835ê±´ (96.1%)\n",
      "\n",
      "ğŸ“Š question_idê°€ ìˆëŠ” ì´ë²¤íŠ¸ íƒ€ì…:\n",
      "â€¢ skip_question: 449,484ê±´\n",
      "\n",
      "ğŸ“Š question_idê°€ ì—†ëŠ” ì´ë²¤íŠ¸ íƒ€ì… (ìƒìœ„ 10ê°œ):\n",
      "â€¢ view_lab_tap: 1,266,665ê±´\n",
      "â€¢ view_timeline_tap: 1,194,508ê±´\n",
      "â€¢ $session_start: 1,036,852ê±´\n",
      "â€¢ launch_app: 986,388ê±´\n",
      "â€¢ click_question_open: 816,801ê±´\n",
      "â€¢ click_bottom_navigation_questions: 769,163ê±´\n",
      "â€¢ click_bottom_navigation_profile: 653,507ê±´\n",
      "â€¢ $session_end: 649,658ê±´\n",
      "â€¢ click_bottom_navigation_timeline: 536,051ê±´\n",
      "â€¢ click_bottom_navigation_lab: 453,683ê±´\n",
      "\n",
      "ğŸ’³ accounts_failpaymenthistory.productId ê²°ì¸¡ íŒ¨í„´:\n",
      "â€¢ ì „ì²´ ì‹¤íŒ¨ ê¸°ë¡: 163ê±´\n",
      "â€¢ productId ìˆìŒ: 56ê±´\n",
      "â€¢ productId ì—†ìŒ: 107ê±´\n",
      "\n",
      "ğŸ“± í”Œë«í¼ë³„ productId ê²°ì¸¡:\n",
      "â€¢ A: 0/56 (0.0%)\n",
      "â€¢ I: 107/107 (100.0%)\n"
     ]
    }
   ],
   "source": [
    "# ê²°ì¸¡ì¹˜ íŒ¨í„´ ìƒì„¸ ë¶„ì„\n",
    "print(\"ğŸ” ê²°ì¸¡ì¹˜ ì˜ë¯¸ ìƒì„¸ ë¶„ì„\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "# 1. hackle_eventsì˜ question_id ê²°ì¸¡ íŒ¨í„´\n",
    "df_events = pd.read_parquet(\"gs://sprintda05_final_project/hackle/hackle_events.parquet\")\n",
    "\n",
    "print(\"ğŸ“± hackle_events.question_id ê²°ì¸¡ íŒ¨í„´:\")\n",
    "question_null = df_events['question_id'].isnull()\n",
    "print(f\"â€¢ ì „ì²´ ì´ë²¤íŠ¸: {len(df_events):,}ê±´\")\n",
    "print(f\"â€¢ question_id ìˆìŒ: {(~question_null).sum():,}ê±´ ({(~question_null).mean()*100:.1f}%)\")\n",
    "print(f\"â€¢ question_id ì—†ìŒ: {question_null.sum():,}ê±´ ({question_null.mean()*100:.1f}%)\")\n",
    "\n",
    "# question_idê°€ ìˆëŠ” ì´ë²¤íŠ¸ íƒ€ì…ë“¤\n",
    "events_with_questions = df_events[~question_null]['event_key'].value_counts()\n",
    "print(f\"\\nğŸ“Š question_idê°€ ìˆëŠ” ì´ë²¤íŠ¸ íƒ€ì…:\")\n",
    "for event, count in events_with_questions.head(10).items():\n",
    "    print(f\"â€¢ {event}: {count:,}ê±´\")\n",
    "\n",
    "# question_idê°€ ì—†ëŠ” ì´ë²¤íŠ¸ íƒ€ì…ë“¤  \n",
    "events_without_questions = df_events[question_null]['event_key'].value_counts() \n",
    "print(f\"\\nğŸ“Š question_idê°€ ì—†ëŠ” ì´ë²¤íŠ¸ íƒ€ì… (ìƒìœ„ 10ê°œ):\")\n",
    "for event, count in events_without_questions.head(10).items():\n",
    "    print(f\"â€¢ {event}: {count:,}ê±´\")\n",
    "\n",
    "# 2. ê²°ì œ ì‹¤íŒ¨ productId ê²°ì¸¡ íŒ¨í„´\n",
    "df_fail = pd.read_parquet(\"gs://sprintda05_final_project/votes/accounts_failpaymenthistory.parquet\")\n",
    "\n",
    "print(f\"\\nğŸ’³ accounts_failpaymenthistory.productId ê²°ì¸¡ íŒ¨í„´:\")\n",
    "print(f\"â€¢ ì „ì²´ ì‹¤íŒ¨ ê¸°ë¡: {len(df_fail):,}ê±´\")\n",
    "print(f\"â€¢ productId ìˆìŒ: {df_fail['productId'].notna().sum():,}ê±´\")\n",
    "print(f\"â€¢ productId ì—†ìŒ: {df_fail['productId'].isna().sum():,}ê±´\")\n",
    "\n",
    "# í”Œë«í¼ë³„ ê²°ì¸¡ íŒ¨í„´\n",
    "platform_missing = df_fail.groupby('phone_type')['productId'].apply(lambda x: x.isna().sum())\n",
    "platform_total = df_fail.groupby('phone_type').size()\n",
    "\n",
    "print(f\"\\nğŸ“± í”Œë«í¼ë³„ productId ê²°ì¸¡:\")\n",
    "for platform in platform_missing.index:\n",
    "    missing = platform_missing[platform] \n",
    "    total = platform_total[platform]\n",
    "    pct = (missing / total) * 100\n",
    "    print(f\"â€¢ {platform}: {missing}/{total} ({pct:.1f}%)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f55425c4",
   "metadata": {},
   "source": [
    "## ì¤‘ë³µê°’ í˜„í™© íŒŒì•…"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "38951573",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ” 2ë‹¨ê³„: ì¤‘ë³µê°’ í˜„í™© ë¶„ì„\n",
      "==================================================\n",
      "\n",
      "ğŸ“‹ accounts_user ì¤‘ë³µ ë¶„ì„ (677,085í–‰)\n",
      "----------------------------------------\n",
      "â€¢ ì™„ì „ ì¤‘ë³µ í–‰: 0ê°œ (0.00%)\n",
      "â€¢ ID ì¤‘ë³µ: 0ê°œ\n",
      "\n",
      "ğŸ“‹ accounts_userquestionrecord ì¤‘ë³µ ë¶„ì„ (1,217,558í–‰)\n",
      "----------------------------------------\n",
      "â€¢ ì™„ì „ ì¤‘ë³µ í–‰: 0ê°œ (0.00%)\n",
      "â€¢ (ì‚¬ìš©ì, ì§ˆë¬¸) ì¤‘ë³µ íˆ¬í‘œ: 0ê°œ\n",
      "\n",
      "ğŸ“‹ accounts_blockrecord ì¤‘ë³µ ë¶„ì„ (19,482í–‰)\n",
      "----------------------------------------\n",
      "â€¢ ì™„ì „ ì¤‘ë³µ í–‰: 0ê°œ (0.00%)\n",
      "â€¢ (ì°¨ë‹¨ì, í”¼ì°¨ë‹¨ì) ì¤‘ë³µ: 977ê°œ\n",
      "\n",
      "ğŸ“‹ accounts_friendrequest ì¤‘ë³µ ë¶„ì„ (17,147,175í–‰)\n",
      "----------------------------------------\n",
      "â€¢ ì™„ì „ ì¤‘ë³µ í–‰: 0ê°œ (0.00%)\n",
      "\n",
      "ğŸ“‹ polls_question ì¤‘ë³µ ë¶„ì„ (5,025í–‰)\n",
      "----------------------------------------\n",
      "â€¢ ì™„ì „ ì¤‘ë³µ í–‰: 0ê°œ (0.00%)\n",
      "â€¢ ë™ì¼ ì§ˆë¬¸ í…ìŠ¤íŠ¸ ì¤‘ë³µ: 1,122ê°œ\n",
      "\n",
      "ğŸ“‹ hackle_events ì¤‘ë³µ ë¶„ì„ (11,441,319í–‰)\n",
      "----------------------------------------\n",
      "â€¢ ì™„ì „ ì¤‘ë³µ í–‰: 0ê°œ (0.00%)\n",
      "â€¢ (ì„¸ì…˜, ì‹œê°„, ì´ë²¤íŠ¸) ì¤‘ë³µ: 195,860ê°œ\n",
      "\n",
      "==================================================\n",
      "ğŸ“Š ì¤‘ë³µê°’ ìš”ì•½\n",
      "==================================================\n",
      "ğŸ”´ ì¤‘ë³µ ë¹„ìœ¨ ìˆœ:\n",
      "â€¢ accounts_user: ì¤‘ë³µ ì—†ìŒ\n",
      "â€¢ accounts_userquestionrecord: ì¤‘ë³µ ì—†ìŒ\n",
      "â€¢ accounts_blockrecord: ì¤‘ë³µ ì—†ìŒ\n",
      "â€¢ accounts_friendrequest: ì¤‘ë³µ ì—†ìŒ\n",
      "â€¢ polls_question: ì¤‘ë³µ ì—†ìŒ\n",
      "â€¢ hackle_events: ì¤‘ë³µ ì—†ìŒ\n"
     ]
    }
   ],
   "source": [
    "print(\"ğŸ” 2ë‹¨ê³„: ì¤‘ë³µê°’ í˜„í™© ë¶„ì„\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "# ì£¼ìš” í…Œì´ë¸”ë“¤ì˜ ì¤‘ë³µ íŒ¨í„´ í™•ì¸\n",
    "tables_to_check = [\n",
    "    'accounts_user', 'accounts_userquestionrecord', 'accounts_blockrecord',\n",
    "    'accounts_friendrequest', 'polls_question', 'hackle_events'\n",
    "]\n",
    "\n",
    "duplicate_summary = []\n",
    "\n",
    "for table_name in tables_to_check:\n",
    "    try:\n",
    "        if table_name in ['hackle_events', 'hackle_properties', 'device_properties', 'user_properties']:\n",
    "            df = pd.read_parquet(f\"gs://sprintda05_final_project/hackle/{table_name}.parquet\")\n",
    "        else:\n",
    "            df = pd.read_parquet(f\"gs://sprintda05_final_project/votes/{table_name}.parquet\")\n",
    "        \n",
    "        print(f\"\\nğŸ“‹ {table_name} ì¤‘ë³µ ë¶„ì„ ({df.shape[0]:,}í–‰)\")\n",
    "        print(\"-\" * 40)\n",
    "        \n",
    "        # 1. ì „ì²´ í–‰ ì¤‘ë³µ\n",
    "        total_duplicates = df.duplicated().sum()\n",
    "        duplicate_pct = (total_duplicates / len(df)) * 100\n",
    "        print(f\"â€¢ ì™„ì „ ì¤‘ë³µ í–‰: {total_duplicates:,}ê°œ ({duplicate_pct:.2f}%)\")\n",
    "        \n",
    "        # 2. í•µì‹¬ ì»¬ëŸ¼ë³„ ì¤‘ë³µ (í…Œì´ë¸”ë³„ë¡œ ë‹¤ë¥´ê²Œ)\n",
    "        if table_name == 'accounts_user':\n",
    "            # ì‚¬ìš©ì í…Œì´ë¸”: ID ì¤‘ë³µ í™•ì¸\n",
    "            id_duplicates = df['id'].duplicated().sum()\n",
    "            print(f\"â€¢ ID ì¤‘ë³µ: {id_duplicates:,}ê°œ\")\n",
    "            \n",
    "        elif table_name == 'accounts_userquestionrecord':\n",
    "            # íˆ¬í‘œ ê¸°ë¡: ë™ì¼ ì‚¬ìš©ìê°€ ë™ì¼ ì§ˆë¬¸ì— ì—¬ëŸ¬ íˆ¬í‘œ\n",
    "            vote_duplicates = df.duplicated(subset=['user_id', 'question_piece_id']).sum()\n",
    "            print(f\"â€¢ (ì‚¬ìš©ì, ì§ˆë¬¸) ì¤‘ë³µ íˆ¬í‘œ: {vote_duplicates:,}ê°œ\")\n",
    "            \n",
    "        elif table_name == 'accounts_blockrecord':\n",
    "            # ì°¨ë‹¨ ê¸°ë¡: ë™ì¼ ì°¨ë‹¨ ìŒ\n",
    "            block_duplicates = df.duplicated(subset=['user_id', 'block_user_id']).sum()\n",
    "            print(f\"â€¢ (ì°¨ë‹¨ì, í”¼ì°¨ë‹¨ì) ì¤‘ë³µ: {block_duplicates:,}ê°œ\")\n",
    "            \n",
    "        elif table_name == 'polls_question':\n",
    "            # ì§ˆë¬¸: ë™ì¼ í…ìŠ¤íŠ¸ ì¤‘ë³µ\n",
    "            text_duplicates = df.duplicated(subset=['question_text']).sum()\n",
    "            print(f\"â€¢ ë™ì¼ ì§ˆë¬¸ í…ìŠ¤íŠ¸ ì¤‘ë³µ: {text_duplicates:,}ê°œ\")\n",
    "            \n",
    "        elif table_name == 'hackle_events':\n",
    "            # ì´ë²¤íŠ¸: ë™ì¼ ì„¸ì…˜+ì‹œê°„ ì¤‘ë³µ\n",
    "            event_duplicates = df.duplicated(subset=['session_id', 'event_datetime', 'event_key']).sum()\n",
    "            print(f\"â€¢ (ì„¸ì…˜, ì‹œê°„, ì´ë²¤íŠ¸) ì¤‘ë³µ: {event_duplicates:,}ê°œ\")\n",
    "            \n",
    "            # ì™„ì „ ë™ì¼í•œ ì´ë²¤íŠ¸ (ëª¨ë“  ì»¬ëŸ¼)\n",
    "            if total_duplicates > 0:\n",
    "                print(f\"â€¢ ì™„ì „ ë™ì¼ ì´ë²¤íŠ¸: {total_duplicates:,}ê°œ\")\n",
    "        \n",
    "        # ìš”ì•½ ì •ë³´ ì €ì¥\n",
    "        duplicate_summary.append({\n",
    "            'table': table_name,\n",
    "            'total_rows': len(df),\n",
    "            'duplicate_rows': total_duplicates,\n",
    "            'duplicate_pct': duplicate_pct\n",
    "        })\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"âŒ {table_name} ë¶„ì„ ì‹¤íŒ¨: {str(e)[:50]}...\")\n",
    "\n",
    "# ì „ì²´ ìš”ì•½\n",
    "print(f\"\\n\" + \"=\" * 50)\n",
    "print(\"ğŸ“Š ì¤‘ë³µê°’ ìš”ì•½\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "if duplicate_summary:\n",
    "    duplicate_df = pd.DataFrame(duplicate_summary)\n",
    "    duplicate_df = duplicate_df.sort_values('duplicate_pct', ascending=False)\n",
    "    \n",
    "    print(\"ğŸ”´ ì¤‘ë³µ ë¹„ìœ¨ ìˆœ:\")\n",
    "    for _, row in duplicate_df.iterrows():\n",
    "        if row['duplicate_rows'] > 0:\n",
    "            print(f\"â€¢ {row['table']}: {row['duplicate_pct']:.3f}% ({row['duplicate_rows']:,}/{row['total_rows']:,})\")\n",
    "        else:\n",
    "            print(f\"â€¢ {row['table']}: ì¤‘ë³µ ì—†ìŒ\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71e2aad7",
   "metadata": {},
   "source": [
    "## 3ë‹¨ê³„: ë°ì´í„° ì¼ê´€ì„±(Data Consistency) ì •ì˜"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2bf4e7cd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ” 3ë‹¨ê³„: ì „ì²´ ë°ì´í„° ë©”ëª¨ë¦¬ íš¨ìœ¨ì  ì¼ê´€ì„± ë¶„ì„\n",
      "============================================================\n",
      "ğŸ“¥ 1ë‹¨ê³„: ì°¸ì¡° ê¸°ì¤€ ë°ì´í„° ë¡œë“œ\n",
      "----------------------------------------\n",
      "âœ… ì‚¬ìš©ì ID ì§‘í•©: 677,085ê°œ\n",
      "âœ… ì§ˆë¬¸ ID ì§‘í•©: 5,025ê°œ\n",
      "\n",
      "ğŸ”— 2ë‹¨ê³„: ì°¸ì¡° ë¬´ê²°ì„± ê²€ì‚¬\n",
      "----------------------------------------\n",
      "â€¢ íˆ¬í‘œ ê¸°ë¡ ì°¸ì¡° ë¬´ê²°ì„± ê²€ì‚¬ ì¤‘...\n",
      "  - ì´ íˆ¬í‘œ ê¸°ë¡: 1,217,558ê±´\n",
      "    ì§„í–‰: 500,000/1,217,558 (41.1%)\n",
      "    ì§„í–‰: 1,000,000/1,217,558 (82.1%)\n",
      "  âœ… íˆ¬í‘œ ê¸°ë¡ ê²€ì‚¬ ì™„ë£Œ\n",
      "    - ì‚¬ìš©ì ì°¸ì¡° ì˜¤ë¥˜: 0ê°œ\n",
      "    - ì§ˆë¬¸ ì°¸ì¡° ì˜¤ë¥˜: 0ê°œ\n",
      "\n",
      "â€¢ ì°¨ë‹¨ ê¸°ë¡ ì°¸ì¡° ë¬´ê²°ì„± ê²€ì‚¬...\n",
      "  âœ… ì°¨ë‹¨ ê¸°ë¡ ê²€ì‚¬ ì™„ë£Œ\n",
      "    - ì´ ì°¨ë‹¨ ê¸°ë¡: 19,482ê±´\n",
      "    - ì‚¬ìš©ì ì°¸ì¡° ì˜¤ë¥˜: 0ê°œ\n",
      "\n",
      "ğŸ“Š 3ë‹¨ê³„: ì‹œê°„ ë°ì´í„° ì¼ê´€ì„±\n",
      "----------------------------------------\n",
      "â€¢ ì‚¬ìš©ì ê°€ì… ê¸°ê°„: 2023-03-29 03:44:14.047130 ~ 2024-05-09 08:31:17.710824\n",
      "â€¢ ë¯¸ë˜ ë‚ ì§œ: 0ê°œ\n",
      "â€¢ í¬ì¸íŠ¸ ë²”ìœ„: 0 ~ 885000006\n",
      "â€¢ ìŒìˆ˜ í¬ì¸íŠ¸ ì‚¬ìš©ì: 0ëª…\n",
      "\n",
      "============================================================\n",
      "ğŸ“‹ ì „ì²´ ë°ì´í„° ì¼ê´€ì„± ê²€ì‚¬ ê²°ê³¼\n",
      "============================================================\n",
      "âœ… ì£¼ìš” ì¼ê´€ì„± ë¬¸ì œ ì—†ìŒ\n",
      "\n",
      "ğŸ’¾ ë©”ëª¨ë¦¬ íš¨ìœ¨ì  ì²˜ë¦¬ ì™„ë£Œ!\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import gc  # ê°€ë¹„ì§€ ì»¬ë ‰ì…˜\n",
    "\n",
    "print(\"ğŸ” 3ë‹¨ê³„: ì „ì²´ ë°ì´í„° ë©”ëª¨ë¦¬ íš¨ìœ¨ì  ì¼ê´€ì„± ë¶„ì„\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# 1. ì‘ì€ í…Œì´ë¸”ë¶€í„° ì²˜ë¦¬í•˜ì—¬ ì°¸ì¡° ê¸°ì¤€ ìƒì„±\n",
    "print(\"ğŸ“¥ 1ë‹¨ê³„: ì°¸ì¡° ê¸°ì¤€ ë°ì´í„° ë¡œë“œ\")\n",
    "print(\"-\" * 40)\n",
    "\n",
    "# ì‚¬ìš©ì ID ì§‘í•© ìƒì„±\n",
    "user_ids = pd.read_parquet(\n",
    "    \"gs://sprintda05_final_project/votes/accounts_user.parquet\",\n",
    "    columns=['id']\n",
    ")['id'].values\n",
    "existing_users = set(user_ids)\n",
    "del user_ids\n",
    "gc.collect()\n",
    "print(f\"âœ… ì‚¬ìš©ì ID ì§‘í•©: {len(existing_users):,}ê°œ\")\n",
    "\n",
    "# ì§ˆë¬¸ ID ì§‘í•© ìƒì„±\n",
    "question_ids = pd.read_parquet(\n",
    "    \"gs://sprintda05_final_project/votes/polls_question.parquet\",\n",
    "    columns=['id']\n",
    ")['id'].values\n",
    "existing_questions = set(question_ids)\n",
    "del question_ids\n",
    "gc.collect()\n",
    "print(f\"âœ… ì§ˆë¬¸ ID ì§‘í•©: {len(existing_questions):,}ê°œ\")\n",
    "\n",
    "print(f\"\\nğŸ”— 2ë‹¨ê³„: ì°¸ì¡° ë¬´ê²°ì„± ê²€ì‚¬\")\n",
    "print(\"-\" * 40)\n",
    "\n",
    "# íˆ¬í‘œ ê¸°ë¡ - ì²­í¬ ë‹¨ìœ„ë¡œ ì²˜ë¦¬\n",
    "print(\"â€¢ íˆ¬í‘œ ê¸°ë¡ ì°¸ì¡° ë¬´ê²°ì„± ê²€ì‚¬ ì¤‘...\")\n",
    "vote_user_errors = 0\n",
    "vote_question_errors = 0\n",
    "total_vote_records = 0\n",
    "\n",
    "# ì²­í¬ í¬ê¸°ë¥¼ ì‘ê²Œ ì„¤ì •\n",
    "chunk_size = 50000\n",
    "\n",
    "# íŒŒì¼ì„ ì²­í¬ë¡œ ì½ê¸°\n",
    "vote_file = \"gs://sprintda05_final_project/votes/accounts_userquestionrecord.parquet\"\n",
    "parquet_file = pd.read_parquet(vote_file)\n",
    "\n",
    "# ì „ì²´ í–‰ ìˆ˜ í™•ì¸\n",
    "total_vote_records = len(parquet_file)\n",
    "print(f\"  - ì´ íˆ¬í‘œ ê¸°ë¡: {total_vote_records:,}ê±´\")\n",
    "\n",
    "# ì²­í¬ ë‹¨ìœ„ë¡œ ì²˜ë¦¬\n",
    "for i in range(0, len(parquet_file), chunk_size):\n",
    "    chunk = parquet_file.iloc[i:i+chunk_size]\n",
    "    \n",
    "    # ì‚¬ìš©ì ì°¸ì¡° í™•ì¸\n",
    "    chunk_users = set(chunk['user_id'].values) | set(chunk['chosen_user_id'].values)\n",
    "    orphaned_users = chunk_users - existing_users\n",
    "    vote_user_errors += len(orphaned_users)\n",
    "    \n",
    "    # ì§ˆë¬¸ ì°¸ì¡° í™•ì¸\n",
    "    chunk_questions = set(chunk['question_id'].values)\n",
    "    orphaned_questions = chunk_questions - existing_questions\n",
    "    vote_question_errors += len(orphaned_questions)\n",
    "    \n",
    "    # ì§„í–‰ìƒí™© ì¶œë ¥\n",
    "    processed = min(i + chunk_size, len(parquet_file))\n",
    "    if processed % (chunk_size * 10) == 0:  # 10ì²­í¬ë§ˆë‹¤ ì¶œë ¥\n",
    "        print(f\"    ì§„í–‰: {processed:,}/{total_vote_records:,} ({processed/total_vote_records*100:.1f}%)\")\n",
    "\n",
    "del parquet_file\n",
    "gc.collect()\n",
    "\n",
    "print(f\"  âœ… íˆ¬í‘œ ê¸°ë¡ ê²€ì‚¬ ì™„ë£Œ\")\n",
    "print(f\"    - ì‚¬ìš©ì ì°¸ì¡° ì˜¤ë¥˜: {vote_user_errors:,}ê°œ\")\n",
    "print(f\"    - ì§ˆë¬¸ ì°¸ì¡° ì˜¤ë¥˜: {vote_question_errors:,}ê°œ\")\n",
    "\n",
    "# ì°¨ë‹¨ ê¸°ë¡ (ì‘ì€ í…Œì´ë¸”ì´ë¯€ë¡œ ì „ì²´ ë¡œë“œ)\n",
    "print(f\"\\nâ€¢ ì°¨ë‹¨ ê¸°ë¡ ì°¸ì¡° ë¬´ê²°ì„± ê²€ì‚¬...\")\n",
    "df_block = pd.read_parquet(\"gs://sprintda05_final_project/votes/accounts_blockrecord.parquet\")\n",
    "\n",
    "block_users = set(df_block['user_id'].values) | set(df_block['block_user_id'].values)\n",
    "orphaned_block_users = block_users - existing_users\n",
    "\n",
    "print(f\"  âœ… ì°¨ë‹¨ ê¸°ë¡ ê²€ì‚¬ ì™„ë£Œ\")\n",
    "print(f\"    - ì´ ì°¨ë‹¨ ê¸°ë¡: {len(df_block):,}ê±´\")\n",
    "print(f\"    - ì‚¬ìš©ì ì°¸ì¡° ì˜¤ë¥˜: {len(orphaned_block_users):,}ê°œ\")\n",
    "\n",
    "del df_block\n",
    "gc.collect()\n",
    "\n",
    "print(f\"\\nğŸ“Š 3ë‹¨ê³„: ì‹œê°„ ë°ì´í„° ì¼ê´€ì„±\")\n",
    "print(\"-\" * 40)\n",
    "\n",
    "# ì‹œê°„ ë°ì´í„° ê²€ì‚¬ (í•„ìš”í•œ ì»¬ëŸ¼ë§Œ)\n",
    "time_columns = ['created_at', 'point']\n",
    "df_user_time = pd.read_parquet(\n",
    "    \"gs://sprintda05_final_project/votes/accounts_user.parquet\",\n",
    "    columns=time_columns\n",
    ")\n",
    "\n",
    "# ì‹œê°„ ë³€í™˜ ë° ë¶„ì„\n",
    "df_user_time['created_at'] = pd.to_datetime(df_user_time['created_at'])\n",
    "min_time = df_user_time['created_at'].min()\n",
    "max_time = df_user_time['created_at'].max()\n",
    "\n",
    "print(f\"â€¢ ì‚¬ìš©ì ê°€ì… ê¸°ê°„: {min_time} ~ {max_time}\")\n",
    "\n",
    "# ë¯¸ë˜ ë‚ ì§œ í™•ì¸\n",
    "future_dates = (df_user_time['created_at'] > pd.Timestamp.now()).sum()\n",
    "print(f\"â€¢ ë¯¸ë˜ ë‚ ì§œ: {future_dates:,}ê°œ\")\n",
    "\n",
    "# í¬ì¸íŠ¸ ë¶„ì„\n",
    "point_stats = df_user_time['point'].describe()\n",
    "negative_points = (df_user_time['point'] < 0).sum()\n",
    "\n",
    "print(f\"â€¢ í¬ì¸íŠ¸ ë²”ìœ„: {point_stats['min']:.0f} ~ {point_stats['max']:.0f}\")\n",
    "print(f\"â€¢ ìŒìˆ˜ í¬ì¸íŠ¸ ì‚¬ìš©ì: {negative_points:,}ëª…\")\n",
    "\n",
    "del df_user_time\n",
    "gc.collect()\n",
    "\n",
    "# ìµœì¢… ê²°ê³¼ ìš”ì•½\n",
    "print(f\"\\n\" + \"=\" * 60)\n",
    "print(\"ğŸ“‹ ì „ì²´ ë°ì´í„° ì¼ê´€ì„± ê²€ì‚¬ ê²°ê³¼\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "issues = []\n",
    "if vote_user_errors > 0:\n",
    "    issues.append(f\"íˆ¬í‘œ ê¸°ë¡ ì‚¬ìš©ì ì°¸ì¡° ì˜¤ë¥˜: {vote_user_errors:,}ê°œ\")\n",
    "if vote_question_errors > 0:\n",
    "    issues.append(f\"íˆ¬í‘œ ê¸°ë¡ ì§ˆë¬¸ ì°¸ì¡° ì˜¤ë¥˜: {vote_question_errors:,}ê°œ\")\n",
    "if len(orphaned_block_users) > 0:\n",
    "    issues.append(f\"ì°¨ë‹¨ ê¸°ë¡ ì‚¬ìš©ì ì°¸ì¡° ì˜¤ë¥˜: {len(orphaned_block_users):,}ê°œ\")\n",
    "if future_dates > 0:\n",
    "    issues.append(f\"ë¯¸ë˜ ë‚ ì§œ ì‚¬ìš©ì: {future_dates:,}ëª…\")\n",
    "if negative_points > 0:\n",
    "    issues.append(f\"ìŒìˆ˜ í¬ì¸íŠ¸ ì‚¬ìš©ì: {negative_points:,}ëª…\")\n",
    "\n",
    "if issues:\n",
    "    print(\"ğŸš¨ ë°œê²¬ëœ ì¼ê´€ì„± ë¬¸ì œ:\")\n",
    "    for i, issue in enumerate(issues, 1):\n",
    "        print(f\"  {i}. {issue}\")\n",
    "else:\n",
    "    print(\"âœ… ì£¼ìš” ì¼ê´€ì„± ë¬¸ì œ ì—†ìŒ\")\n",
    "\n",
    "print(f\"\\nğŸ’¾ ë©”ëª¨ë¦¬ íš¨ìœ¨ì  ì²˜ë¦¬ ì™„ë£Œ!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3182da1a",
   "metadata": {},
   "source": [
    "### ë¹„ì¦ˆë‹ˆìŠ¤ ë¡œì§ ì¼ê´€ì„± ê²€ì‚¬"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8a8a7e28",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ” 4ë‹¨ê³„: ë¹„ì¦ˆë‹ˆìŠ¤ ë¡œì§ ì¼ê´€ì„± ë¶„ì„\n",
      "============================================================\n",
      "ğŸ“‹ 1. ë¦¬ìŠ¤íŠ¸ í˜•íƒœ ì»¬ëŸ¼ í˜•ì‹ ì¼ê´€ì„±\n",
      "----------------------------------------\n",
      "\n",
      "â€¢ friend_id_list í˜•ì‹ ë¶„ì„:\n",
      "  - NULL ê°’: 0ê°œ\n",
      "  - ìƒ˜í”Œ ê°’: ['[1292473, 913158, 1488461, 1064695, 1043565, 1274736]', '[833025, 832642, 982531, 879496, 838541, 837521, 833041, 832151, 1082907, 1426466, 1541413, 1577131, 837806, 834486, 834358, 1575225, 1576252, 837950, 1446852, 1577930, 841037, 1577938, 832340, 831958, 849624, 837338, 1577954, 849763, 862823, 1577703, 834415, 833009, 834289, 833011, 842865, 833013, 856050, 833017, 833018, 833022, 833023, 1580476, 1580855]', '[838785, 982531, 882567, 879496, 838541, 836496, 833041, 837521, 836498, 832920, 1082907, 1426466, 1541413, 837806, 834486, 834358, 1239225, 1575225, 837950, 874050, 1446852, 841037, 834643, 832340, 836693, 849624, 837338, 831962, 832986, 849763, 874212, 832740, 832614, 862823, 840046, 834415, 856050, 832894, 1577131, 1577703, 1577930, 1577938, 1577954, 1578661, 1579185, 1579656, 1580105, 1580329, 1437875, 1580855, 1581251]']\n",
      "  - ë¦¬ìŠ¤íŠ¸ ê¸¸ì´ ë²”ìœ„: 0 ~ 1373\n",
      "  - í‰ê·  ê¸¸ì´: 53.3\n",
      "\n",
      "â€¢ block_user_id_list í˜•ì‹ ë¶„ì„:\n",
      "  - NULL ê°’: 0ê°œ\n",
      "  - ìƒ˜í”Œ ê°’: ['[]', '[]', '[]']\n",
      "  - ë¦¬ìŠ¤íŠ¸ ê¸¸ì´ ë²”ìœ„: 0 ~ 178\n",
      "  - í‰ê·  ê¸¸ì´: 0.0\n",
      "\n",
      "â€¢ hide_user_id_list í˜•ì‹ ë¶„ì„:\n",
      "  - NULL ê°’: 0ê°œ\n",
      "  - ìƒ˜í”Œ ê°’: ['[]', '[]', '[]']\n",
      "  - ë¦¬ìŠ¤íŠ¸ ê¸¸ì´ ë²”ìœ„: 0 ~ 3557\n",
      "  - í‰ê·  ê¸¸ì´: 0.8\n",
      "\n",
      "ğŸ“‹ 2. ì¶œì„ ë°ì´í„° í˜•ì‹ ì¼ê´€ì„±\n",
      "----------------------------------------\n",
      "â€¢ ì¶œì„ ê¸°ë¡ ìˆ˜: 349,637ê°œ\n",
      "â€¢ attendance_date_list ìƒ˜í”Œ:\n",
      "  1. [\"2023-05-27\", \"2023-05-28\", \"2023-05-29\", \"2023-05-30\", \"2023-06-03\", \"2023-06-06\", \"2023-06-12\", \"2023-06-15\", \"2023-07-10\", \"2023-07-31\", \"2023-09-12\", \"2023-09-14\", \"2023-09-19\"]\n",
      "  2. [\"2023-05-27\", \"2023-05-29\", \"2023-05-30\", \"2023-06-02\", \"2023-06-03\", \"2023-06-05\", \"2023-06-07\", \"2023-06-08\", \"2023-06-10\", \"2023-06-11\", \"2023-06-15\", \"2023-06-16\", \"2023-06-17\", \"2023-06-18\", \"2023-06-19\", \"2023-06-20\", \"2023-06-21\", \"2023-06-22\", \"2023-06-23\", \"2023-06-27\", \"2023-07-01\", \"2023-07-04\", \"2023-07-08\", \"2023-07-10\", \"2023-07-15\", \"2023-07-26\", \"2023-08-01\", \"2023-08-02\", \"2023-08-03\", \"2023-08-05\", \"2023-08-14\", \"2023-08-21\", \"2023-08-22\"]\n",
      "  3. [\"2023-05-27\", \"2023-05-29\", \"2023-05-30\", \"2023-05-31\", \"2023-06-01\", \"2023-06-02\", \"2023-06-06\", \"2023-06-07\", \"2023-06-14\"]\n",
      "â€¢ ì¶œì„ì¼ ìˆ˜ ë²”ìœ„: 0 ~ 310\n",
      "â€¢ í‰ê·  ì¶œì„ì¼ ìˆ˜: 6.4\n",
      "\n",
      "ğŸ“‹ 3. ë¹„ì¦ˆë‹ˆìŠ¤ ê·œì¹™ ì¼ê´€ì„±\n",
      "----------------------------------------\n",
      "â€¢ ìê¸° ìì‹  ì°¸ì¡° ê·œì¹™ í™•ì¸:\n",
      "  - ìê¸° ìì‹ ì—ê²Œ íˆ¬í‘œ: 1,959ê±´\n",
      "  - ìê¸° ìì‹ ì—ê²Œ ì¹œêµ¬ìš”ì²­: 0ê±´\n",
      "  - ìê¸° ìì‹  ì°¨ë‹¨: 33ê±´\n",
      "\n",
      "ğŸ“‹ 4. ë‚ ì§œ ë…¼ë¦¬ ì¼ê´€ì„±\n",
      "----------------------------------------\n",
      "â€¢ ìˆ˜ì •ì¼ < ìƒì„±ì¼ì¸ ì¹œêµ¬ìš”ì²­: 0ê±´\n",
      "â€¢ ìˆ˜ì •ì¼ = ìƒì„±ì¼ì¸ ì¹œêµ¬ìš”ì²­: 3,938,451ê±´ (ë¯¸ì²˜ë¦¬ ìš”ì²­)\n",
      "\n",
      "============================================================\n",
      "ğŸ“‹ ë¹„ì¦ˆë‹ˆìŠ¤ ë¡œì§ ì¼ê´€ì„± ê²€ì‚¬ ê²°ê³¼\n",
      "============================================================\n",
      "ğŸš¨ ë°œê²¬ëœ ë¹„ì¦ˆë‹ˆìŠ¤ ë¡œì§ ë¬¸ì œ:\n",
      "  1. ìê¸° ìì‹ ì—ê²Œ íˆ¬í‘œ: 1,959ê±´\n",
      "  2. ìê¸° ìì‹  ì°¨ë‹¨: 33ê±´\n",
      "\n",
      "ğŸ¯ 4ë‹¨ê³„ ë°ì´í„° í˜•ì‹ ë° ë¹„ì¦ˆë‹ˆìŠ¤ ë¡œì§ ê²€ì‚¬ ì™„ë£Œ!\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import ast\n",
    "\n",
    "print(\"ğŸ” 4ë‹¨ê³„: ë¹„ì¦ˆë‹ˆìŠ¤ ë¡œì§ ì¼ê´€ì„± ë¶„ì„\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "print(\"ğŸ“‹ 1. ë¦¬ìŠ¤íŠ¸ í˜•íƒœ ì»¬ëŸ¼ í˜•ì‹ ì¼ê´€ì„±\")\n",
    "print(\"-\" * 40)\n",
    "\n",
    "# 1. accounts_userì˜ ë¦¬ìŠ¤íŠ¸ ì»¬ëŸ¼ë“¤\n",
    "df_user = pd.read_parquet(\n",
    "    \"gs://sprintda05_final_project/votes/accounts_user.parquet\",\n",
    "    columns=['id', 'friend_id_list', 'block_user_id_list', 'hide_user_id_list']\n",
    ")\n",
    "\n",
    "list_columns = ['friend_id_list', 'block_user_id_list', 'hide_user_id_list']\n",
    "\n",
    "for col in list_columns:\n",
    "    print(f\"\\nâ€¢ {col} í˜•ì‹ ë¶„ì„:\")\n",
    "    \n",
    "    # NULL ê°’ í™•ì¸\n",
    "    null_count = df_user[col].isnull().sum()\n",
    "    print(f\"  - NULL ê°’: {null_count:,}ê°œ\")\n",
    "    \n",
    "    # ë¹ˆ ë¦¬ìŠ¤íŠ¸ vs ì‹¤ë°ì´í„° í™•ì¸\n",
    "    non_null = df_user[col].dropna()\n",
    "    if len(non_null) > 0:\n",
    "        # ì²« ëª‡ ê°œ ìƒ˜í”Œ í™•ì¸\n",
    "        samples = non_null.head(3).tolist()\n",
    "        print(f\"  - ìƒ˜í”Œ ê°’: {samples}\")\n",
    "        \n",
    "        # ë¦¬ìŠ¤íŠ¸ ê¸¸ì´ ë¶„í¬\n",
    "        try:\n",
    "            if isinstance(non_null.iloc[0], str):\n",
    "                # ë¬¸ìì—´ë¡œ ì €ì¥ëœ ë¦¬ìŠ¤íŠ¸ íŒŒì‹±\n",
    "                lengths = non_null.apply(lambda x: len(ast.literal_eval(x)) if x.strip() != '' else 0)\n",
    "            else:\n",
    "                # ì‹¤ì œ ë¦¬ìŠ¤íŠ¸\n",
    "                lengths = non_null.apply(len)\n",
    "            \n",
    "            print(f\"  - ë¦¬ìŠ¤íŠ¸ ê¸¸ì´ ë²”ìœ„: {lengths.min()} ~ {lengths.max()}\")\n",
    "            print(f\"  - í‰ê·  ê¸¸ì´: {lengths.mean():.1f}\")\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"  - í˜•ì‹ ë¶„ì„ ì‹¤íŒ¨: {str(e)[:30]}\")\n",
    "\n",
    "del df_user\n",
    "\n",
    "print(f\"\\nğŸ“‹ 2. ì¶œì„ ë°ì´í„° í˜•ì‹ ì¼ê´€ì„±\")\n",
    "print(\"-\" * 40)\n",
    "\n",
    "# 2. accounts_attendanceì˜ ë‚ ì§œ ë¦¬ìŠ¤íŠ¸\n",
    "df_attendance = pd.read_parquet(\"gs://sprintda05_final_project/votes/accounts_attendance.parquet\")\n",
    "\n",
    "print(f\"â€¢ ì¶œì„ ê¸°ë¡ ìˆ˜: {len(df_attendance):,}ê°œ\")\n",
    "print(f\"â€¢ attendance_date_list ìƒ˜í”Œ:\")\n",
    "\n",
    "# ì²« ëª‡ ê°œ ìƒ˜í”Œ í™•ì¸\n",
    "for i, sample in enumerate(df_attendance['attendance_date_list'].head(3)):\n",
    "    print(f\"  {i+1}. {sample}\")\n",
    "\n",
    "# ì¶œì„ì¼ ìˆ˜ ë¶„í¬\n",
    "try:\n",
    "    attendance_lengths = df_attendance['attendance_date_list'].apply(\n",
    "        lambda x: len(ast.literal_eval(x)) if pd.notna(x) and x.strip() != '' else 0\n",
    "    )\n",
    "    print(f\"â€¢ ì¶œì„ì¼ ìˆ˜ ë²”ìœ„: {attendance_lengths.min()} ~ {attendance_lengths.max()}\")\n",
    "    print(f\"â€¢ í‰ê·  ì¶œì„ì¼ ìˆ˜: {attendance_lengths.mean():.1f}\")\n",
    "except Exception as e:\n",
    "    print(f\"â€¢ ì¶œì„ì¼ ë¶„ì„ ì‹¤íŒ¨: {str(e)[:30]}\")\n",
    "\n",
    "del df_attendance\n",
    "\n",
    "print(f\"\\nğŸ“‹ 3. ë¹„ì¦ˆë‹ˆìŠ¤ ê·œì¹™ ì¼ê´€ì„±\")\n",
    "print(\"-\" * 40)\n",
    "\n",
    "# 3. ìê¸° ìì‹  ê´€ë ¨ ê·œì¹™ í™•ì¸\n",
    "print(\"â€¢ ìê¸° ìì‹  ì°¸ì¡° ê·œì¹™ í™•ì¸:\")\n",
    "\n",
    "# íˆ¬í‘œì—ì„œ ìê¸° ìì‹  ì„ íƒ í™•ì¸\n",
    "df_vote_self = pd.read_parquet(\n",
    "    \"gs://sprintda05_final_project/votes/accounts_userquestionrecord.parquet\",\n",
    "    columns=['user_id', 'chosen_user_id']\n",
    ")\n",
    "\n",
    "self_votes = (df_vote_self['user_id'] == df_vote_self['chosen_user_id']).sum()\n",
    "print(f\"  - ìê¸° ìì‹ ì—ê²Œ íˆ¬í‘œ: {self_votes:,}ê±´\")\n",
    "\n",
    "del df_vote_self\n",
    "\n",
    "# ì¹œêµ¬ ìš”ì²­ì—ì„œ ìê¸° ìì‹ ì—ê²Œ ìš”ì²­ í™•ì¸\n",
    "df_friend_self = pd.read_parquet(\n",
    "    \"gs://sprintda05_final_project/votes/accounts_friendrequest.parquet\",\n",
    "    columns=['send_user_id', 'receive_user_id']\n",
    ")\n",
    "\n",
    "self_friend_requests = (df_friend_self['send_user_id'] == df_friend_self['receive_user_id']).sum()\n",
    "print(f\"  - ìê¸° ìì‹ ì—ê²Œ ì¹œêµ¬ìš”ì²­: {self_friend_requests:,}ê±´\")\n",
    "\n",
    "del df_friend_self\n",
    "\n",
    "# ì°¨ë‹¨ì—ì„œ ìê¸° ìì‹  ì°¨ë‹¨ í™•ì¸\n",
    "df_block_self = pd.read_parquet(\n",
    "    \"gs://sprintda05_final_project/votes/accounts_blockrecord.parquet\",\n",
    "    columns=['user_id', 'block_user_id']\n",
    ")\n",
    "\n",
    "self_blocks = (df_block_self['user_id'] == df_block_self['block_user_id']).sum()\n",
    "print(f\"  - ìê¸° ìì‹  ì°¨ë‹¨: {self_blocks:,}ê±´\")\n",
    "\n",
    "del df_block_self\n",
    "\n",
    "print(f\"\\nğŸ“‹ 4. ë‚ ì§œ ë…¼ë¦¬ ì¼ê´€ì„±\")\n",
    "print(\"-\" * 40)\n",
    "\n",
    "# 4. ì¹œêµ¬ ìš”ì²­ì˜ ìƒì„±ì¼ vs ìˆ˜ì •ì¼\n",
    "df_friend_time = pd.read_parquet(\n",
    "    \"gs://sprintda05_final_project/votes/accounts_friendrequest.parquet\",\n",
    "    columns=['created_at', 'updated_at']\n",
    ")\n",
    "\n",
    "df_friend_time['created_at'] = pd.to_datetime(df_friend_time['created_at'])\n",
    "df_friend_time['updated_at'] = pd.to_datetime(df_friend_time['updated_at'])\n",
    "\n",
    "# ìˆ˜ì •ì¼ì´ ìƒì„±ì¼ë³´ë‹¤ ë¹ ë¥¸ ê²½ìš°\n",
    "invalid_dates = (df_friend_time['updated_at'] < df_friend_time['created_at']).sum()\n",
    "print(f\"â€¢ ìˆ˜ì •ì¼ < ìƒì„±ì¼ì¸ ì¹œêµ¬ìš”ì²­: {invalid_dates:,}ê±´\")\n",
    "\n",
    "# ë™ì¼í•œ ë‚ ì§œ\n",
    "same_dates = (df_friend_time['updated_at'] == df_friend_time['created_at']).sum()\n",
    "print(f\"â€¢ ìˆ˜ì •ì¼ = ìƒì„±ì¼ì¸ ì¹œêµ¬ìš”ì²­: {same_dates:,}ê±´ (ë¯¸ì²˜ë¦¬ ìš”ì²­)\")\n",
    "\n",
    "del df_friend_time\n",
    "\n",
    "# ìµœì¢… ìš”ì•½\n",
    "print(f\"\\n\" + \"=\" * 60)\n",
    "print(\"ğŸ“‹ ë¹„ì¦ˆë‹ˆìŠ¤ ë¡œì§ ì¼ê´€ì„± ê²€ì‚¬ ê²°ê³¼\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "logic_issues = []\n",
    "\n",
    "if self_votes > 0:\n",
    "    logic_issues.append(f\"ìê¸° ìì‹ ì—ê²Œ íˆ¬í‘œ: {self_votes:,}ê±´\")\n",
    "if self_friend_requests > 0:\n",
    "    logic_issues.append(f\"ìê¸° ìì‹ ì—ê²Œ ì¹œêµ¬ìš”ì²­: {self_friend_requests:,}ê±´\")\n",
    "if self_blocks > 0:\n",
    "    logic_issues.append(f\"ìê¸° ìì‹  ì°¨ë‹¨: {self_blocks:,}ê±´\")\n",
    "if invalid_dates > 0:\n",
    "    logic_issues.append(f\"ë‚ ì§œ ë…¼ë¦¬ ì˜¤ë¥˜: {invalid_dates:,}ê±´\")\n",
    "\n",
    "if logic_issues:\n",
    "    print(\"ğŸš¨ ë°œê²¬ëœ ë¹„ì¦ˆë‹ˆìŠ¤ ë¡œì§ ë¬¸ì œ:\")\n",
    "    for i, issue in enumerate(logic_issues, 1):\n",
    "        print(f\"  {i}. {issue}\")\n",
    "else:\n",
    "    print(\"âœ… ì£¼ìš” ë¹„ì¦ˆë‹ˆìŠ¤ ë¡œì§ ë¬¸ì œ ì—†ìŒ\")\n",
    "\n",
    "print(f\"\\nğŸ¯ 4ë‹¨ê³„ ë°ì´í„° í˜•ì‹ ë° ë¹„ì¦ˆë‹ˆìŠ¤ ë¡œì§ ê²€ì‚¬ ì™„ë£Œ!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "bcc617e8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ”§ 5ë‹¨ê³„: ë°ì´í„° ì „ì²˜ë¦¬ ì „ëµ ìˆ˜ë¦½\n",
      "==================================================\n",
      "ğŸ“‹ 1. ë¹„ì¦ˆë‹ˆìŠ¤ ë¡œì§ ì´ìŠˆ ì²˜ë¦¬ ì „ëµ\n",
      "----------------------------------------\n",
      "ğŸ¯ ìê¸° ìì‹  íˆ¬í‘œ (1,959ê±´) ì²˜ë¦¬ ë°©ë²•:\n",
      "  ì˜µì…˜ 1: ì œê±° â†’ ë¶„ì„ì—ì„œ ì œì™¸\n",
      "  ì˜µì…˜ 2: ìœ ì§€ â†’ 'ìê¸° ì„ íƒ' íŒ¨í„´ìœ¼ë¡œ ë³„ë„ ë¶„ì„\n",
      "  ì˜µì…˜ 3: í”Œë˜ê·¸ â†’ is_self_vote ì»¬ëŸ¼ ì¶”ê°€\n",
      "  ğŸ’¡ ê¶Œì¥: ì˜µì…˜ 3 (ìê¸° ì„ íƒ í–‰ë™ë„ ì˜ë¯¸ ìˆëŠ” ë°ì´í„°)\n",
      "\n",
      "ğŸš« ìê¸° ìì‹  ì°¨ë‹¨ (33ê±´) ì²˜ë¦¬ ë°©ë²•:\n",
      "  ì˜µì…˜ 1: ì œê±° â†’ ì‹œìŠ¤í…œ ì˜¤ë¥˜ë¡œ ê°„ì£¼\n",
      "  ì˜µì…˜ 2: ìœ ì§€ â†’ íŠ¹ìˆ˜ ì¼€ì´ìŠ¤ë¡œ ë¶„ì„\n",
      "  ğŸ’¡ ê¶Œì¥: ì˜µì…˜ 1 (ìê¸° ì°¨ë‹¨ì€ ë¹„ë…¼ë¦¬ì )\n",
      "\n",
      "ğŸ“‹ 2. ë¦¬ìŠ¤íŠ¸ ì»¬ëŸ¼ ì „ì²˜ë¦¬ ì „ëµ\n",
      "----------------------------------------\n",
      "ğŸ”„ ë¬¸ìì—´ â†’ ë¦¬ìŠ¤íŠ¸ ë³€í™˜ í•„ìš” ì»¬ëŸ¼:\n",
      "  â€¢ friend_id_list: '[1,2,3]' â†’ [1,2,3]\n",
      "  â€¢ block_user_id_list: '[]' â†’ []\n",
      "  â€¢ hide_user_id_list: '[1,2]' â†’ [1,2]\n",
      "  â€¢ attendance_date_list: '[\"2023-05-27\"]' â†’ ['2023-05-27']\n",
      "\n",
      "ğŸ’¡ ë³€í™˜ ë°©ë²•:\n",
      "  ast.literal_eval() ì‚¬ìš© ë˜ëŠ” json.loads() í™œìš©\n",
      "\n",
      "ğŸ“‹ 3. ë¶„ì„ë³„ ì „ì²˜ë¦¬ ì „ëµ\n",
      "----------------------------------------\n",
      "ğŸ” ë„¤íŠ¸ì›Œí¬ ë¶„ì„ìš©:\n",
      "  â€¢ friend_id_list â†’ ë„¤íŠ¸ì›Œí¬ ì—£ì§€ ìƒì„±\n",
      "  â€¢ ìê¸° ìì‹  íˆ¬í‘œ â†’ ìê¸° ì¤‘ì‹¬ì„± ì§€í‘œ\n",
      "\n",
      "ğŸ“Š ì‚¬ìš©ì ì„¸ê·¸ë¨¼íŠ¸ ë¶„ì„ìš©:\n",
      "  â€¢ ì¶œì„ì¼ ìˆ˜ â†’ í™œì„±ë„ ì§€í‘œ\n",
      "  â€¢ ì¹œêµ¬ ìˆ˜ â†’ ì‚¬êµì„± ì§€í‘œ\n",
      "  â€¢ í¬ì¸íŠ¸ â†’ ì°¸ì—¬ë„ ì§€í‘œ\n",
      "\n",
      "â° ì‹œê³„ì—´ ë¶„ì„ìš©:\n",
      "  â€¢ attendance_date_list â†’ ì¼ë³„ ì¶œì„ ì´ë²¤íŠ¸\n",
      "  â€¢ created_at â†’ ê°€ì… ì‹œì  ì¶”ì´\n",
      "\n",
      "ğŸ“‹ 4. ë©”ëª¨ë¦¬ íš¨ìœ¨ì  ì „ì²˜ë¦¬\n",
      "----------------------------------------\n",
      "ğŸ’¾ ëŒ€ìš©ëŸ‰ ë°ì´í„° ì²˜ë¦¬ ë°©ë²•:\n",
      "  â€¢ ì²­í¬ ë‹¨ìœ„ ì²˜ë¦¬\n",
      "  â€¢ í•„ìš”í•œ ì»¬ëŸ¼ë§Œ ë¡œë“œ\n",
      "  â€¢ ì „ì²˜ë¦¬ í›„ ìºì‹œ ì €ì¥\n",
      "  â€¢ ë¶„ì„ë³„ ë°ì´í„° ë§ˆíŠ¸ ìƒì„±\n",
      "\n",
      "==================================================\n",
      "ğŸ¯ ì „ì²˜ë¦¬ ìš°ì„ ìˆœìœ„ ì œì•ˆ\n",
      "==================================================\n",
      "1ï¸âƒ£ í•„ìˆ˜ ì „ì²˜ë¦¬:\n",
      "  â€¢ ë¦¬ìŠ¤íŠ¸ ì»¬ëŸ¼ íŒŒì‹±\n",
      "  â€¢ ìê¸° ìì‹  ì°¨ë‹¨ ì œê±°\n",
      "  â€¢ ë‚ ì§œ ì»¬ëŸ¼ datetime ë³€í™˜\n",
      "\n",
      "2ï¸âƒ£ ì„ íƒì  ì „ì²˜ë¦¬:\n",
      "  â€¢ ìê¸° ìì‹  íˆ¬í‘œ í”Œë˜ê·¸ ì¶”ê°€\n",
      "  â€¢ ì´ìƒì¹˜ í¬ì¸íŠ¸ í™•ì¸\n",
      "  â€¢ iOS ê²°ì œ ë°ì´í„° ë¶„ë¦¬\n",
      "\n",
      "3ï¸âƒ£ ë¶„ì„ë³„ ì „ì²˜ë¦¬:\n",
      "  â€¢ ë„¤íŠ¸ì›Œí¬ ë¶„ì„: ì—£ì§€ ë¦¬ìŠ¤íŠ¸ ìƒì„±\n",
      "  â€¢ ì‹œê³„ì—´ ë¶„ì„: ì´ë²¤íŠ¸ ë°ì´í„° ì¬êµ¬ì„±\n",
      "  â€¢ ì‚¬ìš©ì ë¶„ì„: íŠ¹ì„± ì§€í‘œ ê³„ì‚°\n"
     ]
    }
   ],
   "source": [
    "print(\"ğŸ”§ 5ë‹¨ê³„: ë°ì´í„° ì „ì²˜ë¦¬ ì „ëµ ìˆ˜ë¦½\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "print(\"ğŸ“‹ 1. ë¹„ì¦ˆë‹ˆìŠ¤ ë¡œì§ ì´ìŠˆ ì²˜ë¦¬ ì „ëµ\")\n",
    "print(\"-\" * 40)\n",
    "\n",
    "print(\"ğŸ¯ ìê¸° ìì‹  íˆ¬í‘œ (1,959ê±´) ì²˜ë¦¬ ë°©ë²•:\")\n",
    "print(\"  ì˜µì…˜ 1: ì œê±° â†’ ë¶„ì„ì—ì„œ ì œì™¸\")\n",
    "print(\"  ì˜µì…˜ 2: ìœ ì§€ â†’ 'ìê¸° ì„ íƒ' íŒ¨í„´ìœ¼ë¡œ ë³„ë„ ë¶„ì„\")\n",
    "print(\"  ì˜µì…˜ 3: í”Œë˜ê·¸ â†’ is_self_vote ì»¬ëŸ¼ ì¶”ê°€\")\n",
    "print(\"  ğŸ’¡ ê¶Œì¥: ì˜µì…˜ 3 (ìê¸° ì„ íƒ í–‰ë™ë„ ì˜ë¯¸ ìˆëŠ” ë°ì´í„°)\")\n",
    "\n",
    "print(f\"\\nğŸš« ìê¸° ìì‹  ì°¨ë‹¨ (33ê±´) ì²˜ë¦¬ ë°©ë²•:\")\n",
    "print(\"  ì˜µì…˜ 1: ì œê±° â†’ ì‹œìŠ¤í…œ ì˜¤ë¥˜ë¡œ ê°„ì£¼\")\n",
    "print(\"  ì˜µì…˜ 2: ìœ ì§€ â†’ íŠ¹ìˆ˜ ì¼€ì´ìŠ¤ë¡œ ë¶„ì„\")\n",
    "print(\"  ğŸ’¡ ê¶Œì¥: ì˜µì…˜ 1 (ìê¸° ì°¨ë‹¨ì€ ë¹„ë…¼ë¦¬ì )\")\n",
    "\n",
    "print(f\"\\nğŸ“‹ 2. ë¦¬ìŠ¤íŠ¸ ì»¬ëŸ¼ ì „ì²˜ë¦¬ ì „ëµ\")\n",
    "print(\"-\" * 40)\n",
    "\n",
    "print(\"ğŸ”„ ë¬¸ìì—´ â†’ ë¦¬ìŠ¤íŠ¸ ë³€í™˜ í•„ìš” ì»¬ëŸ¼:\")\n",
    "print(\"  â€¢ friend_id_list: '[1,2,3]' â†’ [1,2,3]\")\n",
    "print(\"  â€¢ block_user_id_list: '[]' â†’ []\")\n",
    "print(\"  â€¢ hide_user_id_list: '[1,2]' â†’ [1,2]\")\n",
    "print(\"  â€¢ attendance_date_list: '[\\\"2023-05-27\\\"]' â†’ ['2023-05-27']\")\n",
    "\n",
    "print(f\"\\nğŸ’¡ ë³€í™˜ ë°©ë²•:\")\n",
    "print(\"  ast.literal_eval() ì‚¬ìš© ë˜ëŠ” json.loads() í™œìš©\")\n",
    "\n",
    "print(f\"\\nğŸ“‹ 3. ë¶„ì„ë³„ ì „ì²˜ë¦¬ ì „ëµ\")\n",
    "print(\"-\" * 40)\n",
    "\n",
    "print(\"ğŸ” ë„¤íŠ¸ì›Œí¬ ë¶„ì„ìš©:\")\n",
    "print(\"  â€¢ friend_id_list â†’ ë„¤íŠ¸ì›Œí¬ ì—£ì§€ ìƒì„±\")\n",
    "print(\"  â€¢ ìê¸° ìì‹  íˆ¬í‘œ â†’ ìê¸° ì¤‘ì‹¬ì„± ì§€í‘œ\")\n",
    "\n",
    "print(f\"\\nğŸ“Š ì‚¬ìš©ì ì„¸ê·¸ë¨¼íŠ¸ ë¶„ì„ìš©:\")\n",
    "print(\"  â€¢ ì¶œì„ì¼ ìˆ˜ â†’ í™œì„±ë„ ì§€í‘œ\")\n",
    "print(\"  â€¢ ì¹œêµ¬ ìˆ˜ â†’ ì‚¬êµì„± ì§€í‘œ\")\n",
    "print(\"  â€¢ í¬ì¸íŠ¸ â†’ ì°¸ì—¬ë„ ì§€í‘œ\")\n",
    "\n",
    "print(f\"\\nâ° ì‹œê³„ì—´ ë¶„ì„ìš©:\")\n",
    "print(\"  â€¢ attendance_date_list â†’ ì¼ë³„ ì¶œì„ ì´ë²¤íŠ¸\")\n",
    "print(\"  â€¢ created_at â†’ ê°€ì… ì‹œì  ì¶”ì´\")\n",
    "\n",
    "print(f\"\\nğŸ“‹ 4. ë©”ëª¨ë¦¬ íš¨ìœ¨ì  ì „ì²˜ë¦¬\")\n",
    "print(\"-\" * 40)\n",
    "\n",
    "print(\"ğŸ’¾ ëŒ€ìš©ëŸ‰ ë°ì´í„° ì²˜ë¦¬ ë°©ë²•:\")\n",
    "print(\"  â€¢ ì²­í¬ ë‹¨ìœ„ ì²˜ë¦¬\")\n",
    "print(\"  â€¢ í•„ìš”í•œ ì»¬ëŸ¼ë§Œ ë¡œë“œ\")\n",
    "print(\"  â€¢ ì „ì²˜ë¦¬ í›„ ìºì‹œ ì €ì¥\")\n",
    "print(\"  â€¢ ë¶„ì„ë³„ ë°ì´í„° ë§ˆíŠ¸ ìƒì„±\")\n",
    "\n",
    "print(f\"\\n\" + \"=\" * 50)\n",
    "print(\"ğŸ¯ ì „ì²˜ë¦¬ ìš°ì„ ìˆœìœ„ ì œì•ˆ\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "print(\"1ï¸âƒ£ í•„ìˆ˜ ì „ì²˜ë¦¬:\")\n",
    "print(\"  â€¢ ë¦¬ìŠ¤íŠ¸ ì»¬ëŸ¼ íŒŒì‹±\")\n",
    "print(\"  â€¢ ìê¸° ìì‹  ì°¨ë‹¨ ì œê±°\")\n",
    "print(\"  â€¢ ë‚ ì§œ ì»¬ëŸ¼ datetime ë³€í™˜\")\n",
    "\n",
    "print(f\"\\n2ï¸âƒ£ ì„ íƒì  ì „ì²˜ë¦¬:\")\n",
    "print(\"  â€¢ ìê¸° ìì‹  íˆ¬í‘œ í”Œë˜ê·¸ ì¶”ê°€\")\n",
    "print(\"  â€¢ ì´ìƒì¹˜ í¬ì¸íŠ¸ í™•ì¸\")\n",
    "print(\"  â€¢ iOS ê²°ì œ ë°ì´í„° ë¶„ë¦¬\")\n",
    "\n",
    "print(f\"\\n3ï¸âƒ£ ë¶„ì„ë³„ ì „ì²˜ë¦¬:\")\n",
    "print(\"  â€¢ ë„¤íŠ¸ì›Œí¬ ë¶„ì„: ì—£ì§€ ë¦¬ìŠ¤íŠ¸ ìƒì„±\")\n",
    "print(\"  â€¢ ì‹œê³„ì—´ ë¶„ì„: ì´ë²¤íŠ¸ ë°ì´í„° ì¬êµ¬ì„±\")\n",
    "print(\"  â€¢ ì‚¬ìš©ì ë¶„ì„: íŠ¹ì„± ì§€í‘œ ê³„ì‚°\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0e88f6a",
   "metadata": {},
   "source": [
    "# ğŸ“± hackle_events ì´ë²¤íŠ¸ ë¶„ì„\n",
    "\n",
    "## í•´ê²°í•  ì˜ë¬¸ì ë“¤\n",
    "1. **ì´ë²¤íŠ¸ ë°œìƒ ì‹œì **: ì–¸ì œ ì–´ë–¤ ì´ë²¤íŠ¸ê°€ ë§ì´ ë°œìƒí•˜ëŠ”ê°€?\n",
    "2. **ì„¸ì…˜ êµ¬ë¶„ ê¸°ì¤€**: session_start/end íŒ¨í„´ìœ¼ë¡œ ì„¸ì…˜ ì •ì˜ íŒŒì•…\n",
    "3. **ì‚¬ìš©ì ì—¬ì •**: ì¼ë°˜ì ì¸ ì•± ì‚¬ìš© í”Œë¡œìš°ì™€ ì´ë²¤íŠ¸ ìˆœì„œ\n",
    "\n",
    "## ë¶„ì„ ì „ëµ\n",
    "- ë©”ëª¨ë¦¬ íš¨ìœ¨ì„ ìœ„í•œ ì²­í¬/ìƒ˜í”Œ ì²˜ë¦¬\n",
    "- ì‹œê°„ íŒ¨í„´ â†’ ì„¸ì…˜ íŒ¨í„´ â†’ ì—¬ì • íŒ¨í„´ ìˆœì„œë¡œ ë¶„ì„"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1cf0ea3a",
   "metadata": {},
   "source": [
    "### ê¸°ë³¸ ì´ë²¤íŠ¸ í˜„í™© íŒŒì•…"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8ab317e2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ” hackle_events ê¸°ë³¸ í˜„í™© ë¶„ì„\n",
      "==================================================\n",
      "ğŸ“Š ê¸°ë³¸ ì •ë³´:\n",
      "â€¢ ì´ ì´ë²¤íŠ¸ ìˆ˜: 11,441,319ê±´\n",
      "â€¢ ê¸°ê°„: 2023-07-18 00:00:00 ~ 2023-08-10 23:59:59\n",
      "â€¢ ì´ ì„¸ì…˜ ìˆ˜: 253,616ê°œ\n",
      "â€¢ ì´ë²¤íŠ¸ ì¢…ë¥˜: 44ê°œ\n",
      "\n",
      "ğŸ“ˆ ìƒìœ„ 10ê°œ ì´ë²¤íŠ¸ íƒ€ì…:\n",
      "â€¢ view_lab_tap: 1,266,665ê±´ (11.1%)\n",
      "â€¢ view_timeline_tap: 1,194,508ê±´ (10.4%)\n",
      "â€¢ $session_start: 1,036,852ê±´ (9.1%)\n",
      "â€¢ launch_app: 986,388ê±´ (8.6%)\n",
      "â€¢ click_question_open: 816,801ê±´ (7.1%)\n",
      "â€¢ click_bottom_navigation_questions: 769,163ê±´ (6.7%)\n",
      "â€¢ click_bottom_navigation_profile: 653,507ê±´ (5.7%)\n",
      "â€¢ $session_end: 649,658ê±´ (5.7%)\n",
      "â€¢ click_bottom_navigation_timeline: 536,051ê±´ (4.7%)\n",
      "â€¢ skip_question: 454,981ê±´ (4.0%)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from datetime import datetime, timedelta\n",
    "import gc\n",
    "\n",
    "print(\"ğŸ” hackle_events ê¸°ë³¸ í˜„í™© ë¶„ì„\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "# ë©”ëª¨ë¦¬ íš¨ìœ¨ì„ ìœ„í•´ í•„ìš”í•œ ì»¬ëŸ¼ë§Œ ë¡œë“œ\n",
    "essential_cols = ['event_id', 'event_datetime', 'event_key', 'session_id']\n",
    "df_events = pd.read_parquet(\n",
    "    \"gs://sprintda05_final_project/hackle/hackle_events.parquet\",\n",
    "    columns=essential_cols\n",
    ")\n",
    "\n",
    "print(f\"ğŸ“Š ê¸°ë³¸ ì •ë³´:\")\n",
    "print(f\"â€¢ ì´ ì´ë²¤íŠ¸ ìˆ˜: {len(df_events):,}ê±´\")\n",
    "print(f\"â€¢ ê¸°ê°„: {df_events['event_datetime'].min()} ~ {df_events['event_datetime'].max()}\")\n",
    "print(f\"â€¢ ì´ ì„¸ì…˜ ìˆ˜: {df_events['session_id'].nunique():,}ê°œ\")\n",
    "print(f\"â€¢ ì´ë²¤íŠ¸ ì¢…ë¥˜: {df_events['event_key'].nunique():,}ê°œ\")\n",
    "\n",
    "# ìƒìœ„ ì´ë²¤íŠ¸ íƒ€ì…\n",
    "print(f\"\\nğŸ“ˆ ìƒìœ„ 10ê°œ ì´ë²¤íŠ¸ íƒ€ì…:\")\n",
    "top_events = df_events['event_key'].value_counts().head(10)\n",
    "for event, count in top_events.items():\n",
    "    pct = count / len(df_events) * 100\n",
    "    print(f\"â€¢ {event}: {count:,}ê±´ ({pct:.1f}%)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa3c3104",
   "metadata": {},
   "source": [
    "### ì´ë²¤íŠ¸ ë°œìƒ ì‹œê°„ íŒ¨í„´ ë¶„ì„"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "60c8ba4c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "â° ì´ë²¤íŠ¸ ë°œìƒ ì‹œê°„ íŒ¨í„´ ë¶„ì„\n",
      "==================================================\n",
      "ğŸ• ì‹œê°„ëŒ€ë³„ ì´ë²¤íŠ¸ ë°œìƒ:\n",
      "â€¢  0ì‹œ: 728,577ê±´ (6.4%)\n",
      "â€¢  1ì‹œ: 529,583ê±´ (4.6%)\n",
      "â€¢  2ì‹œ: 333,545ê±´ (2.9%)\n",
      "â€¢  3ì‹œ: 194,836ê±´ (1.7%)\n",
      "â€¢  4ì‹œ: 106,583ê±´ (0.9%)\n",
      "â€¢  5ì‹œ: 65,042ê±´ (0.6%)\n",
      "â€¢  6ì‹œ: 68,386ê±´ (0.6%)\n",
      "â€¢  7ì‹œ: 140,467ê±´ (1.2%)\n",
      "â€¢  8ì‹œ: 215,217ê±´ (1.9%)\n",
      "â€¢  9ì‹œ: 235,846ê±´ (2.1%)\n",
      "â€¢ 10ì‹œ: 302,296ê±´ (2.6%)\n",
      "â€¢ 11ì‹œ: 346,129ê±´ (3.0%)\n",
      "â€¢ 12ì‹œ: 381,429ê±´ (3.3%)\n",
      "â€¢ 13ì‹œ: 385,423ê±´ (3.4%)\n",
      "â€¢ 14ì‹œ: 388,929ê±´ (3.4%)\n",
      "â€¢ 15ì‹œ: 396,789ê±´ (3.5%)\n",
      "â€¢ 16ì‹œ: 439,773ê±´ (3.8%)\n",
      "â€¢ 17ì‹œ: 793,125ê±´ (6.9%)\n",
      "â€¢ 18ì‹œ: 992,813ê±´ (8.7%)\n",
      "â€¢ 19ì‹œ: 843,456ê±´ (7.4%)\n",
      "â€¢ 20ì‹œ: 1,207,583ê±´ (10.6%)\n",
      "â€¢ 21ì‹œ: 864,239ê±´ (7.6%)\n",
      "â€¢ 22ì‹œ: 755,223ê±´ (6.6%)\n",
      "â€¢ 23ì‹œ: 726,030ê±´ (6.3%)\n",
      "\n",
      "ğŸ“Š í”¼í¬ ì‹œê°„: 20ì‹œ (1,207,583ê±´)\n",
      "ğŸ“Š ìµœì € ì‹œê°„: 5ì‹œ (65,042ê±´)\n",
      "\n",
      "ğŸ“… ìš”ì¼ë³„ ì´ë²¤íŠ¸ ë°œìƒ:\n",
      "â€¢ ì›”ìš”ì¼: 1,157,929ê±´ (10.1%)\n",
      "â€¢ í™”ìš”ì¼: 1,588,087ê±´ (13.9%)\n",
      "â€¢ ìˆ˜ìš”ì¼: 1,345,594ê±´ (11.8%)\n",
      "â€¢ ëª©ìš”ì¼: 1,809,901ê±´ (15.8%)\n",
      "â€¢ ê¸ˆìš”ì¼: 1,896,656ê±´ (16.6%)\n",
      "â€¢ í† ìš”ì¼: 1,786,289ê±´ (15.6%)\n",
      "â€¢ ì¼ìš”ì¼: 1,856,863ê±´ (16.2%)\n",
      "\n",
      "ğŸ“ˆ ì¼ë³„ ì´ë²¤íŠ¸ í†µê³„:\n",
      "â€¢ í‰ê·  ì¼ì¼ ì´ë²¤íŠ¸: 476,722ê±´\n",
      "â€¢ ìµœëŒ€ ì¼ì¼ ì´ë²¤íŠ¸: 806,121ê±´\n",
      "â€¢ ìµœì†Œ ì¼ì¼ ì´ë²¤íŠ¸: 250,096ê±´\n"
     ]
    }
   ],
   "source": [
    "print(f\"\\nâ° ì´ë²¤íŠ¸ ë°œìƒ ì‹œê°„ íŒ¨í„´ ë¶„ì„\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "# ë‚ ì§œ/ì‹œê°„ íŒŒì‹±\n",
    "df_events['event_datetime'] = pd.to_datetime(df_events['event_datetime'])\n",
    "df_events['hour'] = df_events['event_datetime'].dt.hour\n",
    "df_events['day_of_week'] = df_events['event_datetime'].dt.day_name()\n",
    "df_events['date'] = df_events['event_datetime'].dt.date\n",
    "\n",
    "# 1. ì‹œê°„ëŒ€ë³„ ì´ë²¤íŠ¸ ë°œìƒ íŒ¨í„´\n",
    "print(\"ğŸ• ì‹œê°„ëŒ€ë³„ ì´ë²¤íŠ¸ ë°œìƒ:\")\n",
    "hourly_events = df_events['hour'].value_counts().sort_index()\n",
    "for hour, count in hourly_events.items():\n",
    "    pct = count / len(df_events) * 100\n",
    "    print(f\"â€¢ {hour:2d}ì‹œ: {count:,}ê±´ ({pct:.1f}%)\")\n",
    "\n",
    "peak_hour = hourly_events.idxmax()\n",
    "low_hour = hourly_events.idxmin()\n",
    "print(f\"\\nğŸ“Š í”¼í¬ ì‹œê°„: {peak_hour}ì‹œ ({hourly_events[peak_hour]:,}ê±´)\")\n",
    "print(f\"ğŸ“Š ìµœì € ì‹œê°„: {low_hour}ì‹œ ({hourly_events[low_hour]:,}ê±´)\")\n",
    "\n",
    "# 2. ìš”ì¼ë³„ íŒ¨í„´\n",
    "print(f\"\\nğŸ“… ìš”ì¼ë³„ ì´ë²¤íŠ¸ ë°œìƒ:\")\n",
    "daily_events = df_events['day_of_week'].value_counts()\n",
    "day_order = ['Monday', 'Tuesday', 'Wednesday', 'Thursday', 'Friday', 'Saturday', 'Sunday']\n",
    "daily_events = daily_events.reindex(day_order)\n",
    "\n",
    "for day, count in daily_events.items():\n",
    "    pct = count / len(df_events) * 100\n",
    "    day_kr = {'Monday': 'ì›”', 'Tuesday': 'í™”', 'Wednesday': 'ìˆ˜', 'Thursday': 'ëª©', \n",
    "              'Friday': 'ê¸ˆ', 'Saturday': 'í† ', 'Sunday': 'ì¼'}[day]\n",
    "    print(f\"â€¢ {day_kr}ìš”ì¼: {count:,}ê±´ ({pct:.1f}%)\")\n",
    "\n",
    "# 3. ì¼ë³„ ì´ë²¤íŠ¸ ì¶”ì´\n",
    "daily_count = df_events.groupby('date').size()\n",
    "print(f\"\\nğŸ“ˆ ì¼ë³„ ì´ë²¤íŠ¸ í†µê³„:\")\n",
    "print(f\"â€¢ í‰ê·  ì¼ì¼ ì´ë²¤íŠ¸: {daily_count.mean():,.0f}ê±´\")\n",
    "print(f\"â€¢ ìµœëŒ€ ì¼ì¼ ì´ë²¤íŠ¸: {daily_count.max():,}ê±´\")\n",
    "print(f\"â€¢ ìµœì†Œ ì¼ì¼ ì´ë²¤íŠ¸: {daily_count.min():,}ê±´\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db8587b3",
   "metadata": {},
   "source": [
    "### ì„¸ì…˜ íŒ¨í„´ ë¶„ì„"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b16eb83a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ğŸ”— ì„¸ì…˜ íŒ¨í„´ ë¶„ì„\n",
      "==================================================\n",
      "â€¢ ì„¸ì…˜ ê´€ë ¨ ì´ë²¤íŠ¸: 1,686,510ê±´\n",
      "â€¢ session_start: 1,036,852ê±´\n",
      "â€¢ session_end: 649,658ê±´\n",
      "\n",
      "ğŸ“Š ì„¸ì…˜ ì§€ì†ì‹œê°„ ë¶„ì„ (ìƒ˜í”Œ 1000ê°œ):\n",
      "â€¢ í‰ê·  ì„¸ì…˜ ì‹œê°„: 17054.0ë¶„\n",
      "â€¢ ì¤‘ê°„ê°’ ì„¸ì…˜ ì‹œê°„: 18889.9ë¶„\n",
      "â€¢ ìµœëŒ€ ì„¸ì…˜ ì‹œê°„: 34546.8ë¶„\n",
      "â€¢ í‰ê·  ì„¸ì…˜ë‹¹ ì´ë²¤íŠ¸: 314.0ê°œ\n",
      "\n",
      "â±ï¸ ì„¸ì…˜ ì‹œê°„ ë¶„í¬:\n",
      "â€¢ 60ë¶„ ì´ìƒ: 836ê°œ (83.6%)\n",
      "â€¢ 1-5ë¶„: 70ê°œ (7.0%)\n",
      "â€¢ 1ë¶„ ë¯¸ë§Œ: 47ê°œ (4.7%)\n",
      "â€¢ 5-15ë¶„: 26ê°œ (2.6%)\n",
      "â€¢ 30-60ë¶„: 13ê°œ (1.3%)\n",
      "â€¢ 15-30ë¶„: 6ê°œ (0.6%)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(f\"\\nğŸ”— ì„¸ì…˜ íŒ¨í„´ ë¶„ì„\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "# ì„¸ì…˜ ê´€ë ¨ ì´ë²¤íŠ¸ ì¶”ì¶œ\n",
    "session_events = df_events[df_events['event_key'].isin(['$session_start', '$session_end'])]\n",
    "print(f\"â€¢ ì„¸ì…˜ ê´€ë ¨ ì´ë²¤íŠ¸: {len(session_events):,}ê±´\")\n",
    "\n",
    "# ì„¸ì…˜ ì‹œì‘/ì¢…ë£Œ ì´ë²¤íŠ¸ ìˆ˜\n",
    "session_counts = session_events['event_key'].value_counts()\n",
    "print(f\"â€¢ session_start: {session_counts.get('$session_start', 0):,}ê±´\")\n",
    "print(f\"â€¢ session_end: {session_counts.get('$session_end', 0):,}ê±´\")\n",
    "\n",
    "# ì„¸ì…˜ë³„ ë¶„ì„ (ìƒ˜í”Œ)\n",
    "print(f\"\\nğŸ“Š ì„¸ì…˜ ì§€ì†ì‹œê°„ ë¶„ì„ (ìƒ˜í”Œ 1000ê°œ):\")\n",
    "\n",
    "# ë©”ëª¨ë¦¬ ì ˆì•½ì„ ìœ„í•´ ìƒ˜í”Œ ì„¸ì…˜ë§Œ ë¶„ì„\n",
    "sample_sessions = df_events['session_id'].unique()[:1000]\n",
    "sample_events = df_events[df_events['session_id'].isin(sample_sessions)]\n",
    "\n",
    "session_durations = []\n",
    "session_event_counts = []\n",
    "\n",
    "for session_id in sample_sessions:\n",
    "    session_data = sample_events[sample_events['session_id'] == session_id].sort_values('event_datetime')\n",
    "    \n",
    "    if len(session_data) > 1:\n",
    "        # ì„¸ì…˜ ì§€ì†ì‹œê°„ ê³„ì‚°\n",
    "        start_time = session_data['event_datetime'].min()\n",
    "        end_time = session_data['event_datetime'].max()\n",
    "        duration = (end_time - start_time).total_seconds() / 60  # ë¶„ ë‹¨ìœ„\n",
    "        session_durations.append(duration)\n",
    "        \n",
    "        # ì„¸ì…˜ ë‚´ ì´ë²¤íŠ¸ ìˆ˜\n",
    "        session_event_counts.append(len(session_data))\n",
    "\n",
    "if session_durations:\n",
    "    durations = pd.Series(session_durations)\n",
    "    event_counts = pd.Series(session_event_counts)\n",
    "    \n",
    "    print(f\"â€¢ í‰ê·  ì„¸ì…˜ ì‹œê°„: {durations.mean():.1f}ë¶„\")\n",
    "    print(f\"â€¢ ì¤‘ê°„ê°’ ì„¸ì…˜ ì‹œê°„: {durations.median():.1f}ë¶„\")\n",
    "    print(f\"â€¢ ìµœëŒ€ ì„¸ì…˜ ì‹œê°„: {durations.max():.1f}ë¶„\")\n",
    "    print(f\"â€¢ í‰ê·  ì„¸ì…˜ë‹¹ ì´ë²¤íŠ¸: {event_counts.mean():.1f}ê°œ\")\n",
    "    \n",
    "    # ì„¸ì…˜ ì‹œê°„ ë¶„í¬\n",
    "    print(f\"\\nâ±ï¸ ì„¸ì…˜ ì‹œê°„ ë¶„í¬:\")\n",
    "    duration_ranges = pd.cut(durations, bins=[0, 1, 5, 15, 30, 60, float('inf')], \n",
    "                           labels=['1ë¶„ ë¯¸ë§Œ', '1-5ë¶„', '5-15ë¶„', '15-30ë¶„', '30-60ë¶„', '60ë¶„ ì´ìƒ'])\n",
    "    for range_name, count in duration_ranges.value_counts().items():\n",
    "        pct = count / len(durations) * 100\n",
    "        print(f\"â€¢ {range_name}: {count}ê°œ ({pct:.1f}%)\")\n",
    "\n",
    "# ë©”ëª¨ë¦¬ ì •ë¦¬\n",
    "del sample_events, session_events\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9c0c985",
   "metadata": {},
   "source": [
    "### ì‚¬ìš©ì ì—¬ì • íŒ¨í„´ ë¶„ì„"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f7adf09d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ğŸ—ºï¸ ì‚¬ìš©ì ì—¬ì • íŒ¨í„´ ë¶„ì„\n",
      "==================================================\n",
      "ğŸ“± ì¼ë°˜ì ì¸ ì•± ì‚¬ìš© í”Œë¡œìš° ë¶„ì„ (ìƒ˜í”Œ 100ê°œ ì„¸ì…˜):\n",
      "ğŸ” ê°€ì¥ ì¼ë°˜ì ì¸ ì•± ì‹œì‘ íŒ¨í„´ (ì²« 3ê°œ ì´ë²¤íŠ¸):\n",
      " 1. $session_start â†’ launch_app â†’ $session_end\n",
      "    (12íšŒ, 12.0%)\n",
      " 2. launch_app â†’ $session_start â†’ $session_end\n",
      "    (12íšŒ, 12.0%)\n",
      " 3. $session_end â†’ launch_app â†’ $session_start\n",
      "    (8íšŒ, 8.0%)\n",
      " 4. launch_app â†’ $session_end â†’ $session_start\n",
      "    (6íšŒ, 6.0%)\n",
      " 5. $session_end â†’ $session_start â†’ launch_app\n",
      "    (6íšŒ, 6.0%)\n",
      " 6. launch_app â†’ $session_start â†’ launch_app\n",
      "    (5íšŒ, 5.0%)\n",
      " 7. launch_app â†’ $session_start â†’ click_appbar_alarm_center\n",
      "    (5íšŒ, 5.0%)\n",
      " 8. $session_start â†’ launch_app â†’ click_question_start\n",
      "    (4íšŒ, 4.0%)\n",
      " 9. launch_app â†’ $session_start â†’ click_bottom_navigation_questions\n",
      "    (4íšŒ, 4.0%)\n",
      "10. launch_app â†’ $session_start â†’ view_signup\n",
      "    (4íšŒ, 4.0%)\n",
      "\n",
      "ğŸ”„ ì´ë²¤íŠ¸ ì „í™˜ íŒ¨í„´ ë¶„ì„ (ìƒ˜í”Œ):\n",
      "ğŸ”— ê°€ì¥ ë¹ˆë²ˆí•œ ì´ë²¤íŠ¸ ì „í™˜:\n",
      " 1. view_timeline_tap â†’ launch_app (1íšŒ)\n",
      " 2. click_question_start â†’ click_question_start (1íšŒ)\n",
      " 3. view_questions_tap â†’ click_bottom_navigation_questions (1íšŒ)\n",
      " 4. $session_start â†’ view_profile_tap (1íšŒ)\n",
      " 5. view_profile_tap â†’ click_bottom_navigation_profile (1íšŒ)\n",
      " 6. click_bottom_navigation_profile â†’ skip_question (1íšŒ)\n",
      " 7. skip_question â†’ click_question_open (1íšŒ)\n",
      " 8. click_question_open â†’ skip_question (1íšŒ)\n",
      " 9. view_lab_tap â†’ view_timeline_tap (1íšŒ)\n",
      "10. click_bottom_navigation_lab â†’ click_random_ask_shuffle (1íšŒ)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "26"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(f\"\\nğŸ—ºï¸ ì‚¬ìš©ì ì—¬ì • íŒ¨í„´ ë¶„ì„\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "# ì‚¬ìš©ì ì—¬ì • ë¶„ì„ì„ ìœ„í•œ ìƒ˜í”Œ ë°ì´í„°\n",
    "print(\"ğŸ“± ì¼ë°˜ì ì¸ ì•± ì‚¬ìš© í”Œë¡œìš° ë¶„ì„ (ìƒ˜í”Œ 100ê°œ ì„¸ì…˜):\")\n",
    "\n",
    "# 100ê°œ ì„¸ì…˜ì˜ ì´ë²¤íŠ¸ ì‹œí€€ìŠ¤ ë¶„ì„\n",
    "sample_sessions_small = df_events['session_id'].unique()[:100]\n",
    "journey_patterns = []\n",
    "\n",
    "for session_id in sample_sessions_small:\n",
    "    session_data = df_events[df_events['session_id'] == session_id].sort_values('event_datetime')\n",
    "    event_sequence = session_data['event_key'].tolist()\n",
    "    \n",
    "    if len(event_sequence) >= 3:  # ìµœì†Œ 3ê°œ ì´ë²¤íŠ¸ ì´ìƒ\n",
    "        # ì²« 3ê°œ ì´ë²¤íŠ¸ íŒ¨í„´\n",
    "        first_three = ' â†’ '.join(event_sequence[:3])\n",
    "        journey_patterns.append(first_three)\n",
    "\n",
    "# ê°€ì¥ ì¼ë°˜ì ì¸ ì‚¬ìš©ì ì—¬ì • íŒ¨í„´\n",
    "if journey_patterns:\n",
    "    common_journeys = pd.Series(journey_patterns).value_counts().head(10)\n",
    "    \n",
    "    print(\"ğŸ” ê°€ì¥ ì¼ë°˜ì ì¸ ì•± ì‹œì‘ íŒ¨í„´ (ì²« 3ê°œ ì´ë²¤íŠ¸):\")\n",
    "    for i, (pattern, count) in enumerate(common_journeys.items(), 1):\n",
    "        pct = count / len(journey_patterns) * 100\n",
    "        print(f\"{i:2d}. {pattern}\")\n",
    "        print(f\"    ({count}íšŒ, {pct:.1f}%)\")\n",
    "\n",
    "# ì´ë²¤íŠ¸ ì „í™˜ íŒ¨í„´ ë¶„ì„\n",
    "print(f\"\\nğŸ”„ ì´ë²¤íŠ¸ ì „í™˜ íŒ¨í„´ ë¶„ì„ (ìƒ˜í”Œ):\")\n",
    "\n",
    "# ì´ë²¤íŠ¸ ìŒ ì „í™˜ íŒ¨í„´\n",
    "transition_pairs = []\n",
    "sample_data = df_events.head(10000).sort_values(['session_id', 'event_datetime'])\n",
    "\n",
    "for session_id in sample_data['session_id'].unique()[:50]:\n",
    "    session_events = sample_data[sample_data['session_id'] == session_id]['event_key'].tolist()\n",
    "    \n",
    "    for i in range(len(session_events) - 1):\n",
    "        from_event = session_events[i]\n",
    "        to_event = session_events[i + 1]\n",
    "        transition_pairs.append(f\"{from_event} â†’ {to_event}\")\n",
    "\n",
    "if transition_pairs:\n",
    "    top_transitions = pd.Series(transition_pairs).value_counts().head(10)\n",
    "    \n",
    "    print(\"ğŸ”— ê°€ì¥ ë¹ˆë²ˆí•œ ì´ë²¤íŠ¸ ì „í™˜:\")\n",
    "    for i, (transition, count) in enumerate(top_transitions.items(), 1):\n",
    "        print(f\"{i:2d}. {transition} ({count}íšŒ)\")\n",
    "\n",
    "# ë©”ëª¨ë¦¬ ì •ë¦¬\n",
    "del df_events\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f20d594",
   "metadata": {},
   "source": [
    "### ì„¸ì…˜ ë¬¸ì œ ìƒì„¸ ë¶„ì„"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f51acd08",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ” ì„¸ì…˜ ë¬¸ì œ ìƒì„¸ ë¶„ì„\n",
      "==================================================\n",
      "ğŸ“Š ì„¸ì…˜ ì™„ì„±ë„ ë¶„ì„:\n",
      "ì„¸ì…˜ ìƒíƒœë³„ ë¶„í¬:\n",
      "â€¢ ì •ìƒ (ì‹œì‘+ì¢…ë£Œ): 929ê°œ (92.9%)\n",
      "â€¢ ì‹œì‘ë§Œ ìˆìŒ: 71ê°œ (7.1%)\n",
      "\n",
      "â° ì •ìƒ ì„¸ì…˜ ì‹œê°„ ì¬ê³„ì‚° (929ê°œ):\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_8229/2263042957.py:54: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  session_data['event_datetime'] = pd.to_datetime(session_data['event_datetime'])\n",
      "/tmp/ipykernel_8229/2263042957.py:54: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  session_data['event_datetime'] = pd.to_datetime(session_data['event_datetime'])\n",
      "/tmp/ipykernel_8229/2263042957.py:54: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  session_data['event_datetime'] = pd.to_datetime(session_data['event_datetime'])\n",
      "/tmp/ipykernel_8229/2263042957.py:54: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  session_data['event_datetime'] = pd.to_datetime(session_data['event_datetime'])\n",
      "/tmp/ipykernel_8229/2263042957.py:54: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  session_data['event_datetime'] = pd.to_datetime(session_data['event_datetime'])\n",
      "/tmp/ipykernel_8229/2263042957.py:54: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  session_data['event_datetime'] = pd.to_datetime(session_data['event_datetime'])\n",
      "/tmp/ipykernel_8229/2263042957.py:54: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  session_data['event_datetime'] = pd.to_datetime(session_data['event_datetime'])\n",
      "/tmp/ipykernel_8229/2263042957.py:54: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  session_data['event_datetime'] = pd.to_datetime(session_data['event_datetime'])\n",
      "/tmp/ipykernel_8229/2263042957.py:54: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  session_data['event_datetime'] = pd.to_datetime(session_data['event_datetime'])\n",
      "/tmp/ipykernel_8229/2263042957.py:54: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  session_data['event_datetime'] = pd.to_datetime(session_data['event_datetime'])\n",
      "/tmp/ipykernel_8229/2263042957.py:54: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  session_data['event_datetime'] = pd.to_datetime(session_data['event_datetime'])\n",
      "/tmp/ipykernel_8229/2263042957.py:54: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  session_data['event_datetime'] = pd.to_datetime(session_data['event_datetime'])\n",
      "/tmp/ipykernel_8229/2263042957.py:54: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  session_data['event_datetime'] = pd.to_datetime(session_data['event_datetime'])\n",
      "/tmp/ipykernel_8229/2263042957.py:54: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  session_data['event_datetime'] = pd.to_datetime(session_data['event_datetime'])\n",
      "/tmp/ipykernel_8229/2263042957.py:54: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  session_data['event_datetime'] = pd.to_datetime(session_data['event_datetime'])\n",
      "/tmp/ipykernel_8229/2263042957.py:54: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  session_data['event_datetime'] = pd.to_datetime(session_data['event_datetime'])\n",
      "/tmp/ipykernel_8229/2263042957.py:54: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  session_data['event_datetime'] = pd.to_datetime(session_data['event_datetime'])\n",
      "/tmp/ipykernel_8229/2263042957.py:54: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  session_data['event_datetime'] = pd.to_datetime(session_data['event_datetime'])\n",
      "/tmp/ipykernel_8229/2263042957.py:54: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  session_data['event_datetime'] = pd.to_datetime(session_data['event_datetime'])\n",
      "/tmp/ipykernel_8229/2263042957.py:54: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  session_data['event_datetime'] = pd.to_datetime(session_data['event_datetime'])\n",
      "/tmp/ipykernel_8229/2263042957.py:54: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  session_data['event_datetime'] = pd.to_datetime(session_data['event_datetime'])\n",
      "/tmp/ipykernel_8229/2263042957.py:54: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  session_data['event_datetime'] = pd.to_datetime(session_data['event_datetime'])\n",
      "/tmp/ipykernel_8229/2263042957.py:54: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  session_data['event_datetime'] = pd.to_datetime(session_data['event_datetime'])\n",
      "/tmp/ipykernel_8229/2263042957.py:54: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  session_data['event_datetime'] = pd.to_datetime(session_data['event_datetime'])\n",
      "/tmp/ipykernel_8229/2263042957.py:54: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  session_data['event_datetime'] = pd.to_datetime(session_data['event_datetime'])\n",
      "/tmp/ipykernel_8229/2263042957.py:54: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  session_data['event_datetime'] = pd.to_datetime(session_data['event_datetime'])\n",
      "/tmp/ipykernel_8229/2263042957.py:54: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  session_data['event_datetime'] = pd.to_datetime(session_data['event_datetime'])\n",
      "/tmp/ipykernel_8229/2263042957.py:54: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  session_data['event_datetime'] = pd.to_datetime(session_data['event_datetime'])\n",
      "/tmp/ipykernel_8229/2263042957.py:54: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  session_data['event_datetime'] = pd.to_datetime(session_data['event_datetime'])\n",
      "/tmp/ipykernel_8229/2263042957.py:54: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  session_data['event_datetime'] = pd.to_datetime(session_data['event_datetime'])\n",
      "/tmp/ipykernel_8229/2263042957.py:54: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  session_data['event_datetime'] = pd.to_datetime(session_data['event_datetime'])\n",
      "/tmp/ipykernel_8229/2263042957.py:54: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  session_data['event_datetime'] = pd.to_datetime(session_data['event_datetime'])\n",
      "/tmp/ipykernel_8229/2263042957.py:54: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  session_data['event_datetime'] = pd.to_datetime(session_data['event_datetime'])\n",
      "/tmp/ipykernel_8229/2263042957.py:54: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  session_data['event_datetime'] = pd.to_datetime(session_data['event_datetime'])\n",
      "/tmp/ipykernel_8229/2263042957.py:54: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  session_data['event_datetime'] = pd.to_datetime(session_data['event_datetime'])\n",
      "/tmp/ipykernel_8229/2263042957.py:54: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  session_data['event_datetime'] = pd.to_datetime(session_data['event_datetime'])\n",
      "/tmp/ipykernel_8229/2263042957.py:54: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  session_data['event_datetime'] = pd.to_datetime(session_data['event_datetime'])\n",
      "/tmp/ipykernel_8229/2263042957.py:54: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  session_data['event_datetime'] = pd.to_datetime(session_data['event_datetime'])\n",
      "/tmp/ipykernel_8229/2263042957.py:54: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  session_data['event_datetime'] = pd.to_datetime(session_data['event_datetime'])\n",
      "/tmp/ipykernel_8229/2263042957.py:54: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  session_data['event_datetime'] = pd.to_datetime(session_data['event_datetime'])\n",
      "/tmp/ipykernel_8229/2263042957.py:54: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  session_data['event_datetime'] = pd.to_datetime(session_data['event_datetime'])\n",
      "/tmp/ipykernel_8229/2263042957.py:54: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  session_data['event_datetime'] = pd.to_datetime(session_data['event_datetime'])\n",
      "/tmp/ipykernel_8229/2263042957.py:54: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  session_data['event_datetime'] = pd.to_datetime(session_data['event_datetime'])\n",
      "/tmp/ipykernel_8229/2263042957.py:54: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  session_data['event_datetime'] = pd.to_datetime(session_data['event_datetime'])\n",
      "/tmp/ipykernel_8229/2263042957.py:54: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  session_data['event_datetime'] = pd.to_datetime(session_data['event_datetime'])\n",
      "/tmp/ipykernel_8229/2263042957.py:54: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  session_data['event_datetime'] = pd.to_datetime(session_data['event_datetime'])\n",
      "/tmp/ipykernel_8229/2263042957.py:54: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  session_data['event_datetime'] = pd.to_datetime(session_data['event_datetime'])\n",
      "/tmp/ipykernel_8229/2263042957.py:54: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  session_data['event_datetime'] = pd.to_datetime(session_data['event_datetime'])\n",
      "/tmp/ipykernel_8229/2263042957.py:54: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  session_data['event_datetime'] = pd.to_datetime(session_data['event_datetime'])\n",
      "/tmp/ipykernel_8229/2263042957.py:54: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  session_data['event_datetime'] = pd.to_datetime(session_data['event_datetime'])\n",
      "/tmp/ipykernel_8229/2263042957.py:54: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  session_data['event_datetime'] = pd.to_datetime(session_data['event_datetime'])\n",
      "/tmp/ipykernel_8229/2263042957.py:54: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  session_data['event_datetime'] = pd.to_datetime(session_data['event_datetime'])\n",
      "/tmp/ipykernel_8229/2263042957.py:54: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  session_data['event_datetime'] = pd.to_datetime(session_data['event_datetime'])\n",
      "/tmp/ipykernel_8229/2263042957.py:54: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  session_data['event_datetime'] = pd.to_datetime(session_data['event_datetime'])\n",
      "/tmp/ipykernel_8229/2263042957.py:54: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  session_data['event_datetime'] = pd.to_datetime(session_data['event_datetime'])\n",
      "/tmp/ipykernel_8229/2263042957.py:54: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  session_data['event_datetime'] = pd.to_datetime(session_data['event_datetime'])\n",
      "/tmp/ipykernel_8229/2263042957.py:54: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  session_data['event_datetime'] = pd.to_datetime(session_data['event_datetime'])\n",
      "/tmp/ipykernel_8229/2263042957.py:54: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  session_data['event_datetime'] = pd.to_datetime(session_data['event_datetime'])\n",
      "/tmp/ipykernel_8229/2263042957.py:54: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  session_data['event_datetime'] = pd.to_datetime(session_data['event_datetime'])\n",
      "/tmp/ipykernel_8229/2263042957.py:54: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  session_data['event_datetime'] = pd.to_datetime(session_data['event_datetime'])\n",
      "/tmp/ipykernel_8229/2263042957.py:54: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  session_data['event_datetime'] = pd.to_datetime(session_data['event_datetime'])\n",
      "/tmp/ipykernel_8229/2263042957.py:54: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  session_data['event_datetime'] = pd.to_datetime(session_data['event_datetime'])\n",
      "/tmp/ipykernel_8229/2263042957.py:54: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  session_data['event_datetime'] = pd.to_datetime(session_data['event_datetime'])\n",
      "/tmp/ipykernel_8229/2263042957.py:54: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  session_data['event_datetime'] = pd.to_datetime(session_data['event_datetime'])\n",
      "/tmp/ipykernel_8229/2263042957.py:54: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  session_data['event_datetime'] = pd.to_datetime(session_data['event_datetime'])\n",
      "/tmp/ipykernel_8229/2263042957.py:54: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  session_data['event_datetime'] = pd.to_datetime(session_data['event_datetime'])\n",
      "/tmp/ipykernel_8229/2263042957.py:54: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  session_data['event_datetime'] = pd.to_datetime(session_data['event_datetime'])\n",
      "/tmp/ipykernel_8229/2263042957.py:54: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  session_data['event_datetime'] = pd.to_datetime(session_data['event_datetime'])\n",
      "/tmp/ipykernel_8229/2263042957.py:54: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  session_data['event_datetime'] = pd.to_datetime(session_data['event_datetime'])\n",
      "/tmp/ipykernel_8229/2263042957.py:54: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  session_data['event_datetime'] = pd.to_datetime(session_data['event_datetime'])\n",
      "/tmp/ipykernel_8229/2263042957.py:54: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  session_data['event_datetime'] = pd.to_datetime(session_data['event_datetime'])\n",
      "/tmp/ipykernel_8229/2263042957.py:54: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  session_data['event_datetime'] = pd.to_datetime(session_data['event_datetime'])\n",
      "/tmp/ipykernel_8229/2263042957.py:54: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  session_data['event_datetime'] = pd.to_datetime(session_data['event_datetime'])\n",
      "/tmp/ipykernel_8229/2263042957.py:54: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  session_data['event_datetime'] = pd.to_datetime(session_data['event_datetime'])\n",
      "/tmp/ipykernel_8229/2263042957.py:54: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  session_data['event_datetime'] = pd.to_datetime(session_data['event_datetime'])\n",
      "/tmp/ipykernel_8229/2263042957.py:54: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  session_data['event_datetime'] = pd.to_datetime(session_data['event_datetime'])\n",
      "/tmp/ipykernel_8229/2263042957.py:54: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  session_data['event_datetime'] = pd.to_datetime(session_data['event_datetime'])\n",
      "/tmp/ipykernel_8229/2263042957.py:54: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  session_data['event_datetime'] = pd.to_datetime(session_data['event_datetime'])\n",
      "/tmp/ipykernel_8229/2263042957.py:54: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  session_data['event_datetime'] = pd.to_datetime(session_data['event_datetime'])\n",
      "/tmp/ipykernel_8229/2263042957.py:54: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  session_data['event_datetime'] = pd.to_datetime(session_data['event_datetime'])\n",
      "/tmp/ipykernel_8229/2263042957.py:54: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  session_data['event_datetime'] = pd.to_datetime(session_data['event_datetime'])\n",
      "/tmp/ipykernel_8229/2263042957.py:54: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  session_data['event_datetime'] = pd.to_datetime(session_data['event_datetime'])\n",
      "/tmp/ipykernel_8229/2263042957.py:54: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  session_data['event_datetime'] = pd.to_datetime(session_data['event_datetime'])\n",
      "/tmp/ipykernel_8229/2263042957.py:54: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  session_data['event_datetime'] = pd.to_datetime(session_data['event_datetime'])\n",
      "/tmp/ipykernel_8229/2263042957.py:54: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  session_data['event_datetime'] = pd.to_datetime(session_data['event_datetime'])\n",
      "/tmp/ipykernel_8229/2263042957.py:54: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  session_data['event_datetime'] = pd.to_datetime(session_data['event_datetime'])\n",
      "/tmp/ipykernel_8229/2263042957.py:54: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  session_data['event_datetime'] = pd.to_datetime(session_data['event_datetime'])\n",
      "/tmp/ipykernel_8229/2263042957.py:54: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  session_data['event_datetime'] = pd.to_datetime(session_data['event_datetime'])\n",
      "/tmp/ipykernel_8229/2263042957.py:54: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  session_data['event_datetime'] = pd.to_datetime(session_data['event_datetime'])\n",
      "/tmp/ipykernel_8229/2263042957.py:54: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  session_data['event_datetime'] = pd.to_datetime(session_data['event_datetime'])\n",
      "/tmp/ipykernel_8229/2263042957.py:54: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  session_data['event_datetime'] = pd.to_datetime(session_data['event_datetime'])\n",
      "/tmp/ipykernel_8229/2263042957.py:54: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  session_data['event_datetime'] = pd.to_datetime(session_data['event_datetime'])\n",
      "/tmp/ipykernel_8229/2263042957.py:54: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  session_data['event_datetime'] = pd.to_datetime(session_data['event_datetime'])\n",
      "/tmp/ipykernel_8229/2263042957.py:54: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  session_data['event_datetime'] = pd.to_datetime(session_data['event_datetime'])\n",
      "/tmp/ipykernel_8229/2263042957.py:54: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  session_data['event_datetime'] = pd.to_datetime(session_data['event_datetime'])\n",
      "/tmp/ipykernel_8229/2263042957.py:54: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  session_data['event_datetime'] = pd.to_datetime(session_data['event_datetime'])\n",
      "/tmp/ipykernel_8229/2263042957.py:54: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  session_data['event_datetime'] = pd.to_datetime(session_data['event_datetime'])\n",
      "/tmp/ipykernel_8229/2263042957.py:54: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  session_data['event_datetime'] = pd.to_datetime(session_data['event_datetime'])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "â€¢ í‰ê·  ì„¸ì…˜ ì‹œê°„: 7.2ë¶„\n",
      "â€¢ ì¤‘ê°„ê°’: 0.7ë¶„\n",
      "â€¢ 90ë¶„ìœ„ìˆ˜: 5.9ë¶„\n",
      "\n",
      "ğŸ“Š ì •ìƒ ì„¸ì…˜ ì‹œê°„ ë¶„í¬:\n",
      "â€¢ 1-5ë¶„: 10ê°œ (31.2%)\n",
      "â€¢ 1ë¶„ ë¯¸ë§Œ: 5ê°œ (15.6%)\n",
      "â€¢ 5-15ë¶„: 4ê°œ (12.5%)\n",
      "â€¢ 15-30ë¶„: 1ê°œ (3.1%)\n",
      "â€¢ 60ë¶„ ì´ìƒ: 1ê°œ (3.1%)\n",
      "â€¢ 30-60ë¶„: 0ê°œ (0.0%)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_8229/2263042957.py:54: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  session_data['event_datetime'] = pd.to_datetime(session_data['event_datetime'])\n",
      "/tmp/ipykernel_8229/2263042957.py:54: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  session_data['event_datetime'] = pd.to_datetime(session_data['event_datetime'])\n"
     ]
    }
   ],
   "source": [
    "print(\"ğŸ” ì„¸ì…˜ ë¬¸ì œ ìƒì„¸ ë¶„ì„\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "# ì„¸ì…˜ ì‹œì‘/ì¢…ë£Œ ë¶ˆê· í˜• ë¶„ì„\n",
    "df_events = pd.read_parquet(\n",
    "    \"gs://sprintda05_final_project/hackle/hackle_events.parquet\",\n",
    "    columns=['session_id', 'event_datetime', 'event_key']\n",
    ")\n",
    "\n",
    "print(\"ğŸ“Š ì„¸ì…˜ ì™„ì„±ë„ ë¶„ì„:\")\n",
    "\n",
    "# ê° ì„¸ì…˜ë³„ ì‹œì‘/ì¢…ë£Œ ì´ë²¤íŠ¸ í™•ì¸\n",
    "session_analysis = []\n",
    "unique_sessions = df_events['session_id'].unique()[:1000]  # ìƒ˜í”Œ 1000ê°œ\n",
    "\n",
    "for session_id in unique_sessions:\n",
    "    session_data = df_events[df_events['session_id'] == session_id]\n",
    "    \n",
    "    has_start = '$session_start' in session_data['event_key'].values\n",
    "    has_end = '$session_end' in session_data['event_key'].values\n",
    "    total_events = len(session_data)\n",
    "    \n",
    "    session_analysis.append({\n",
    "        'session_id': session_id,\n",
    "        'has_start': has_start,\n",
    "        'has_end': has_end,\n",
    "        'total_events': total_events,\n",
    "        'status': f\"{'S' if has_start else ''}{'E' if has_end else ''}\"\n",
    "    })\n",
    "\n",
    "analysis_df = pd.DataFrame(session_analysis)\n",
    "status_counts = analysis_df['status'].value_counts()\n",
    "\n",
    "print(\"ì„¸ì…˜ ìƒíƒœë³„ ë¶„í¬:\")\n",
    "for status, count in status_counts.items():\n",
    "    pct = count / len(analysis_df) * 100\n",
    "    status_meaning = {\n",
    "        'SE': 'ì •ìƒ (ì‹œì‘+ì¢…ë£Œ)',\n",
    "        'S': 'ì‹œì‘ë§Œ ìˆìŒ',\n",
    "        'E': 'ì¢…ë£Œë§Œ ìˆìŒ', \n",
    "        '': 'ì‹œì‘/ì¢…ë£Œ ì—†ìŒ'\n",
    "    }.get(status, f'ê¸°íƒ€({status})')\n",
    "    print(f\"â€¢ {status_meaning}: {count}ê°œ ({pct:.1f}%)\")\n",
    "\n",
    "# ì˜¬ë°”ë¥¸ ì„¸ì…˜ ì‹œê°„ ê³„ì‚° (ì‹œì‘+ì¢…ë£Œ ìˆëŠ” ê²ƒë§Œ)\n",
    "normal_sessions = analysis_df[analysis_df['status'] == 'SE']['session_id'].tolist()\n",
    "\n",
    "if normal_sessions:\n",
    "    print(f\"\\nâ° ì •ìƒ ì„¸ì…˜ ì‹œê°„ ì¬ê³„ì‚° ({len(normal_sessions)}ê°œ):\")\n",
    "    \n",
    "    durations = []\n",
    "    for session_id in normal_sessions[:100]:  # 100ê°œë§Œ ìƒ˜í”Œ\n",
    "        session_data = df_events[df_events['session_id'] == session_id]\n",
    "        session_data['event_datetime'] = pd.to_datetime(session_data['event_datetime'])\n",
    "        \n",
    "        start_events = session_data[session_data['event_key'] == '$session_start']\n",
    "        end_events = session_data[session_data['event_key'] == '$session_end']\n",
    "        \n",
    "        if len(start_events) > 0 and len(end_events) > 0:\n",
    "            start_time = start_events['event_datetime'].min()\n",
    "            end_time = end_events['event_datetime'].max()\n",
    "            duration = (end_time - start_time).total_seconds() / 60\n",
    "            \n",
    "            if 0 <= duration <= 300:  # 5ì‹œê°„ ì´í•˜ë§Œ (ì´ìƒì¹˜ ì œì™¸)\n",
    "                durations.append(duration)\n",
    "    \n",
    "    if durations:\n",
    "        durations = pd.Series(durations)\n",
    "        print(f\"â€¢ í‰ê·  ì„¸ì…˜ ì‹œê°„: {durations.mean():.1f}ë¶„\")\n",
    "        print(f\"â€¢ ì¤‘ê°„ê°’: {durations.median():.1f}ë¶„\")\n",
    "        print(f\"â€¢ 90ë¶„ìœ„ìˆ˜: {durations.quantile(0.9):.1f}ë¶„\")\n",
    "        \n",
    "        # ì„¸ì…˜ ì‹œê°„ ë¶„í¬ (ì¬ê³„ì‚°)\n",
    "        duration_ranges = pd.cut(durations, \n",
    "                               bins=[0, 1, 5, 15, 30, 60, float('inf')],\n",
    "                               labels=['1ë¶„ ë¯¸ë§Œ', '1-5ë¶„', '5-15ë¶„', '15-30ë¶„', '30-60ë¶„', '60ë¶„ ì´ìƒ'])\n",
    "        print(f\"\\nğŸ“Š ì •ìƒ ì„¸ì…˜ ì‹œê°„ ë¶„í¬:\")\n",
    "        for range_name, count in duration_ranges.value_counts().items():\n",
    "            pct = count / len(durations) * 100\n",
    "            print(f\"â€¢ {range_name}: {count}ê°œ ({pct:.1f}%)\")\n",
    "\n",
    "del df_events"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9382481",
   "metadata": {},
   "source": [
    "### ì‹¤ì œ ì‚¬ìš©ì ì—¬ì • ì¬ë¶„ì„"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e0805e45",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ğŸ—ºï¸ ì‹¤ì œ ì‚¬ìš©ì ì—¬ì • ì¬ë¶„ì„\n",
      "==================================================\n",
      "ğŸ“± ì •ìƒ ì„¸ì…˜ì˜ ì•± ì‚¬ìš© í”Œë¡œìš°:\n",
      "â€¢ ë¶„ì„ ëŒ€ìƒ ì •ìƒ ì„¸ì…˜: 464ê°œ\n",
      "\n",
      "ğŸ” ì‹¤ì œ ì‚¬ìš©ì í–‰ë™ íŒ¨í„´ (ì‹œìŠ¤í…œ ì´ë²¤íŠ¸ ì œì™¸):\n",
      " 1. launch_app â†’ click_question_start â†’ skip_question\n",
      "    (5íšŒ, 10.0%)\n",
      " 2. launch_app â†’ launch_app â†’ launch_app\n",
      "    (4íšŒ, 8.0%)\n",
      " 3. launch_app â†’ launch_app â†’ view_login\n",
      "    (3íšŒ, 6.0%)\n",
      " 4. launch_app â†’ view_signup â†’ view_signup\n",
      "    (3íšŒ, 6.0%)\n",
      " 5. launch_app â†’ click_bottom_navigation_questions â†’ click_bottom_navigation_questions\n",
      "    (3íšŒ, 6.0%)\n",
      " 6. launch_app â†’ launch_app â†’ click_question_start\n",
      "    (3íšŒ, 6.0%)\n",
      " 7. launch_app â†’ click_bottom_navigation_questions â†’ click_bottom_navigation_timeline\n",
      "    (2íšŒ, 4.0%)\n",
      " 8. launch_app â†’ launch_app â†’ click_question_open\n",
      "    (2íšŒ, 4.0%)\n",
      " 9. launch_app â†’ click_bottom_navigation_profile â†’ view_lab_tap\n",
      "    (2íšŒ, 4.0%)\n",
      "10. launch_app â†’ click_question_open â†’ click_question_open\n",
      "    (2íšŒ, 4.0%)\n",
      "\n",
      "ğŸ“Š ì£¼ìš” ê¸°ëŠ¥ ì´ìš© ìˆœì„œ:\n",
      " 1. view_timeline_tap â†’ view_lab_tap (2014íšŒ)\n",
      " 2. click_question_open â†’ click_question_open (1866íšŒ)\n",
      " 3. view_lab_tap â†’ view_timeline_tap (1647íšŒ)\n",
      " 4. view_lab_tap â†’ view_lab_tap (1339íšŒ)\n",
      " 5. launch_app â†’ launch_app (1132íšŒ)\n",
      " 6. launch_app â†’ view_timeline_tap (854íšŒ)\n",
      " 7. view_lab_tap â†’ click_bottom_navigation_questions (791íšŒ)\n",
      " 8. view_lab_tap â†’ launch_app (773íšŒ)\n",
      " 9. view_timeline_tap â†’ click_bottom_navigation_questions (764íšŒ)\n",
      "10. click_bottom_navigation_questions â†’ view_timeline_tap (662íšŒ)\n"
     ]
    }
   ],
   "source": [
    "print(f\"\\nğŸ—ºï¸ ì‹¤ì œ ì‚¬ìš©ì ì—¬ì • ì¬ë¶„ì„\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "# ì •ìƒì ì¸ ì„¸ì…˜ë§Œìœ¼ë¡œ ì—¬ì • ë¶„ì„\n",
    "df_events = pd.read_parquet(\n",
    "    \"gs://sprintda05_final_project/hackle/hackle_events.parquet\",\n",
    "    columns=['session_id', 'event_datetime', 'event_key']\n",
    ")\n",
    "\n",
    "print(\"ğŸ“± ì •ìƒ ì„¸ì…˜ì˜ ì•± ì‚¬ìš© í”Œë¡œìš°:\")\n",
    "\n",
    "# ì‹œì‘ê³¼ ì¢…ë£Œê°€ ëª¨ë‘ ìˆëŠ” ì„¸ì…˜ë§Œ í•„í„°ë§\n",
    "normal_session_ids = []\n",
    "sample_sessions = df_events['session_id'].unique()[:500]\n",
    "\n",
    "for session_id in sample_sessions:\n",
    "    session_data = df_events[df_events['session_id'] == session_id]\n",
    "    has_start = '$session_start' in session_data['event_key'].values\n",
    "    has_end = '$session_end' in session_data['event_key'].values\n",
    "    \n",
    "    if has_start and has_end and len(session_data) >= 5:  # ìµœì†Œ 5ê°œ ì´ë²¤íŠ¸\n",
    "        normal_session_ids.append(session_id)\n",
    "\n",
    "print(f\"â€¢ ë¶„ì„ ëŒ€ìƒ ì •ìƒ ì„¸ì…˜: {len(normal_session_ids)}ê°œ\")\n",
    "\n",
    "if len(normal_session_ids) >= 50:\n",
    "    journey_patterns = []\n",
    "    \n",
    "    for session_id in normal_session_ids[:50]:\n",
    "        session_data = df_events[df_events['session_id'] == session_id].sort_values('event_datetime')\n",
    "        \n",
    "        # ì„¸ì…˜ ì‹œì‘ í›„ ì‹¤ì œ ì²« í–‰ë™ë“¤\n",
    "        events = session_data['event_key'].tolist()\n",
    "        \n",
    "        # $session_start ì œì™¸í•˜ê³  ì‹¤ì œ ì‚¬ìš©ì í–‰ë™ë§Œ\n",
    "        user_actions = [e for e in events if not e.startswith('$')]\n",
    "        \n",
    "        if len(user_actions) >= 3:\n",
    "            first_actions = ' â†’ '.join(user_actions[:3])\n",
    "            journey_patterns.append(first_actions)\n",
    "    \n",
    "    if journey_patterns:\n",
    "        common_journeys = pd.Series(journey_patterns).value_counts().head(10)\n",
    "        \n",
    "        print(f\"\\nğŸ” ì‹¤ì œ ì‚¬ìš©ì í–‰ë™ íŒ¨í„´ (ì‹œìŠ¤í…œ ì´ë²¤íŠ¸ ì œì™¸):\")\n",
    "        for i, (pattern, count) in enumerate(common_journeys.items(), 1):\n",
    "            pct = count / len(journey_patterns) * 100\n",
    "            print(f\"{i:2d}. {pattern}\")\n",
    "            print(f\"    ({count}íšŒ, {pct:.1f}%)\")\n",
    "\n",
    "# ê¸°ëŠ¥ë³„ ì´ìš© íŒ¨í„´\n",
    "print(f\"\\nğŸ“Š ì£¼ìš” ê¸°ëŠ¥ ì´ìš© ìˆœì„œ:\")\n",
    "main_functions = ['launch_app', 'view_timeline_tap', 'view_lab_tap', \n",
    "                 'click_question_open', 'click_bottom_navigation_questions']\n",
    "\n",
    "function_transitions = []\n",
    "for session_id in normal_session_ids[:100]:\n",
    "    session_data = df_events[df_events['session_id'] == session_id].sort_values('event_datetime')\n",
    "    events = session_data['event_key'].tolist()\n",
    "    \n",
    "    # ì£¼ìš” ê¸°ëŠ¥ë“¤ ê°„ì˜ ì „í™˜ë§Œ ì¶”ì¶œ\n",
    "    main_events = [e for e in events if e in main_functions]\n",
    "    \n",
    "    for i in range(len(main_events) - 1):\n",
    "        transition = f\"{main_events[i]} â†’ {main_events[i+1]}\"\n",
    "        function_transitions.append(transition)\n",
    "\n",
    "if function_transitions:\n",
    "    top_function_transitions = pd.Series(function_transitions).value_counts().head(10)\n",
    "    \n",
    "    for i, (transition, count) in enumerate(top_function_transitions.items(), 1):\n",
    "        print(f\"{i:2d}. {transition} ({count}íšŒ)\")\n",
    "\n",
    "del df_events"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6a7a37c",
   "metadata": {},
   "source": [
    "### ì„¸ì…˜ êµ¬ë¶„ ê¸°ì¤€ ëª…í™•íˆ íŒŒì•…"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "765839c1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ” ì„¸ì…˜ êµ¬ë¶„ ê¸°ì¤€ ëª…í™•íˆ ë¶„ì„\n",
      "============================================================\n",
      "ğŸ“Š 1. ì„¸ì…˜ ID ìƒì„± íŒ¨í„´ ë¶„ì„\n",
      "----------------------------------------\n",
      "ì„¸ì…˜ ID ìƒ˜í”Œ:\n",
      " 1. 4OzYh3seq3VKytpSn5pvQkZNQii1\n",
      " 2. 8QXy31PQxbW9qLzq0Y1dhR8Ypm52\n",
      " 3. 6bcea65d-9f40-46fc-888c-700fe707483f\n",
      " 4. XVYNT6zfhFWqIg9omwg2AHDjTLx2\n",
      " 5. XFB2SPiGfjbVhvJ3Q3DBsaT3m2B3\n",
      " 6. LztzUUFoRxdqTSPgQrX3MAAyNkM2\n",
      " 7. d2b3ca43-4716-4852-b0e2-334848eb66f4\n",
      " 8. 414540BA-1980-4371-BF37-5BFA71158C4D\n",
      " 9. AOMLgbQlhNUGnyvbsrdtbnUcOOc2\n",
      "10. 94860349-d46f-4e98-8505-e96877376cee\n",
      "\n",
      "ì„¸ì…˜ ID ê¸¸ì´ ë¶„í¬:\n",
      "â€¢ 28ìë¦¬: 7,558,915ê°œ\n",
      "â€¢ 36ìë¦¬: 3,882,404ê°œ\n",
      "\n",
      "ğŸ“Š 2. ì„¸ì…˜ ì‹œì‘/ì¢…ë£Œ ì´ë²¤íŠ¸ ìƒì„¸ ë¶„ì„\n",
      "----------------------------------------\n",
      "ì„¸ì…˜ ë‚´ ì‹œì‘ ì´ë²¤íŠ¸ ê°œìˆ˜:\n",
      "â€¢ 1ê°œ: 44ì„¸ì…˜\n",
      "â€¢ 2ê°œ: 142ì„¸ì…˜\n",
      "â€¢ 3ê°œ: 142ì„¸ì…˜\n",
      "â€¢ 4ê°œ: 89ì„¸ì…˜\n",
      "â€¢ 5ê°œ: 59ì„¸ì…˜\n",
      "â€¢ 6ê°œ: 47ì„¸ì…˜\n",
      "â€¢ 7ê°œ: 47ì„¸ì…˜\n",
      "â€¢ 8ê°œ: 29ì„¸ì…˜\n",
      "â€¢ 9ê°œ: 34ì„¸ì…˜\n",
      "â€¢ 10ê°œ: 28ì„¸ì…˜\n",
      "â€¢ 11ê°œ: 13ì„¸ì…˜\n",
      "â€¢ 12ê°œ: 8ì„¸ì…˜\n",
      "â€¢ 13ê°œ: 13ì„¸ì…˜\n",
      "â€¢ 14ê°œ: 21ì„¸ì…˜\n",
      "â€¢ 15ê°œ: 13ì„¸ì…˜\n",
      "â€¢ 16ê°œ: 10ì„¸ì…˜\n",
      "â€¢ 17ê°œ: 6ì„¸ì…˜\n",
      "â€¢ 18ê°œ: 4ì„¸ì…˜\n",
      "â€¢ 19ê°œ: 5ì„¸ì…˜\n",
      "â€¢ 20ê°œ: 6ì„¸ì…˜\n",
      "â€¢ 21ê°œ: 8ì„¸ì…˜\n",
      "â€¢ 22ê°œ: 4ì„¸ì…˜\n",
      "â€¢ 23ê°œ: 7ì„¸ì…˜\n",
      "â€¢ 24ê°œ: 8ì„¸ì…˜\n",
      "â€¢ 25ê°œ: 11ì„¸ì…˜\n",
      "â€¢ 26ê°œ: 4ì„¸ì…˜\n",
      "â€¢ 27ê°œ: 5ì„¸ì…˜\n",
      "â€¢ 28ê°œ: 4ì„¸ì…˜\n",
      "â€¢ 29ê°œ: 6ì„¸ì…˜\n",
      "â€¢ 30ê°œ: 3ì„¸ì…˜\n",
      "â€¢ 31ê°œ: 5ì„¸ì…˜\n",
      "â€¢ 32ê°œ: 5ì„¸ì…˜\n",
      "â€¢ 33ê°œ: 7ì„¸ì…˜\n",
      "â€¢ 34ê°œ: 4ì„¸ì…˜\n",
      "â€¢ 35ê°œ: 4ì„¸ì…˜\n",
      "â€¢ 36ê°œ: 4ì„¸ì…˜\n",
      "â€¢ 37ê°œ: 5ì„¸ì…˜\n",
      "â€¢ 38ê°œ: 6ì„¸ì…˜\n",
      "â€¢ 39ê°œ: 4ì„¸ì…˜\n",
      "â€¢ 40ê°œ: 3ì„¸ì…˜\n",
      "â€¢ 41ê°œ: 2ì„¸ì…˜\n",
      "â€¢ 42ê°œ: 3ì„¸ì…˜\n",
      "â€¢ 43ê°œ: 5ì„¸ì…˜\n",
      "â€¢ 44ê°œ: 3ì„¸ì…˜\n",
      "â€¢ 45ê°œ: 4ì„¸ì…˜\n",
      "â€¢ 46ê°œ: 5ì„¸ì…˜\n",
      "â€¢ 47ê°œ: 2ì„¸ì…˜\n",
      "â€¢ 48ê°œ: 1ì„¸ì…˜\n",
      "â€¢ 49ê°œ: 2ì„¸ì…˜\n",
      "â€¢ 50ê°œ: 2ì„¸ì…˜\n",
      "â€¢ 52ê°œ: 2ì„¸ì…˜\n",
      "â€¢ 53ê°œ: 1ì„¸ì…˜\n",
      "â€¢ 54ê°œ: 2ì„¸ì…˜\n",
      "â€¢ 55ê°œ: 1ì„¸ì…˜\n",
      "â€¢ 57ê°œ: 3ì„¸ì…˜\n",
      "â€¢ 58ê°œ: 2ì„¸ì…˜\n",
      "â€¢ 59ê°œ: 2ì„¸ì…˜\n",
      "â€¢ 60ê°œ: 3ì„¸ì…˜\n",
      "â€¢ 61ê°œ: 1ì„¸ì…˜\n",
      "â€¢ 62ê°œ: 1ì„¸ì…˜\n",
      "â€¢ 63ê°œ: 2ì„¸ì…˜\n",
      "â€¢ 64ê°œ: 1ì„¸ì…˜\n",
      "â€¢ 65ê°œ: 2ì„¸ì…˜\n",
      "â€¢ 66ê°œ: 1ì„¸ì…˜\n",
      "â€¢ 67ê°œ: 1ì„¸ì…˜\n",
      "â€¢ 68ê°œ: 2ì„¸ì…˜\n",
      "â€¢ 69ê°œ: 2ì„¸ì…˜\n",
      "â€¢ 70ê°œ: 3ì„¸ì…˜\n",
      "â€¢ 72ê°œ: 1ì„¸ì…˜\n",
      "â€¢ 73ê°œ: 2ì„¸ì…˜\n",
      "â€¢ 74ê°œ: 1ì„¸ì…˜\n",
      "â€¢ 75ê°œ: 2ì„¸ì…˜\n",
      "â€¢ 76ê°œ: 1ì„¸ì…˜\n",
      "â€¢ 77ê°œ: 2ì„¸ì…˜\n",
      "â€¢ 79ê°œ: 1ì„¸ì…˜\n",
      "â€¢ 82ê°œ: 1ì„¸ì…˜\n",
      "â€¢ 83ê°œ: 1ì„¸ì…˜\n",
      "â€¢ 85ê°œ: 1ì„¸ì…˜\n",
      "â€¢ 86ê°œ: 3ì„¸ì…˜\n",
      "â€¢ 87ê°œ: 2ì„¸ì…˜\n",
      "â€¢ 88ê°œ: 3ì„¸ì…˜\n",
      "â€¢ 89ê°œ: 1ì„¸ì…˜\n",
      "â€¢ 92ê°œ: 1ì„¸ì…˜\n",
      "â€¢ 94ê°œ: 1ì„¸ì…˜\n",
      "â€¢ 95ê°œ: 2ì„¸ì…˜\n",
      "â€¢ 98ê°œ: 1ì„¸ì…˜\n",
      "â€¢ 101ê°œ: 3ì„¸ì…˜\n",
      "â€¢ 104ê°œ: 1ì„¸ì…˜\n",
      "â€¢ 105ê°œ: 1ì„¸ì…˜\n",
      "â€¢ 106ê°œ: 1ì„¸ì…˜\n",
      "â€¢ 110ê°œ: 1ì„¸ì…˜\n",
      "â€¢ 113ê°œ: 1ì„¸ì…˜\n",
      "â€¢ 116ê°œ: 2ì„¸ì…˜\n",
      "â€¢ 117ê°œ: 2ì„¸ì…˜\n",
      "â€¢ 121ê°œ: 1ì„¸ì…˜\n",
      "â€¢ 124ê°œ: 1ì„¸ì…˜\n",
      "â€¢ 125ê°œ: 1ì„¸ì…˜\n",
      "â€¢ 126ê°œ: 1ì„¸ì…˜\n",
      "â€¢ 127ê°œ: 1ì„¸ì…˜\n",
      "â€¢ 130ê°œ: 1ì„¸ì…˜\n",
      "â€¢ 131ê°œ: 2ì„¸ì…˜\n",
      "â€¢ 133ê°œ: 1ì„¸ì…˜\n",
      "â€¢ 134ê°œ: 1ì„¸ì…˜\n",
      "â€¢ 138ê°œ: 1ì„¸ì…˜\n",
      "â€¢ 141ê°œ: 1ì„¸ì…˜\n",
      "â€¢ 143ê°œ: 1ì„¸ì…˜\n",
      "â€¢ 145ê°œ: 1ì„¸ì…˜\n",
      "â€¢ 150ê°œ: 1ì„¸ì…˜\n",
      "â€¢ 151ê°œ: 1ì„¸ì…˜\n",
      "â€¢ 153ê°œ: 1ì„¸ì…˜\n",
      "â€¢ 154ê°œ: 1ì„¸ì…˜\n",
      "â€¢ 157ê°œ: 1ì„¸ì…˜\n",
      "â€¢ 163ê°œ: 1ì„¸ì…˜\n",
      "â€¢ 164ê°œ: 1ì„¸ì…˜\n",
      "â€¢ 166ê°œ: 1ì„¸ì…˜\n",
      "â€¢ 170ê°œ: 1ì„¸ì…˜\n",
      "â€¢ 173ê°œ: 1ì„¸ì…˜\n",
      "â€¢ 178ê°œ: 1ì„¸ì…˜\n",
      "â€¢ 184ê°œ: 1ì„¸ì…˜\n",
      "â€¢ 202ê°œ: 1ì„¸ì…˜\n",
      "â€¢ 205ê°œ: 1ì„¸ì…˜\n",
      "â€¢ 210ê°œ: 1ì„¸ì…˜\n",
      "â€¢ 223ê°œ: 1ì„¸ì…˜\n",
      "â€¢ 227ê°œ: 1ì„¸ì…˜\n",
      "â€¢ 271ê°œ: 1ì„¸ì…˜\n",
      "â€¢ 284ê°œ: 1ì„¸ì…˜\n",
      "\n",
      "ì„¸ì…˜ ë‚´ ì¢…ë£Œ ì´ë²¤íŠ¸ ê°œìˆ˜:\n",
      "â€¢ 0ê°œ: 71ì„¸ì…˜\n",
      "â€¢ 1ê°œ: 216ì„¸ì…˜\n",
      "â€¢ 2ê°œ: 135ì„¸ì…˜\n",
      "â€¢ 3ê°œ: 71ì„¸ì…˜\n",
      "â€¢ 4ê°œ: 55ì„¸ì…˜\n",
      "â€¢ 5ê°œ: 47ì„¸ì…˜\n",
      "â€¢ 6ê°œ: 27ì„¸ì…˜\n",
      "â€¢ 7ê°œ: 31ì„¸ì…˜\n",
      "â€¢ 8ê°œ: 19ì„¸ì…˜\n",
      "â€¢ 9ê°œ: 14ì„¸ì…˜\n",
      "â€¢ 10ê°œ: 8ì„¸ì…˜\n",
      "â€¢ 11ê°œ: 18ì„¸ì…˜\n",
      "â€¢ 12ê°œ: 15ì„¸ì…˜\n",
      "â€¢ 13ê°œ: 8ì„¸ì…˜\n",
      "â€¢ 14ê°œ: 9ì„¸ì…˜\n",
      "â€¢ 15ê°œ: 5ì„¸ì…˜\n",
      "â€¢ 16ê°œ: 5ì„¸ì…˜\n",
      "â€¢ 17ê°œ: 7ì„¸ì…˜\n",
      "â€¢ 18ê°œ: 6ì„¸ì…˜\n",
      "â€¢ 19ê°œ: 5ì„¸ì…˜\n",
      "â€¢ 20ê°œ: 9ì„¸ì…˜\n",
      "â€¢ 21ê°œ: 5ì„¸ì…˜\n",
      "â€¢ 22ê°œ: 8ì„¸ì…˜\n",
      "â€¢ 23ê°œ: 9ì„¸ì…˜\n",
      "â€¢ 24ê°œ: 3ì„¸ì…˜\n",
      "â€¢ 25ê°œ: 4ì„¸ì…˜\n",
      "â€¢ 26ê°œ: 5ì„¸ì…˜\n",
      "â€¢ 27ê°œ: 4ì„¸ì…˜\n",
      "â€¢ 28ê°œ: 7ì„¸ì…˜\n",
      "â€¢ 29ê°œ: 5ì„¸ì…˜\n",
      "â€¢ 30ê°œ: 4ì„¸ì…˜\n",
      "â€¢ 31ê°œ: 4ì„¸ì…˜\n",
      "â€¢ 32ê°œ: 5ì„¸ì…˜\n",
      "â€¢ 33ê°œ: 4ì„¸ì…˜\n",
      "â€¢ 34ê°œ: 1ì„¸ì…˜\n",
      "â€¢ 35ê°œ: 8ì„¸ì…˜\n",
      "â€¢ 36ê°œ: 4ì„¸ì…˜\n",
      "â€¢ 37ê°œ: 5ì„¸ì…˜\n",
      "â€¢ 38ê°œ: 3ì„¸ì…˜\n",
      "â€¢ 39ê°œ: 2ì„¸ì…˜\n",
      "â€¢ 40ê°œ: 6ì„¸ì…˜\n",
      "â€¢ 41ê°œ: 3ì„¸ì…˜\n",
      "â€¢ 42ê°œ: 3ì„¸ì…˜\n",
      "â€¢ 43ê°œ: 2ì„¸ì…˜\n",
      "â€¢ 44ê°œ: 2ì„¸ì…˜\n",
      "â€¢ 45ê°œ: 5ì„¸ì…˜\n",
      "â€¢ 46ê°œ: 1ì„¸ì…˜\n",
      "â€¢ 47ê°œ: 1ì„¸ì…˜\n",
      "â€¢ 48ê°œ: 2ì„¸ì…˜\n",
      "â€¢ 49ê°œ: 2ì„¸ì…˜\n",
      "â€¢ 51ê°œ: 1ì„¸ì…˜\n",
      "â€¢ 52ê°œ: 1ì„¸ì…˜\n",
      "â€¢ 53ê°œ: 2ì„¸ì…˜\n",
      "â€¢ 54ê°œ: 2ì„¸ì…˜\n",
      "â€¢ 55ê°œ: 2ì„¸ì…˜\n",
      "â€¢ 56ê°œ: 1ì„¸ì…˜\n",
      "â€¢ 57ê°œ: 2ì„¸ì…˜\n",
      "â€¢ 58ê°œ: 3ì„¸ì…˜\n",
      "â€¢ 59ê°œ: 1ì„¸ì…˜\n",
      "â€¢ 60ê°œ: 3ì„¸ì…˜\n",
      "â€¢ 61ê°œ: 1ì„¸ì…˜\n",
      "â€¢ 62ê°œ: 1ì„¸ì…˜\n",
      "â€¢ 63ê°œ: 1ì„¸ì…˜\n",
      "â€¢ 65ê°œ: 2ì„¸ì…˜\n",
      "â€¢ 66ê°œ: 4ì„¸ì…˜\n",
      "â€¢ 68ê°œ: 3ì„¸ì…˜\n",
      "â€¢ 70ê°œ: 1ì„¸ì…˜\n",
      "â€¢ 71ê°œ: 1ì„¸ì…˜\n",
      "â€¢ 72ê°œ: 4ì„¸ì…˜\n",
      "â€¢ 74ê°œ: 2ì„¸ì…˜\n",
      "â€¢ 75ê°œ: 1ì„¸ì…˜\n",
      "â€¢ 78ê°œ: 1ì„¸ì…˜\n",
      "â€¢ 81ê°œ: 2ì„¸ì…˜\n",
      "â€¢ 82ê°œ: 1ì„¸ì…˜\n",
      "â€¢ 84ê°œ: 3ì„¸ì…˜\n",
      "â€¢ 86ê°œ: 3ì„¸ì…˜\n",
      "â€¢ 87ê°œ: 2ì„¸ì…˜\n",
      "â€¢ 88ê°œ: 1ì„¸ì…˜\n",
      "â€¢ 90ê°œ: 1ì„¸ì…˜\n",
      "â€¢ 92ê°œ: 1ì„¸ì…˜\n",
      "â€¢ 94ê°œ: 2ì„¸ì…˜\n",
      "â€¢ 95ê°œ: 1ì„¸ì…˜\n",
      "â€¢ 98ê°œ: 1ì„¸ì…˜\n",
      "â€¢ 99ê°œ: 2ì„¸ì…˜\n",
      "â€¢ 104ê°œ: 3ì„¸ì…˜\n",
      "â€¢ 109ê°œ: 1ì„¸ì…˜\n",
      "â€¢ 111ê°œ: 1ì„¸ì…˜\n",
      "â€¢ 113ê°œ: 1ì„¸ì…˜\n",
      "â€¢ 115ê°œ: 2ì„¸ì…˜\n",
      "â€¢ 116ê°œ: 1ì„¸ì…˜\n",
      "â€¢ 120ê°œ: 1ì„¸ì…˜\n",
      "â€¢ 123ê°œ: 2ì„¸ì…˜\n",
      "â€¢ 124ê°œ: 1ì„¸ì…˜\n",
      "â€¢ 127ê°œ: 1ì„¸ì…˜\n",
      "â€¢ 129ê°œ: 3ì„¸ì…˜\n",
      "â€¢ 132ê°œ: 1ì„¸ì…˜\n",
      "â€¢ 133ê°œ: 1ì„¸ì…˜\n",
      "â€¢ 137ê°œ: 1ì„¸ì…˜\n",
      "â€¢ 140ê°œ: 1ì„¸ì…˜\n",
      "â€¢ 142ê°œ: 1ì„¸ì…˜\n",
      "â€¢ 144ê°œ: 1ì„¸ì…˜\n",
      "â€¢ 149ê°œ: 1ì„¸ì…˜\n",
      "â€¢ 151ê°œ: 2ì„¸ì…˜\n",
      "â€¢ 153ê°œ: 1ì„¸ì…˜\n",
      "â€¢ 156ê°œ: 1ì„¸ì…˜\n",
      "â€¢ 162ê°œ: 1ì„¸ì…˜\n",
      "â€¢ 163ê°œ: 1ì„¸ì…˜\n",
      "â€¢ 166ê°œ: 1ì„¸ì…˜\n",
      "â€¢ 170ê°œ: 1ì„¸ì…˜\n",
      "â€¢ 173ê°œ: 1ì„¸ì…˜\n",
      "â€¢ 178ê°œ: 1ì„¸ì…˜\n",
      "â€¢ 184ê°œ: 1ì„¸ì…˜\n",
      "â€¢ 202ê°œ: 1ì„¸ì…˜\n",
      "â€¢ 204ê°œ: 1ì„¸ì…˜\n",
      "â€¢ 209ê°œ: 1ì„¸ì…˜\n",
      "â€¢ 224ê°œ: 1ì„¸ì…˜\n",
      "â€¢ 227ê°œ: 1ì„¸ì…˜\n",
      "â€¢ 270ê°œ: 1ì„¸ì…˜\n",
      "â€¢ 285ê°œ: 1ì„¸ì…˜\n",
      "\n",
      "ğŸ“Š 3. ì„¸ì…˜ ê°„ ì‹œê°„ ê°„ê²© ë¶„ì„\n",
      "----------------------------------------\n",
      "ë™ì¼ ì‚¬ìš©ì ì—°ì† ì„¸ì…˜ ê°„ ì‹œê°„ ê°„ê²©:\n",
      "â€¢ í‰ê· : 373.6ë¶„\n",
      "â€¢ ì¤‘ê°„ê°’: 151.0ë¶„\n",
      "â€¢ ìµœì†Œ: 0.1ë¶„\n",
      "â€¢ 25ë¶„ìœ„: 23.6ë¶„\n",
      "â€¢ 75ë¶„ìœ„: 535.7ë¶„\n",
      "\n",
      "ì„¸ì…˜ ê°„ê²© ë¶„í¬:\n",
      "â€¢ 3ì‹œê°„ ì´ìƒ: 36ê°œ (41.4%)\n",
      "â€¢ 1-3ì‹œê°„: 20ê°œ (23.0%)\n",
      "â€¢ 5-15ë¶„: 10ê°œ (11.5%)\n",
      "â€¢ 15-30ë¶„: 10ê°œ (11.5%)\n",
      "â€¢ 30-60ë¶„: 6ê°œ (6.9%)\n",
      "â€¢ 1-5ë¶„: 3ê°œ (3.4%)\n",
      "â€¢ 1ë¶„ ë¯¸ë§Œ: 2ê°œ (2.3%)\n",
      "\n",
      "ğŸ“Š 4. launch_appê³¼ ì„¸ì…˜ ì‹œì‘ì˜ ê´€ê³„\n",
      "----------------------------------------\n",
      "launch_appê³¼ $session_start ìˆœì„œ:\n",
      "â€¢ ê±°ì˜ ë™ì‹œ: 189ê°œ (100.0%)\n",
      "\n",
      "============================================================\n",
      "ğŸ¯ ì„¸ì…˜ êµ¬ë¶„ ê¸°ì¤€ ê²°ë¡ \n",
      "============================================================\n"
     ]
    }
   ],
   "source": [
    "print(\"ğŸ” ì„¸ì…˜ êµ¬ë¶„ ê¸°ì¤€ ëª…í™•íˆ ë¶„ì„\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# ì„¸ì…˜ íŒ¨í„´ ìƒì„¸ ë¶„ì„\n",
    "df_events = pd.read_parquet(\n",
    "    \"gs://sprintda05_final_project/hackle/hackle_events.parquet\",\n",
    "    columns=['session_id', 'event_datetime', 'event_key']\n",
    ")\n",
    "\n",
    "df_events['event_datetime'] = pd.to_datetime(df_events['event_datetime'])\n",
    "\n",
    "print(\"ğŸ“Š 1. ì„¸ì…˜ ID ìƒì„± íŒ¨í„´ ë¶„ì„\")\n",
    "print(\"-\" * 40)\n",
    "\n",
    "# ì„¸ì…˜ ID ìƒ˜í”Œ í™•ì¸\n",
    "sample_session_ids = df_events['session_id'].unique()[:10]\n",
    "print(\"ì„¸ì…˜ ID ìƒ˜í”Œ:\")\n",
    "for i, session_id in enumerate(sample_session_ids, 1):\n",
    "    print(f\"{i:2d}. {session_id}\")\n",
    "\n",
    "# ì„¸ì…˜ ID ê¸¸ì´ì™€ íŒ¨í„´\n",
    "session_id_lengths = df_events['session_id'].astype(str).str.len().value_counts()\n",
    "print(f\"\\nì„¸ì…˜ ID ê¸¸ì´ ë¶„í¬:\")\n",
    "for length, count in session_id_lengths.head().items():\n",
    "    print(f\"â€¢ {length}ìë¦¬: {count:,}ê°œ\")\n",
    "\n",
    "print(f\"\\nğŸ“Š 2. ì„¸ì…˜ ì‹œì‘/ì¢…ë£Œ ì´ë²¤íŠ¸ ìƒì„¸ ë¶„ì„\")\n",
    "print(\"-\" * 40)\n",
    "\n",
    "# ë™ì¼ ì„¸ì…˜ ë‚´ ì‹œì‘/ì¢…ë£Œ ì´ë²¤íŠ¸ ê°œìˆ˜\n",
    "session_start_end_counts = []\n",
    "sample_sessions = df_events['session_id'].unique()[:1000]\n",
    "\n",
    "for session_id in sample_sessions:\n",
    "    session_data = df_events[df_events['session_id'] == session_id]\n",
    "    \n",
    "    start_count = (session_data['event_key'] == '$session_start').sum()\n",
    "    end_count = (session_data['event_key'] == '$session_end').sum()\n",
    "    total_events = len(session_data)\n",
    "    \n",
    "    session_start_end_counts.append({\n",
    "        'session_id': session_id,\n",
    "        'start_count': start_count,\n",
    "        'end_count': end_count,\n",
    "        'total_events': total_events\n",
    "    })\n",
    "\n",
    "counts_df = pd.DataFrame(session_start_end_counts)\n",
    "\n",
    "print(\"ì„¸ì…˜ ë‚´ ì‹œì‘ ì´ë²¤íŠ¸ ê°œìˆ˜:\")\n",
    "start_dist = counts_df['start_count'].value_counts().sort_index()\n",
    "for count, sessions in start_dist.items():\n",
    "    print(f\"â€¢ {count}ê°œ: {sessions}ì„¸ì…˜\")\n",
    "\n",
    "print(f\"\\nì„¸ì…˜ ë‚´ ì¢…ë£Œ ì´ë²¤íŠ¸ ê°œìˆ˜:\")\n",
    "end_dist = counts_df['end_count'].value_counts().sort_index()\n",
    "for count, sessions in end_dist.items():\n",
    "    print(f\"â€¢ {count}ê°œ: {sessions}ì„¸ì…˜\")\n",
    "\n",
    "print(f\"\\nğŸ“Š 3. ì„¸ì…˜ ê°„ ì‹œê°„ ê°„ê²© ë¶„ì„\")\n",
    "print(\"-\" * 40)\n",
    "\n",
    "# ë™ì¼ ì‚¬ìš©ìì˜ ì—°ì† ì„¸ì…˜ ê°„ ì‹œê°„ ê°„ê²© ë¶„ì„ (hackle_properties í•„ìš”)\n",
    "try:\n",
    "    df_properties = pd.read_parquet(\n",
    "        \"gs://sprintda05_final_project/hackle/hackle_properties.parquet\",\n",
    "        columns=['session_id', 'user_id']\n",
    "    )\n",
    "    \n",
    "    # ì„¸ì…˜ê³¼ ì‚¬ìš©ì ë§¤í•‘\n",
    "    session_user_map = df_properties.set_index('session_id')['user_id'].to_dict()\n",
    "    \n",
    "    # ì‚¬ìš©ìë³„ ì„¸ì…˜ ì‹œê°„ ë¶„ì„\n",
    "    user_sessions = {}\n",
    "    for session_id in sample_sessions[:500]:\n",
    "        if session_id in session_user_map:\n",
    "            user_id = session_user_map[session_id]\n",
    "            session_data = df_events[df_events['session_id'] == session_id]\n",
    "            \n",
    "            if len(session_data) > 0:\n",
    "                session_start_time = session_data['event_datetime'].min()\n",
    "                \n",
    "                if user_id not in user_sessions:\n",
    "                    user_sessions[user_id] = []\n",
    "                user_sessions[user_id].append({\n",
    "                    'session_id': session_id,\n",
    "                    'start_time': session_start_time\n",
    "                })\n",
    "    \n",
    "    # ë™ì¼ ì‚¬ìš©ìì˜ ì—°ì† ì„¸ì…˜ ê°„ê²©\n",
    "    session_gaps = []\n",
    "    for user_id, sessions in user_sessions.items():\n",
    "        if len(sessions) >= 2:\n",
    "            # ì‹œê°„ìˆœ ì •ë ¬\n",
    "            sessions_sorted = sorted(sessions, key=lambda x: x['start_time'])\n",
    "            \n",
    "            for i in range(len(sessions_sorted) - 1):\n",
    "                current_session = sessions_sorted[i]\n",
    "                next_session = sessions_sorted[i + 1]\n",
    "                \n",
    "                gap_minutes = (next_session['start_time'] - current_session['start_time']).total_seconds() / 60\n",
    "                session_gaps.append(gap_minutes)\n",
    "    \n",
    "    if session_gaps:\n",
    "        gaps_series = pd.Series(session_gaps)\n",
    "        print(f\"ë™ì¼ ì‚¬ìš©ì ì—°ì† ì„¸ì…˜ ê°„ ì‹œê°„ ê°„ê²©:\")\n",
    "        print(f\"â€¢ í‰ê· : {gaps_series.mean():.1f}ë¶„\")\n",
    "        print(f\"â€¢ ì¤‘ê°„ê°’: {gaps_series.median():.1f}ë¶„\")\n",
    "        print(f\"â€¢ ìµœì†Œ: {gaps_series.min():.1f}ë¶„\")\n",
    "        print(f\"â€¢ 25ë¶„ìœ„: {gaps_series.quantile(0.25):.1f}ë¶„\")\n",
    "        print(f\"â€¢ 75ë¶„ìœ„: {gaps_series.quantile(0.75):.1f}ë¶„\")\n",
    "        \n",
    "        # ê°„ê²© ë¶„í¬\n",
    "        gap_ranges = pd.cut(gaps_series, \n",
    "                           bins=[0, 1, 5, 15, 30, 60, 180, float('inf')],\n",
    "                           labels=['1ë¶„ ë¯¸ë§Œ', '1-5ë¶„', '5-15ë¶„', '15-30ë¶„', '30-60ë¶„', '1-3ì‹œê°„', '3ì‹œê°„ ì´ìƒ'])\n",
    "        \n",
    "        print(f\"\\nì„¸ì…˜ ê°„ê²© ë¶„í¬:\")\n",
    "        for range_name, count in gap_ranges.value_counts().items():\n",
    "            pct = count / len(session_gaps) * 100\n",
    "            print(f\"â€¢ {range_name}: {count}ê°œ ({pct:.1f}%)\")\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"âŒ ì‚¬ìš©ìë³„ ì„¸ì…˜ ë¶„ì„ ì‹¤íŒ¨: {str(e)[:50]}...\")\n",
    "\n",
    "print(f\"\\nğŸ“Š 4. launch_appê³¼ ì„¸ì…˜ ì‹œì‘ì˜ ê´€ê³„\")\n",
    "print(\"-\" * 40)\n",
    "\n",
    "# launch_appê³¼ $session_startì˜ ì‹œê°„ ê´€ê³„\n",
    "launch_session_patterns = []\n",
    "\n",
    "for session_id in sample_sessions[:200]:\n",
    "    session_data = df_events[df_events['session_id'] == session_id].sort_values('event_datetime')\n",
    "    \n",
    "    launch_events = session_data[session_data['event_key'] == 'launch_app']\n",
    "    start_events = session_data[session_data['event_key'] == '$session_start']\n",
    "    \n",
    "    if len(launch_events) > 0 and len(start_events) > 0:\n",
    "        first_launch = launch_events['event_datetime'].min()\n",
    "        first_start = start_events['event_datetime'].min()\n",
    "        \n",
    "        time_diff = (first_start - first_launch).total_seconds()\n",
    "        \n",
    "        if -300 <= time_diff <= 300:  # 5ë¶„ ì´ë‚´\n",
    "            if time_diff < -1:\n",
    "                pattern = \"session_startê°€ ë¨¼ì €\"\n",
    "            elif time_diff > 1:\n",
    "                pattern = \"launch_appì´ ë¨¼ì €\"\n",
    "            else:\n",
    "                pattern = \"ê±°ì˜ ë™ì‹œ\"\n",
    "            \n",
    "            launch_session_patterns.append(pattern)\n",
    "\n",
    "if launch_session_patterns:\n",
    "    pattern_counts = pd.Series(launch_session_patterns).value_counts()\n",
    "    print(\"launch_appê³¼ $session_start ìˆœì„œ:\")\n",
    "    for pattern, count in pattern_counts.items():\n",
    "        pct = count / len(launch_session_patterns) * 100\n",
    "        print(f\"â€¢ {pattern}: {count}ê°œ ({pct:.1f}%)\")\n",
    "\n",
    "print(f\"\\n\" + \"=\" * 60)\n",
    "print(\"ğŸ¯ ì„¸ì…˜ êµ¬ë¶„ ê¸°ì¤€ ê²°ë¡ \")\n",
    "print(\"=\" * 60)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
