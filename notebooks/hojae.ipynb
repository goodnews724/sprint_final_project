{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a81b2b6a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pandas in /opt/conda/lib/python3.11/site-packages (2.1.4)\n",
      "Collecting google-cloud-storage\n",
      "  Downloading google_cloud_storage-3.1.0-py2.py3-none-any.whl.metadata (12 kB)\n",
      "Collecting pyarrow\n",
      "  Downloading pyarrow-20.0.0-cp311-cp311-manylinux_2_28_aarch64.whl.metadata (3.3 kB)\n",
      "Collecting fsspec\n",
      "  Downloading fsspec-2025.5.1-py3-none-any.whl.metadata (11 kB)\n",
      "Collecting gcsfs\n",
      "  Downloading gcsfs-2025.5.1-py2.py3-none-any.whl.metadata (1.9 kB)\n",
      "Requirement already satisfied: numpy<2,>=1.23.2 in /opt/conda/lib/python3.11/site-packages (from pandas) (1.26.2)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /opt/conda/lib/python3.11/site-packages (from pandas) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in /opt/conda/lib/python3.11/site-packages (from pandas) (2023.3.post1)\n",
      "Requirement already satisfied: tzdata>=2022.1 in /opt/conda/lib/python3.11/site-packages (from pandas) (2025.2)\n",
      "Collecting google-auth<3.0dev,>=2.26.1 (from google-cloud-storage)\n",
      "  Downloading google_auth-2.40.2-py2.py3-none-any.whl.metadata (6.2 kB)\n",
      "Collecting google-api-core<3.0.0dev,>=2.15.0 (from google-cloud-storage)\n",
      "  Downloading google_api_core-2.24.2-py3-none-any.whl.metadata (3.0 kB)\n",
      "Collecting google-cloud-core<3.0dev,>=2.4.2 (from google-cloud-storage)\n",
      "  Downloading google_cloud_core-2.4.3-py2.py3-none-any.whl.metadata (2.7 kB)\n",
      "Collecting google-resumable-media>=2.7.2 (from google-cloud-storage)\n",
      "  Downloading google_resumable_media-2.7.2-py2.py3-none-any.whl.metadata (2.2 kB)\n",
      "Requirement already satisfied: requests<3.0.0dev,>=2.18.0 in /opt/conda/lib/python3.11/site-packages (from google-cloud-storage) (2.31.0)\n",
      "Collecting google-crc32c<2.0dev,>=1.0 (from google-cloud-storage)\n",
      "  Downloading google_crc32c-1.7.1-cp311-cp311-manylinux_2_17_aarch64.manylinux2014_aarch64.whl.metadata (2.3 kB)\n",
      "Collecting aiohttp!=4.0.0a0,!=4.0.0a1 (from gcsfs)\n",
      "  Downloading aiohttp-3.12.2-cp311-cp311-manylinux_2_17_aarch64.manylinux2014_aarch64.whl.metadata (7.6 kB)\n",
      "Requirement already satisfied: decorator>4.1.2 in /opt/conda/lib/python3.11/site-packages (from gcsfs) (5.1.1)\n",
      "Collecting google-auth-oauthlib (from gcsfs)\n",
      "  Downloading google_auth_oauthlib-1.2.2-py3-none-any.whl.metadata (2.7 kB)\n",
      "Collecting aiohappyeyeballs>=2.5.0 (from aiohttp!=4.0.0a0,!=4.0.0a1->gcsfs)\n",
      "  Downloading aiohappyeyeballs-2.6.1-py3-none-any.whl.metadata (5.9 kB)\n",
      "Collecting aiosignal>=1.1.2 (from aiohttp!=4.0.0a0,!=4.0.0a1->gcsfs)\n",
      "  Downloading aiosignal-1.3.2-py2.py3-none-any.whl.metadata (3.8 kB)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /opt/conda/lib/python3.11/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->gcsfs) (23.1.0)\n",
      "Collecting frozenlist>=1.1.1 (from aiohttp!=4.0.0a0,!=4.0.0a1->gcsfs)\n",
      "  Downloading frozenlist-1.6.0-cp311-cp311-manylinux_2_17_aarch64.manylinux2014_aarch64.whl.metadata (16 kB)\n",
      "Collecting multidict<7.0,>=4.5 (from aiohttp!=4.0.0a0,!=4.0.0a1->gcsfs)\n",
      "  Downloading multidict-6.4.4-cp311-cp311-manylinux_2_17_aarch64.manylinux2014_aarch64.whl.metadata (5.3 kB)\n",
      "Collecting propcache>=0.2.0 (from aiohttp!=4.0.0a0,!=4.0.0a1->gcsfs)\n",
      "  Downloading propcache-0.3.1-cp311-cp311-manylinux_2_17_aarch64.manylinux2014_aarch64.whl.metadata (10 kB)\n",
      "Collecting yarl<2.0,>=1.17.0 (from aiohttp!=4.0.0a0,!=4.0.0a1->gcsfs)\n",
      "  Downloading yarl-1.20.0-cp311-cp311-manylinux_2_17_aarch64.manylinux2014_aarch64.whl.metadata (72 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m72.4/72.4 kB\u001b[0m \u001b[31m2.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting googleapis-common-protos<2.0.0,>=1.56.2 (from google-api-core<3.0.0dev,>=2.15.0->google-cloud-storage)\n",
      "  Downloading googleapis_common_protos-1.70.0-py3-none-any.whl.metadata (9.3 kB)\n",
      "Collecting protobuf!=3.20.0,!=3.20.1,!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<7.0.0,>=3.19.5 (from google-api-core<3.0.0dev,>=2.15.0->google-cloud-storage)\n",
      "  Downloading protobuf-6.31.0-cp39-abi3-manylinux2014_aarch64.whl.metadata (593 bytes)\n",
      "Collecting proto-plus<2.0.0,>=1.22.3 (from google-api-core<3.0.0dev,>=2.15.0->google-cloud-storage)\n",
      "  Downloading proto_plus-1.26.1-py3-none-any.whl.metadata (2.2 kB)\n",
      "Collecting cachetools<6.0,>=2.0.0 (from google-auth<3.0dev,>=2.26.1->google-cloud-storage)\n",
      "  Downloading cachetools-5.5.2-py3-none-any.whl.metadata (5.4 kB)\n",
      "Collecting pyasn1-modules>=0.2.1 (from google-auth<3.0dev,>=2.26.1->google-cloud-storage)\n",
      "  Downloading pyasn1_modules-0.4.2-py3-none-any.whl.metadata (3.5 kB)\n",
      "Collecting rsa<5,>=3.1.4 (from google-auth<3.0dev,>=2.26.1->google-cloud-storage)\n",
      "  Downloading rsa-4.9.1-py3-none-any.whl.metadata (5.6 kB)\n",
      "Requirement already satisfied: six>=1.5 in /opt/conda/lib/python3.11/site-packages (from python-dateutil>=2.8.2->pandas) (1.16.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.11/site-packages (from requests<3.0.0dev,>=2.18.0->google-cloud-storage) (3.3.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.11/site-packages (from requests<3.0.0dev,>=2.18.0->google-cloud-storage) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.11/site-packages (from requests<3.0.0dev,>=2.18.0->google-cloud-storage) (2.0.7)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.11/site-packages (from requests<3.0.0dev,>=2.18.0->google-cloud-storage) (2023.7.22)\n",
      "Collecting requests-oauthlib>=0.7.0 (from google-auth-oauthlib->gcsfs)\n",
      "  Downloading requests_oauthlib-2.0.0-py2.py3-none-any.whl.metadata (11 kB)\n",
      "Collecting pyasn1<0.7.0,>=0.6.1 (from pyasn1-modules>=0.2.1->google-auth<3.0dev,>=2.26.1->google-cloud-storage)\n",
      "  Downloading pyasn1-0.6.1-py3-none-any.whl.metadata (8.4 kB)\n",
      "Requirement already satisfied: oauthlib>=3.0.0 in /opt/conda/lib/python3.11/site-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib->gcsfs) (3.2.2)\n",
      "Downloading google_cloud_storage-3.1.0-py2.py3-none-any.whl (174 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m174.9/174.9 kB\u001b[0m \u001b[31m4.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading pyarrow-20.0.0-cp311-cp311-manylinux_2_28_aarch64.whl (40.7 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m40.7/40.7 MB\u001b[0m \u001b[31m4.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading fsspec-2025.5.1-py3-none-any.whl (199 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m199.1/199.1 kB\u001b[0m \u001b[31m4.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading gcsfs-2025.5.1-py2.py3-none-any.whl (36 kB)\n",
      "Downloading aiohttp-3.12.2-cp311-cp311-manylinux_2_17_aarch64.manylinux2014_aarch64.whl (1.7 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.7/1.7 MB\u001b[0m \u001b[31m5.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading google_api_core-2.24.2-py3-none-any.whl (160 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m160.1/160.1 kB\u001b[0m \u001b[31m6.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading google_auth-2.40.2-py2.py3-none-any.whl (216 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m216.1/216.1 kB\u001b[0m \u001b[31m6.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading google_cloud_core-2.4.3-py2.py3-none-any.whl (29 kB)\n",
      "Downloading google_crc32c-1.7.1-cp311-cp311-manylinux_2_17_aarch64.manylinux2014_aarch64.whl (33 kB)\n",
      "Downloading google_resumable_media-2.7.2-py2.py3-none-any.whl (81 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m81.3/81.3 kB\u001b[0m \u001b[31m5.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading google_auth_oauthlib-1.2.2-py3-none-any.whl (19 kB)\n",
      "Downloading aiohappyeyeballs-2.6.1-py3-none-any.whl (15 kB)\n",
      "Downloading aiosignal-1.3.2-py2.py3-none-any.whl (7.6 kB)\n",
      "Downloading cachetools-5.5.2-py3-none-any.whl (10 kB)\n",
      "Downloading frozenlist-1.6.0-cp311-cp311-manylinux_2_17_aarch64.manylinux2014_aarch64.whl (314 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m314.8/314.8 kB\u001b[0m \u001b[31m3.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading googleapis_common_protos-1.70.0-py3-none-any.whl (294 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m294.5/294.5 kB\u001b[0m \u001b[31m3.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading multidict-6.4.4-cp311-cp311-manylinux_2_17_aarch64.manylinux2014_aarch64.whl (226 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m226.7/226.7 kB\u001b[0m \u001b[31m3.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading propcache-0.3.1-cp311-cp311-manylinux_2_17_aarch64.manylinux2014_aarch64.whl (233 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m233.6/233.6 kB\u001b[0m \u001b[31m4.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading proto_plus-1.26.1-py3-none-any.whl (50 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m50.2/50.2 kB\u001b[0m \u001b[31m4.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading protobuf-6.31.0-cp39-abi3-manylinux2014_aarch64.whl (321 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m321.9/321.9 kB\u001b[0m \u001b[31m4.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading pyasn1_modules-0.4.2-py3-none-any.whl (181 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m181.3/181.3 kB\u001b[0m \u001b[31m4.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading requests_oauthlib-2.0.0-py2.py3-none-any.whl (24 kB)\n",
      "Downloading rsa-4.9.1-py3-none-any.whl (34 kB)\n",
      "Downloading yarl-1.20.0-cp311-cp311-manylinux_2_17_aarch64.manylinux2014_aarch64.whl (355 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m355.8/355.8 kB\u001b[0m \u001b[31m5.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading pyasn1-0.6.1-py3-none-any.whl (83 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m83.1/83.1 kB\u001b[0m \u001b[31m3.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: pyasn1, pyarrow, protobuf, propcache, multidict, google-crc32c, fsspec, frozenlist, cachetools, aiohappyeyeballs, yarl, rsa, requests-oauthlib, pyasn1-modules, proto-plus, googleapis-common-protos, google-resumable-media, aiosignal, google-auth, aiohttp, google-auth-oauthlib, google-api-core, google-cloud-core, google-cloud-storage, gcsfs\n",
      "Successfully installed aiohappyeyeballs-2.6.1 aiohttp-3.12.2 aiosignal-1.3.2 cachetools-5.5.2 frozenlist-1.6.0 fsspec-2025.5.1 gcsfs-2025.5.1 google-api-core-2.24.2 google-auth-2.40.2 google-auth-oauthlib-1.2.2 google-cloud-core-2.4.3 google-cloud-storage-3.1.0 google-crc32c-1.7.1 google-resumable-media-2.7.2 googleapis-common-protos-1.70.0 multidict-6.4.4 propcache-0.3.1 proto-plus-1.26.1 protobuf-6.31.0 pyarrow-20.0.0 pyasn1-0.6.1 pyasn1-modules-0.4.2 requests-oauthlib-2.0.0 rsa-4.9.1 yarl-1.20.0\n"
     ]
    }
   ],
   "source": [
    "!pip install pandas google-cloud-storage pyarrow fsspec gcsfs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3ed0400c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "키 파일 경로: /home/jovyan/work/secrets/google_cloud_storage_hojae.json\n",
      "✅ 연결 성공! 프로젝트: sprintda05-hojae2\n",
      "버킷 개수: 1\n",
      "  - sprintda05_final_project\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "# 빠른 연결 테스트용\n",
    "import os\n",
    "from google.cloud import storage\n",
    "\n",
    "# .env 파일이 docker-compose.yaml의 env_file로 로드되므로\n",
    "# 환경 변수가 이미 설정되어 있음!\n",
    "\n",
    "try:\n",
    "    # 환경 변수 확인\n",
    "    print(f\"키 파일 경로: {os.environ.get('GOOGLE_APPLICATION_CREDENTIALS')}\")\n",
    "    \n",
    "    # 바로 사용 가능\n",
    "    client = storage.Client()\n",
    "    print(f\"✅ 연결 성공! 프로젝트: {client.project}\")\n",
    "    \n",
    "    buckets = list(client.list_buckets())\n",
    "    print(f\"버킷 개수: {len(buckets)}\")\n",
    "    \n",
    "    # 버킷 목록\n",
    "    for bucket in buckets:\n",
    "        print(f\"  - {bucket.name}\")\n",
    "        \n",
    "except Exception as e:\n",
    "    print(f\"❌ 연결 실패: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "ddf4dcd8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- 2. GCS Parquet 파일 로드 및 형식 확인 ---\n",
      "📂 다음 Parquet 파일을 불러옵니다: gs://sprintda05_final_project/hackle/hackle_events.parquet\n",
      "\n",
      "✅ Parquet 파일 로드 성공!\n",
      "\n",
      "--- 데이터프레임 상위 5개 행 (hackle_events.head()) ---\n",
      "                               event_id      event_datetime  \\\n",
      "0  00000533-3f1c-4b3b-81f1-0c8f35754b4e 2023-07-18 19:40:17   \n",
      "1  00000716-27e9-4e72-a602-d0ce61784b06 2023-07-18 21:07:24   \n",
      "2  000007c8-68ce-40e6-9b1e-f0e34e8ff9cc 2023-08-06 20:18:03   \n",
      "3  00000981-5e2a-4111-993e-4f1891ad9a53 2023-08-05 01:46:10   \n",
      "4  00000a7a-ba72-4332-b4a9-7910670aaeb2 2023-07-24 15:03:37   \n",
      "\n",
      "                         event_key                            session_id  \\\n",
      "0                   $session_start          4OzYh3seq3VKytpSn5pvQkZNQii1   \n",
      "1              click_question_open          8QXy31PQxbW9qLzq0Y1dhR8Ypm52   \n",
      "2  click_bottom_navigation_profile  6bcea65d-9f40-46fc-888c-700fe707483f   \n",
      "3                        view_shop          XVYNT6zfhFWqIg9omwg2AHDjTLx2   \n",
      "4      click_bottom_navigation_lab          XFB2SPiGfjbVhvJ3Q3DBsaT3m2B3   \n",
      "\n",
      "                                     id item_name page_name  friend_count  \\\n",
      "0  00000533-3f1c-4b3b-81f1-0c8f35754b4e                               NaN   \n",
      "1  00000716-27e9-4e72-a602-d0ce61784b06                              64.0   \n",
      "2  000007c8-68ce-40e6-9b1e-f0e34e8ff9cc                              26.0   \n",
      "3  00000981-5e2a-4111-993e-4f1891ad9a53                              61.0   \n",
      "4  00000a7a-ba72-4332-b4a9-7910670aaeb2                             119.0   \n",
      "\n",
      "   votes_count  heart_balance  question_id  \n",
      "0          NaN            NaN          NaN  \n",
      "1        436.0         4830.0          NaN  \n",
      "2        174.0         4729.0          NaN  \n",
      "3         44.0          142.0          NaN  \n",
      "4        545.0         3287.0          NaN  \n",
      "\n",
      "--- 데이터프레임 정보 (hackle_events.info()) ---\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 11441319 entries, 0 to 11441318\n",
      "Data columns (total 11 columns):\n",
      " #   Column          Dtype         \n",
      "---  ------          -----         \n",
      " 0   event_id        object        \n",
      " 1   event_datetime  datetime64[ms]\n",
      " 2   event_key       object        \n",
      " 3   session_id      object        \n",
      " 4   id              object        \n",
      " 5   item_name       object        \n",
      " 6   page_name       object        \n",
      " 7   friend_count    float64       \n",
      " 8   votes_count     float64       \n",
      " 9   heart_balance   float64       \n",
      " 10  question_id     float64       \n",
      "dtypes: datetime64[ms](1), float64(4), object(6)\n",
      "memory usage: 960.2+ MB\n",
      "\n",
      "--- 데이터프레임 기술 통계 (hackle_events.describe()) ---\n",
      "                                    event_id              event_datetime  \\\n",
      "count                               11441319                    11441319   \n",
      "unique                              11441319                         NaN   \n",
      "top     00000533-3f1c-4b3b-81f1-0c8f35754b4e                         NaN   \n",
      "freq                                       1                         NaN   \n",
      "mean                                     NaN  2023-07-29 01:58:17.236000   \n",
      "min                                      NaN         2023-07-18 00:00:00   \n",
      "25%                                      NaN         2023-07-22 21:31:17   \n",
      "50%                                      NaN         2023-07-28 17:08:58   \n",
      "75%                                      NaN         2023-08-04 17:59:10   \n",
      "max                                      NaN         2023-08-10 23:59:59   \n",
      "std                                      NaN                         NaN   \n",
      "\n",
      "           event_key                            session_id  \\\n",
      "count       11441319                              11441319   \n",
      "unique            44                                253616   \n",
      "top     view_lab_tap  A40CA2FA-CEB6-4E94-857D-7C229ECC2598   \n",
      "freq         1266665                                  8157   \n",
      "mean             NaN                                   NaN   \n",
      "min              NaN                                   NaN   \n",
      "25%              NaN                                   NaN   \n",
      "50%              NaN                                   NaN   \n",
      "75%              NaN                                   NaN   \n",
      "max              NaN                                   NaN   \n",
      "std              NaN                                   NaN   \n",
      "\n",
      "                                          id item_name page_name  \\\n",
      "count                               11441319  11441319  11441319   \n",
      "unique                              11441319         6        13   \n",
      "top     00000533-3f1c-4b3b-81f1-0c8f35754b4e                       \n",
      "freq                                       1  11428280  10652540   \n",
      "mean                                     NaN       NaN       NaN   \n",
      "min                                      NaN       NaN       NaN   \n",
      "25%                                      NaN       NaN       NaN   \n",
      "50%                                      NaN       NaN       NaN   \n",
      "75%                                      NaN       NaN       NaN   \n",
      "max                                      NaN       NaN       NaN   \n",
      "std                                      NaN       NaN       NaN   \n",
      "\n",
      "        friend_count   votes_count  heart_balance    question_id  \n",
      "count   1.068876e+07  1.068676e+07   1.071268e+07  449484.000000  \n",
      "unique           NaN           NaN            NaN            NaN  \n",
      "top              NaN           NaN            NaN            NaN  \n",
      "freq             NaN           NaN            NaN            NaN  \n",
      "mean    5.434357e+01  2.572742e+02   1.626929e+04    2766.385262  \n",
      "min     0.000000e+00  0.000000e+00   0.000000e+00      99.000000  \n",
      "25%     3.200000e+01  9.700000e+01   4.340000e+02    1393.000000  \n",
      "50%     4.900000e+01  2.100000e+02   1.249000e+03    2569.000000  \n",
      "75%     7.100000e+01  3.620000e+02   3.188000e+03    4459.000000  \n",
      "max     1.365000e+03  3.017000e+03   8.849998e+08    5133.000000  \n",
      "std     3.350798e+01  2.180682e+02   3.317340e+06    1599.967343  \n",
      "\n",
      "--- 데이터프레임 행과 열 개수 (hackle_events.shape): (11441319, 11) ---\n",
      "\n",
      "--- 데이터프레임 컬럼 목록 (hackle_events.columns) ---\n",
      "['event_id', 'event_datetime', 'event_key', 'session_id', 'id', 'item_name', 'page_name', 'friend_count', 'votes_count', 'heart_balance', 'question_id']\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "from google.cloud import storage\n",
    "\n",
    "# GCS에서 Parquet 파일 불러오기 및 형식 확인\n",
    "print(\"\\n--- 2. GCS Parquet 파일 로드 및 형식 확인 ---\")\n",
    "gcs_parquet_path = \"gs://sprintda05_final_project/hackle/hackle_events.parquet\"\n",
    "\n",
    "print(f\"📂 다음 Parquet 파일을 불러옵니다: {gcs_parquet_path}\")\n",
    "\n",
    "# pandas를 사용하여 Parquet 파일 불러오기\n",
    "# 'engine'을 'pyarrow'로 명시하여 확실하게 pyarrow 사용\n",
    "# gcsfs가 설치되어 있다면 pandas는 gs:// 경로를 자동으로 처리\n",
    "hackle_events = pd.read_parquet(gcs_parquet_path, engine='pyarrow')\n",
    "\n",
    "print(\"\\n✅ Parquet 파일 로드 성공!\")\n",
    "\n",
    "print(\"\\n--- 데이터프레임 상위 5개 행 (hackle_events.head()) ---\")\n",
    "print(hackle_events.head())\n",
    "\n",
    "print(\"\\n--- 데이터프레임 정보 (hackle_events.info()) ---\")\n",
    "# 각 컬럼의 이름, Non-Null 개수, 데이터 타입(Dtype) 확인\n",
    "hackle_events.info()\n",
    "\n",
    "print(\"\\n--- 데이터프레임 기술 통계 (hackle_events.describe()) ---\")\n",
    "# 숫자형 컬럼에 대한 통계 정보 확인\n",
    "print(hackle_events.describe(include='all')) # 모든 컬럼 타입 포함\n",
    "\n",
    "print(f\"\\n--- 데이터프레임 행과 열 개수 (hackle_events.shape): {hackle_events.shape} ---\")\n",
    "\n",
    "print(\"\\n--- 데이터프레임 컬럼 목록 (hackle_events.columns) ---\")\n",
    "print(hackle_events.columns.tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "bf1f55da",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- 2. GCS Parquet 파일 로드 및 형식 확인 ---\n",
      "📂 다음 Parquet 파일을 불러옵니다: gs://sprintda05_final_project/hackle/user_properties.parquet\n",
      "\n",
      "✅ Parquet 파일 로드 성공!\n",
      "\n",
      "--- 데이터프레임 상위 5개 행 (user_properties.head()) ---\n",
      "   user_id  class gender  grade  school_id\n",
      "0  1000000      1      M      1       1885\n",
      "1  1000009     10      F      2       3869\n",
      "2  1000012     10      F      1       5091\n",
      "3  1000013      8      F      2       1743\n",
      "4  1000015      2      F      3       5078\n",
      "\n",
      "--- 데이터프레임 정보 (user_properties.info()) ---\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 230819 entries, 0 to 230818\n",
      "Data columns (total 5 columns):\n",
      " #   Column     Non-Null Count   Dtype \n",
      "---  ------     --------------   ----- \n",
      " 0   user_id    230819 non-null  object\n",
      " 1   class      230819 non-null  int64 \n",
      " 2   gender     230819 non-null  object\n",
      " 3   grade      230819 non-null  int64 \n",
      " 4   school_id  230819 non-null  int64 \n",
      "dtypes: int64(3), object(2)\n",
      "memory usage: 8.8+ MB\n",
      "\n",
      "--- 데이터프레임 기술 통계 (user_properties.describe()) ---\n",
      "        user_id          class  gender          grade      school_id\n",
      "count    230819  230819.000000  230819  230819.000000  230819.000000\n",
      "unique   230819            NaN       2            NaN            NaN\n",
      "top     1000000            NaN       F            NaN            NaN\n",
      "freq          1            NaN  132610            NaN            NaN\n",
      "mean        NaN       4.594999     NaN       2.002197    3083.383335\n",
      "std         NaN       3.151979     NaN       0.762048    1711.671162\n",
      "min         NaN       1.000000     NaN       1.000000       1.000000\n",
      "25%         NaN       2.000000     NaN       1.000000    1594.000000\n",
      "50%         NaN       4.000000     NaN       2.000000    3138.000000\n",
      "75%         NaN       6.000000     NaN       3.000000    4640.000000\n",
      "max         NaN      20.000000     NaN       3.000000    5964.000000\n",
      "\n",
      "--- 데이터프레임 행과 열 개수 (user_properties.shape): (230819, 5) ---\n",
      "\n",
      "--- 데이터프레임 컬럼 목록 (user_properties.columns) ---\n",
      "['user_id', 'class', 'gender', 'grade', 'school_id']\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "from google.cloud import storage\n",
    "\n",
    "# GCS에서 Parquet 파일 불러오기 및 형식 확인\n",
    "print(\"\\n--- 2. GCS Parquet 파일 로드 및 형식 확인 ---\")\n",
    "gcs_parquet_path = \"gs://sprintda05_final_project/hackle/user_properties.parquet\"\n",
    "\n",
    "print(f\"📂 다음 Parquet 파일을 불러옵니다: {gcs_parquet_path}\")\n",
    "\n",
    "# pandas를 사용하여 Parquet 파일 불러오기\n",
    "# 'engine'을 'pyarrow'로 명시하여 확실하게 pyarrow 사용\n",
    "# gcsfs가 설치되어 있다면 pandas는 gs:// 경로를 자동으로 처리\n",
    "user_properties = pd.read_parquet(gcs_parquet_path, engine='pyarrow')\n",
    "\n",
    "print(\"\\n✅ Parquet 파일 로드 성공!\")\n",
    "\n",
    "print(\"\\n--- 데이터프레임 상위 5개 행 (user_properties.head()) ---\")\n",
    "print(user_properties.head())\n",
    "\n",
    "print(\"\\n--- 데이터프레임 정보 (user_properties.info()) ---\")\n",
    "# 각 컬럼의 이름, Non-Null 개수, 데이터 타입(Dtype) 확인\n",
    "user_properties.info()\n",
    "\n",
    "print(\"\\n--- 데이터프레임 기술 통계 (user_properties.describe()) ---\")\n",
    "# 숫자형 컬럼에 대한 통계 정보 확인\n",
    "print(user_properties.describe(include='all')) # 모든 컬럼 타입 포함\n",
    "\n",
    "print(f\"\\n--- 데이터프레임 행과 열 개수 (user_properties.shape): {user_properties.shape} ---\")\n",
    "\n",
    "print(\"\\n--- 데이터프레임 컬럼 목록 (user_properties.columns) ---\")\n",
    "print(user_properties.columns.tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efadb76e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>class</th>\n",
       "      <th>gender</th>\n",
       "      <th>grade</th>\n",
       "      <th>school_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1000000</td>\n",
       "      <td>1</td>\n",
       "      <td>M</td>\n",
       "      <td>1</td>\n",
       "      <td>1885</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1000009</td>\n",
       "      <td>10</td>\n",
       "      <td>F</td>\n",
       "      <td>2</td>\n",
       "      <td>3869</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1000012</td>\n",
       "      <td>10</td>\n",
       "      <td>F</td>\n",
       "      <td>1</td>\n",
       "      <td>5091</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1000013</td>\n",
       "      <td>8</td>\n",
       "      <td>F</td>\n",
       "      <td>2</td>\n",
       "      <td>1743</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1000015</td>\n",
       "      <td>2</td>\n",
       "      <td>F</td>\n",
       "      <td>3</td>\n",
       "      <td>5078</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>230814</th>\n",
       "      <td>999992</td>\n",
       "      <td>1</td>\n",
       "      <td>M</td>\n",
       "      <td>2</td>\n",
       "      <td>2240</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>230815</th>\n",
       "      <td>999996</td>\n",
       "      <td>5</td>\n",
       "      <td>M</td>\n",
       "      <td>2</td>\n",
       "      <td>365</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>230816</th>\n",
       "      <td>999997</td>\n",
       "      <td>2</td>\n",
       "      <td>M</td>\n",
       "      <td>3</td>\n",
       "      <td>2502</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>230817</th>\n",
       "      <td>nhj4wh46MAf5K0IHDu4DGyRsdWn2</td>\n",
       "      <td>5</td>\n",
       "      <td>F</td>\n",
       "      <td>2</td>\n",
       "      <td>3499</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>230818</th>\n",
       "      <td>nmbzA4awkiRGXX26fT6wpoxURY43</td>\n",
       "      <td>1</td>\n",
       "      <td>F</td>\n",
       "      <td>1</td>\n",
       "      <td>5407</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>230819 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                             user_id  class gender  grade  school_id\n",
       "0                            1000000      1      M      1       1885\n",
       "1                            1000009     10      F      2       3869\n",
       "2                            1000012     10      F      1       5091\n",
       "3                            1000013      8      F      2       1743\n",
       "4                            1000015      2      F      3       5078\n",
       "...                              ...    ...    ...    ...        ...\n",
       "230814                        999992      1      M      2       2240\n",
       "230815                        999996      5      M      2        365\n",
       "230816                        999997      2      M      3       2502\n",
       "230817  nhj4wh46MAf5K0IHDu4DGyRsdWn2      5      F      2       3499\n",
       "230818  nmbzA4awkiRGXX26fT6wpoxURY43      1      F      1       5407\n",
       "\n",
       "[230819 rows x 5 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(user_properties)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c65ce9d6",
   "metadata": {},
   "source": [
    "# 🔍 명세서 모호 부분 정의\n",
    "\n",
    "## 해결할 모호한 점들\n",
    "\n",
    "### accounts_blockrecord\n",
    "- ❓ \"차단 후 차단 해제는 없다. 왜?\" → **실제로 해제 기능이 없는지 확인**\n",
    "- ❓ 차단 이유 목록이 정확한가? → **실제 데이터의 reason 값들 확인**\n",
    "\n",
    "### accounts_nearbyschool  \n",
    "- ❓ \"거리 기준이 뭔지?\" → **distance 단위와 최대값 확정**\n",
    "- ❓ \"반경 50km 내부 추측\" → **실제로 50km가 기준인지 확인**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19e8764d",
   "metadata": {},
   "source": [
    "## 데이터 로드"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f473f20f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# 데이터 로드\n",
    "df_block = pd.read_parquet(\"gs://sprintda05_final_project/votes/accounts_blockrecord.parquet\")\n",
    "df_nearby = pd.read_parquet(\"gs://sprintda05_final_project/votes/accounts_nearbyschool.parquet\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b56a79dc",
   "metadata": {},
   "source": [
    "### 차단 해제 여부 확정"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "06bfd247",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==================================================\n",
      "🔍 차단 해제 기능 존재 여부\n",
      "==================================================\n",
      "총 차단 관계: 19,482건\n",
      "고유 차단 쌍: 18,505쌍\n",
      "중복 차단 쌍: 548쌍\n",
      "\n",
      "⚠️  결론: 차단 해제 후 재차단 가능\n",
      "   → 548쌍이 여러 번 차단됨\n",
      "   → 최대 20번 차단\n"
     ]
    }
   ],
   "source": [
    "# 🚫 차단 해제 기능 존재 여부 확정\n",
    "print(\"=\" * 50)\n",
    "print(\"🔍 차단 해제 기능 존재 여부\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "# 동일 사용자 쌍의 중복 차단 확인\n",
    "duplicate_pairs = df_block.groupby(['user_id', 'block_user_id']).size()\n",
    "repeated_blocks = duplicate_pairs[duplicate_pairs > 1]\n",
    "\n",
    "print(f\"총 차단 관계: {len(df_block):,}건\")\n",
    "print(f\"고유 차단 쌍: {len(duplicate_pairs):,}쌍\")\n",
    "print(f\"중복 차단 쌍: {len(repeated_blocks):,}쌍\")\n",
    "\n",
    "if len(repeated_blocks) == 0:\n",
    "    print(\"\\n✅ 결론: 차단 해제 기능 없음 (또는 해제 시 기록 삭제)\")\n",
    "    print(\"   → 동일 사용자 쌍의 중복 차단이 전혀 없음\")\n",
    "else:\n",
    "    print(f\"\\n⚠️  결론: 차단 해제 후 재차단 가능\")\n",
    "    print(f\"   → {len(repeated_blocks)}쌍이 여러 번 차단됨\")\n",
    "    print(f\"   → 최대 {repeated_blocks.max()}번 차단\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e56ec49",
   "metadata": {},
   "source": [
    "## 차단 사유 정확한 목록 확정"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "08d578c7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==================================================\n",
      "🔍 차단 사유 정확한 목록\n",
      "==================================================\n",
      "📋 실제 데이터의 차단 사유:\n",
      " 1. '그냥...' - 6건 (0.0%)\n",
      " 2. '친구 사이가 어색해짐' - 5,805건 (29.8%)\n",
      " 3. '나랑 관련 없는 질문을 자꾸 보냄' - 1,083건 (5.6%)\n",
      " 4. '기타' - 7건 (0.0%)\n",
      " 5. '모르는 사람임' - 9,640건 (49.5%)\n",
      " 6. '너무 많은 양의 질문을 보냄' - 919건 (4.7%)\n",
      " 7. '사칭 계정' - 2,022건 (10.4%)\n",
      "\n",
      "총 7개 사유\n",
      "\n",
      "🔍 명세서 사유 개수: 7개\n",
      "실제 데이터 사유 개수: 7개\n",
      "\n",
      "✅ 명세서와 실제 데이터 일치\n"
     ]
    }
   ],
   "source": [
    "# 🚫 차단 사유 정확한 목록 확정  \n",
    "print(\"=\" * 50)\n",
    "print(\"🔍 차단 사유 정확한 목록\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "actual_reasons = df_block['reason'].unique()\n",
    "reason_counts = df_block['reason'].value_counts()\n",
    "\n",
    "print(\"📋 실제 데이터의 차단 사유:\")\n",
    "for i, reason in enumerate(actual_reasons, 1):\n",
    "    count = reason_counts[reason]\n",
    "    pct = count / len(df_block) * 100\n",
    "    print(f\"{i:2d}. '{reason}' - {count:,}건 ({pct:.1f}%)\")\n",
    "\n",
    "print(f\"\\n총 {len(actual_reasons)}개 사유\")\n",
    "\n",
    "# 명세서와 비교\n",
    "spec_reasons = ['그냥...', '친구 사이가 어색해짐', '나랑 관련 없는 질문을 자꾸 보냄', \n",
    "                '기타', '모르는 사람임', '너무 많은 양의 질문을 보냄', '사칭 계정']\n",
    "\n",
    "print(f\"\\n🔍 명세서 사유 개수: {len(spec_reasons)}개\")\n",
    "print(f\"실제 데이터 사유 개수: {len(actual_reasons)}개\")\n",
    "\n",
    "missing_in_spec = set(actual_reasons) - set(spec_reasons)\n",
    "missing_in_data = set(spec_reasons) - set(actual_reasons) \n",
    "\n",
    "if missing_in_spec:\n",
    "    print(f\"\\n⚠️  명세서에 없는 사유: {list(missing_in_spec)}\")\n",
    "if missing_in_data:\n",
    "    print(f\"⚠️  데이터에 없는 사유: {list(missing_in_data)}\")\n",
    "if not missing_in_spec and not missing_in_data:\n",
    "    print(\"\\n✅ 명세서와 실제 데이터 일치\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eef67e0c",
   "metadata": {},
   "source": [
    "### 가까운 학교 거리 기준 확정"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5d2551df",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==================================================\n",
      "🔍 가까운 학교 거리 기준 확정\n",
      "==================================================\n",
      "📏 거리 통계:\n",
      "최소값: 0.000000\n",
      "최대값: 49.296594\n",
      "평균값: 0.055338\n",
      "\n",
      "✅ 거리 단위: 킬로미터(km)\n",
      "\n",
      "🎯 50km 기준 분석:\n",
      "50km 이하 관계: 59,500쌍 (100.0%)\n",
      "전체 관계: 59,500쌍\n",
      "\n",
      "✅ 결론: 50km가 가까운 학교 기준으로 확정\n",
      "   → 모든 관계가 50km 이하\n"
     ]
    }
   ],
   "source": [
    "# 🏫 가까운 학교 거리 기준 확정\n",
    "print(\"=\" * 50) \n",
    "print(\"🔍 가까운 학교 거리 기준 확정\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "distances = df_nearby['distance']\n",
    "\n",
    "print(\"📏 거리 통계:\")\n",
    "print(f\"최소값: {distances.min():.6f}\")\n",
    "print(f\"최대값: {distances.max():.6f}\")\n",
    "print(f\"평균값: {distances.mean():.6f}\")\n",
    "\n",
    "# 거리 단위 확정\n",
    "max_dist = distances.max()\n",
    "if max_dist < 100:\n",
    "    unit = \"km\"\n",
    "    print(f\"\\n✅ 거리 단위: 킬로미터(km)\")\n",
    "else:\n",
    "    unit = \"m\" \n",
    "    print(f\"\\n✅ 거리 단위: 미터(m)\")\n",
    "    print(f\"   → 최대 거리: {max_dist/1000:.1f}km\")\n",
    "\n",
    "# 50km 기준 확정\n",
    "if unit == \"km\":\n",
    "    within_50km = (distances <= 50).sum()\n",
    "    exactly_50km = (distances > 49.9) & (distances <= 50.0)\n",
    "else:\n",
    "    within_50km = (distances <= 50000).sum()\n",
    "    exactly_50km = (distances > 49900) & (distances <= 50000)\n",
    "\n",
    "print(f\"\\n🎯 50km 기준 분석:\")\n",
    "print(f\"50km 이하 관계: {within_50km:,}쌍 ({within_50km/len(df_nearby)*100:.1f}%)\")\n",
    "print(f\"전체 관계: {len(df_nearby):,}쌍\")\n",
    "\n",
    "if within_50km == len(df_nearby):\n",
    "    print(\"\\n✅ 결론: 50km가 가까운 학교 기준으로 확정\")\n",
    "    print(\"   → 모든 관계가 50km 이하\")\n",
    "else:\n",
    "    over_50km = len(df_nearby) - within_50km\n",
    "    print(f\"\\n⚠️  50km 초과 관계: {over_50km:,}쌍\")\n",
    "    print(f\"   → 실제 기준: 약 {distances.max():.1f}{unit}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87da2169",
   "metadata": {},
   "source": [
    "### 50km 기준 상세 검증"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1029997f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==================================================\n",
      "🔍 50km 기준 상세 검증\n",
      "==================================================\n",
      "최대 거리: 49.296594\n",
      "최대 거리의 99% 이상인 값들:\n",
      "개수: 6개\n",
      "범위: 49.149385 ~ 49.296594\n",
      "\n",
      "📊 최대값 근처 거리별 개수:\n",
      "0km: 59,403개\n",
      "1km: 33개\n",
      "2km: 46개\n",
      "6km: 9개\n",
      "43km: 1개\n",
      "48km: 2개\n",
      "49km: 6개\n",
      "\n",
      "✅ 최종 결론:\n",
      "가까운 학교 정의: 기준 학교로부터 50km 이내\n"
     ]
    }
   ],
   "source": [
    "# 🏫 50km 기준 상세 검증\n",
    "print(\"=\" * 50)\n",
    "print(\"🔍 50km 기준 상세 검증\") \n",
    "print(\"=\" * 50)\n",
    "\n",
    "# 최대값 근처 분포 확인\n",
    "max_distance = distances.max()\n",
    "near_max = distances[distances > max_distance * 0.99]\n",
    "\n",
    "print(f\"최대 거리: {max_distance:.6f}\")\n",
    "print(f\"최대 거리의 99% 이상인 값들:\")\n",
    "print(f\"개수: {len(near_max):,}개\")\n",
    "print(f\"범위: {near_max.min():.6f} ~ {near_max.max():.6f}\")\n",
    "\n",
    "# 정확히 49.xx나 50.xx 같은 값이 많은지 확인\n",
    "rounded_distances = distances.round(0)\n",
    "rounded_counts = rounded_distances.value_counts().sort_index().tail(10)\n",
    "\n",
    "print(f\"\\n📊 최대값 근처 거리별 개수:\")\n",
    "for dist, count in rounded_counts.items():\n",
    "    print(f\"{int(dist)}{unit}: {count:,}개\")\n",
    "\n",
    "# 임계값 추정\n",
    "if unit == \"km\":\n",
    "    if max_distance > 49.9 and max_distance <= 50.1:\n",
    "        threshold = 50\n",
    "    else:\n",
    "        threshold = int(max_distance) + 1\n",
    "else:\n",
    "    if max_distance > 49900 and max_distance <= 50100:\n",
    "        threshold = 50000  \n",
    "    else:\n",
    "        threshold = int(max_distance/1000) * 1000 + 1000\n",
    "\n",
    "print(f\"\\n✅ 최종 결론:\")\n",
    "print(f\"가까운 학교 정의: 기준 학교로부터 {threshold}{unit if unit=='km' else 'm'} 이내\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b06a1c3",
   "metadata": {},
   "source": [
    "### 정의 완료 요약"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "549b0f45",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "🎯 모호한 부분 정의 완료\n",
      "============================================================\n",
      "✅ accounts_blockrecord:\n",
      "   • 차단 해제 기능: 있음 (중복 차단 548쌍)\n",
      "   • 차단 사유: 7개 확정\n",
      "\n",
      "✅ accounts_nearbyschool:\n",
      "   • 거리 단위: km\n",
      "   • 가까운 학교 기준: 50km 이내\n",
      "   • 전체 관계 수: 59,500쌍\n",
      "\n",
      "🔍 확정된 명세:\n",
      "   • 차단은 해제 가능\n",
      "   • 가까운 학교는 50km 반경 내 모든 학교\n"
     ]
    }
   ],
   "source": [
    "# 📋 모호한 부분 정의 완료 요약\n",
    "print(\"=\" * 60)\n",
    "print(\"🎯 모호한 부분 정의 완료\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "print(\"✅ accounts_blockrecord:\")\n",
    "duplicate_pairs = df_block.groupby(['user_id', 'block_user_id']).size()\n",
    "repeated_blocks = duplicate_pairs[duplicate_pairs > 1]\n",
    "\n",
    "if len(repeated_blocks) == 0:\n",
    "    print(\"   • 차단 해제 기능: 없음 (중복 차단 0건)\")\n",
    "else:\n",
    "    print(f\"   • 차단 해제 기능: 있음 (중복 차단 {len(repeated_blocks)}쌍)\")\n",
    "\n",
    "actual_reasons = df_block['reason'].unique()\n",
    "print(f\"   • 차단 사유: {len(actual_reasons)}개 확정\")\n",
    "\n",
    "print(f\"\\n✅ accounts_nearbyschool:\")\n",
    "max_distance = df_nearby['distance'].max()\n",
    "if max_distance < 100:\n",
    "    unit_str = \"km\"\n",
    "    threshold = 50 if max_distance <= 50.1 else int(max_distance) + 1\n",
    "else:\n",
    "    unit_str = \"m\"  \n",
    "    threshold = 50000 if max_distance <= 50100 else int(max_distance/1000)*1000 + 1000\n",
    "    \n",
    "print(f\"   • 거리 단위: {unit_str}\")\n",
    "print(f\"   • 가까운 학교 기준: {threshold}{unit_str} 이내\")\n",
    "print(f\"   • 전체 관계 수: {len(df_nearby):,}쌍\")\n",
    "\n",
    "print(f\"\\n🔍 확정된 명세:\")\n",
    "print(f\"   • 차단은 해제 {'불가능' if len(repeated_blocks) == 0 else '가능'}\")\n",
    "print(f\"   • 가까운 학교는 {threshold}{unit_str} 반경 내 모든 학교\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d73fde0",
   "metadata": {},
   "source": [
    "## 질문 송수신 개념 정리"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ef4db55",
   "metadata": {},
   "source": [
    "## 🤔 \"질문을 보냈다\"의 정확한 의미\n",
    "\n",
    "### 혼란스러운 표현들\n",
    "- 차단 사유: \"나랑 관련 없는 질문을 자꾸 **보냄**\"\n",
    "- 차단 사유: \"너무 많은 양의 질문을 **보냄**\"  \n",
    "- 하지만 이 앱은 **익명 투표 앱**인데 질문을 직접 보내나?\n",
    "\n",
    "### 가설\n",
    "1. **투표 = 질문 보내기**: A가 질문에서 B를 선택 → B가 \"질문을 받음\"\n",
    "2. **별도 질문 기능**: 투표 외에 직접 질문을 보내는 기능이 있음ㅡ\n",
    "3. **표현상 혼동**: 실제로는 투표인데 \"질문\"이라고 표현"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d5b18b8",
   "metadata": {},
   "source": [
    "### 투표 기록 분석"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f8582281",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🗳️ 투표 기록 테이블 분석\n",
      "==================================================\n",
      "데이터 형태: (1217558, 12)\n",
      "컬럼: ['id', 'status', 'created_at', 'chosen_user_id', 'question_id', 'user_id', 'question_piece_id', 'has_read', 'answer_status', 'answer_updated_at', 'report_count', 'opened_times']\n",
      "\n",
      "상위 5개 행:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>status</th>\n",
       "      <th>created_at</th>\n",
       "      <th>chosen_user_id</th>\n",
       "      <th>question_id</th>\n",
       "      <th>user_id</th>\n",
       "      <th>question_piece_id</th>\n",
       "      <th>has_read</th>\n",
       "      <th>answer_status</th>\n",
       "      <th>answer_updated_at</th>\n",
       "      <th>report_count</th>\n",
       "      <th>opened_times</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>771777</td>\n",
       "      <td>C</td>\n",
       "      <td>2023-04-28 12:27:49</td>\n",
       "      <td>849469</td>\n",
       "      <td>252</td>\n",
       "      <td>849436</td>\n",
       "      <td>998458</td>\n",
       "      <td>0</td>\n",
       "      <td>N</td>\n",
       "      <td>2023-04-28 12:27:49</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>771800</td>\n",
       "      <td>C</td>\n",
       "      <td>2023-04-28 12:28:02</td>\n",
       "      <td>849446</td>\n",
       "      <td>244</td>\n",
       "      <td>849436</td>\n",
       "      <td>998459</td>\n",
       "      <td>0</td>\n",
       "      <td>N</td>\n",
       "      <td>2023-04-28 12:28:02</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>771812</td>\n",
       "      <td>C</td>\n",
       "      <td>2023-04-28 12:28:09</td>\n",
       "      <td>849454</td>\n",
       "      <td>183</td>\n",
       "      <td>849436</td>\n",
       "      <td>998460</td>\n",
       "      <td>1</td>\n",
       "      <td>N</td>\n",
       "      <td>2023-04-28 12:28:09</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>771828</td>\n",
       "      <td>C</td>\n",
       "      <td>2023-04-28 12:28:16</td>\n",
       "      <td>847375</td>\n",
       "      <td>101</td>\n",
       "      <td>849436</td>\n",
       "      <td>998461</td>\n",
       "      <td>0</td>\n",
       "      <td>N</td>\n",
       "      <td>2023-04-28 12:28:16</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>771851</td>\n",
       "      <td>C</td>\n",
       "      <td>2023-04-28 12:28:26</td>\n",
       "      <td>849477</td>\n",
       "      <td>209</td>\n",
       "      <td>849436</td>\n",
       "      <td>998462</td>\n",
       "      <td>1</td>\n",
       "      <td>N</td>\n",
       "      <td>2023-04-28 12:28:26</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       id status          created_at  chosen_user_id  question_id  user_id  \\\n",
       "0  771777      C 2023-04-28 12:27:49          849469          252   849436   \n",
       "1  771800      C 2023-04-28 12:28:02          849446          244   849436   \n",
       "2  771812      C 2023-04-28 12:28:09          849454          183   849436   \n",
       "3  771828      C 2023-04-28 12:28:16          847375          101   849436   \n",
       "4  771851      C 2023-04-28 12:28:26          849477          209   849436   \n",
       "\n",
       "   question_piece_id  has_read answer_status   answer_updated_at  \\\n",
       "0             998458         0             N 2023-04-28 12:27:49   \n",
       "1             998459         0             N 2023-04-28 12:28:02   \n",
       "2             998460         1             N 2023-04-28 12:28:09   \n",
       "3             998461         0             N 2023-04-28 12:28:16   \n",
       "4             998462         1             N 2023-04-28 12:28:26   \n",
       "\n",
       "   report_count  opened_times  \n",
       "0             0             0  \n",
       "1             0             0  \n",
       "2             0             0  \n",
       "3             0             0  \n",
       "4             0             0  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# 투표 기록 테이블 로드 (핵심 테이블)\n",
    "df_vote = pd.read_parquet(\"gs://sprintda05_final_project/votes/accounts_userquestionrecord.parquet\")\n",
    "\n",
    "print(\"🗳️ 투표 기록 테이블 분석\")\n",
    "print(\"=\" * 50)\n",
    "print(f\"데이터 형태: {df_vote.shape}\")\n",
    "print(f\"컬럼: {list(df_vote.columns)}\")\n",
    "print(\"\\n상위 5개 행:\")\n",
    "df_vote.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c74342a",
   "metadata": {},
   "source": [
    "### 투표 → 질문 받기 관계 확인"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "8efcf53c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "📨 투표 = 질문 보내기 관계 분석\n",
      "==================================================\n",
      "가장 많이 투표한 사용자: 2786번\n",
      "평균 투표 횟수: 251.1번\n",
      "가장 많이 투표 받은 사용자: 1239번\n",
      "평균 투표 받은 횟수: 78.9번\n",
      "\n",
      "📊 투표 패턴:\n",
      "총 투표 기록: 1,217,558건\n",
      "투표한 사용자 수: 4,849명\n",
      "투표 받은 사용자 수: 15,426명\n"
     ]
    }
   ],
   "source": [
    "# 투표 기록에서 \"질문 보내기\" 패턴 분석\n",
    "print(\"📨 투표 = 질문 보내기 관계 분석\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "# 사용자별 투표한 횟수 (= 질문 보낸 횟수?)\n",
    "vote_sent = df_vote['user_id'].value_counts()\n",
    "print(f\"가장 많이 투표한 사용자: {vote_sent.max()}번\")\n",
    "print(f\"평균 투표 횟수: {vote_sent.mean():.1f}번\")\n",
    "\n",
    "# 사용자별 투표 받은 횟수 (= 질문 받은 횟수?)  \n",
    "vote_received = df_vote['chosen_user_id'].value_counts()\n",
    "print(f\"가장 많이 투표 받은 사용자: {vote_received.max()}번\")\n",
    "print(f\"평균 투표 받은 횟수: {vote_received.mean():.1f}번\")\n",
    "\n",
    "print(f\"\\n📊 투표 패턴:\")\n",
    "print(f\"총 투표 기록: {len(df_vote):,}건\")\n",
    "print(f\"투표한 사용자 수: {df_vote['user_id'].nunique():,}명\")\n",
    "print(f\"투표 받은 사용자 수: {df_vote['chosen_user_id'].nunique():,}명\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "972c90aa",
   "metadata": {},
   "source": [
    "### 차단 사유와 투표 패턴 연관성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "7dfb8082",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🚫 차단 사유와 투표 패턴 연관 분석\n",
      "==================================================\n",
      "질문 관련 차단 사유:\n",
      "• '나랑 관련 없는 질문을 자꾸 보냄': 1,083건\n",
      "• '너무 많은 양의 질문을 보냄': 919건\n",
      "\n",
      "📈 상관관계 분석:\n",
      "투표 많이 받은 상위 10% 사용자: 1542명\n",
      "이 중 차단당한 사용자: 45명\n",
      "차단당한 비율: 2.9%\n"
     ]
    }
   ],
   "source": [
    "# 차단 사유 재분석\n",
    "df_block = pd.read_parquet(\"gs://sprintda05_final_project/votes/accounts_blockrecord.parquet\")\n",
    "\n",
    "print(\"🚫 차단 사유와 투표 패턴 연관 분석\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "question_related_blocks = df_block[\n",
    "    df_block['reason'].str.contains('질문|보냄', na=False)\n",
    "]['reason'].value_counts()\n",
    "\n",
    "print(\"질문 관련 차단 사유:\")\n",
    "for reason, count in question_related_blocks.items():\n",
    "    print(f\"• '{reason}': {count:,}건\")\n",
    "\n",
    "# 실제로 많이 투표받은 사용자가 많이 차단당했는지 확인\n",
    "if len(vote_received) > 0 and len(df_block) > 0:\n",
    "    # 투표를 많이 받은 상위 10% 사용자\n",
    "    top_vote_receivers = vote_received.head(int(len(vote_received) * 0.1)).index\n",
    "    \n",
    "    # 이들이 차단당한 비율\n",
    "    blocked_users = df_block['block_user_id'].unique()\n",
    "    top_receivers_blocked = len(set(top_vote_receivers) & set(blocked_users))\n",
    "    \n",
    "    print(f\"\\n📈 상관관계 분석:\")\n",
    "    print(f\"투표 많이 받은 상위 10% 사용자: {len(top_vote_receivers)}명\")\n",
    "    print(f\"이 중 차단당한 사용자: {top_receivers_blocked}명\")\n",
    "    print(f\"차단당한 비율: {top_receivers_blocked/len(top_vote_receivers)*100:.1f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "517bf777",
   "metadata": {},
   "source": [
    "### 사용자별 투표 발송/수신 패턴"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b38242bd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "👤 사용자별 투표 발송/수신 패턴\n",
      "==================================================\n",
      "투표를 가장 많이 보낸 사용자들:\n",
      "사용자 849103: 2786번 투표\n",
      "사용자 876509: 1708번 투표\n",
      "사용자 856042: 1701번 투표\n",
      "사용자 1213990: 1695번 투표\n",
      "사용자 1159163: 1656번 투표\n",
      "사용자 1058255: 1544번 투표\n",
      "사용자 1206529: 1544번 투표\n",
      "사용자 952220: 1527번 투표\n",
      "사용자 1170559: 1513번 투표\n",
      "사용자 1236004: 1482번 투표\n",
      "\n",
      "투표를 가장 많이 받은 사용자들:\n",
      "사용자 913265: 1239번 투표받음\n",
      "사용자 1206668: 1054번 투표받음\n",
      "사용자 1402487: 1049번 투표받음\n",
      "사용자 1122686: 1042번 투표받음\n",
      "사용자 994573: 997번 투표받음\n",
      "사용자 1017281: 997번 투표받음\n",
      "사용자 1132932: 993번 투표받음\n",
      "사용자 873259: 971번 투표받음\n",
      "사용자 1207784: 948번 투표받음\n",
      "사용자 1017447: 917번 투표받음\n",
      "\n",
      "💕 가장 빈번한 투표 관계:\n",
      "사용자 1214232 → 사용자 1132932: 887번\n",
      "사용자 952220 → 사용자 907442: 537번\n",
      "사용자 952220 → 사용자 884218: 422번\n",
      "사용자 1401244 → 사용자 968333: 404번\n",
      "사용자 1213990 → 사용자 1206529: 316번\n",
      "사용자 880602 → 사용자 876643: 276번\n",
      "사용자 1170559 → 사용자 1136231: 272번\n",
      "사용자 1395767 → 사용자 1367561: 264번\n",
      "사용자 952220 → 사용자 905351: 262번\n",
      "사용자 1170559 → 사용자 916592: 257번\n",
      "\n",
      "⚠️  동일 사용자 쌍의 과도한 투표 발견!\n",
      "   → 이것이 '너무 많은 질문을 보냄' 차단 사유와 연관될 수 있음\n"
     ]
    }
   ],
   "source": [
    "# 개별 사용자의 투표 발송/수신 패턴 분석\n",
    "print(\"👤 사용자별 투표 발송/수신 패턴\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "# 투표를 많이 보낸 사용자 (= 질문을 많이 보낸 사용자?)\n",
    "top_senders = vote_sent.head(10)\n",
    "print(\"투표를 가장 많이 보낸 사용자들:\")\n",
    "for user_id, count in top_senders.items():\n",
    "    print(f\"사용자 {user_id}: {count}번 투표\")\n",
    "\n",
    "# 투표를 많이 받은 사용자 (= 질문을 많이 받은 사용자?)\n",
    "top_receivers = vote_received.head(10)\n",
    "print(f\"\\n투표를 가장 많이 받은 사용자들:\")\n",
    "for user_id, count in top_receivers.items():\n",
    "    print(f\"사용자 {user_id}: {count}번 투표받음\")\n",
    "\n",
    "# 특정 사용자 쌍의 관계 분석\n",
    "user_pairs = df_vote.groupby(['user_id', 'chosen_user_id']).size().sort_values(ascending=False)\n",
    "top_pairs = user_pairs.head(10)\n",
    "\n",
    "print(f\"\\n💕 가장 빈번한 투표 관계:\")\n",
    "for (sender, receiver), count in top_pairs.items():\n",
    "    print(f\"사용자 {sender} → 사용자 {receiver}: {count}번\")\n",
    "    \n",
    "if top_pairs.iloc[0] > 5:\n",
    "    print(\"\\n⚠️  동일 사용자 쌍의 과도한 투표 발견!\")\n",
    "    print(\"   → 이것이 '너무 많은 질문을 보냄' 차단 사유와 연관될 수 있음\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5cc4528d",
   "metadata": {},
   "source": [
    "### 질문 종류별 분석"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "add89cb3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "❓ 질문 종류와 투표 패턴\n",
      "==================================================\n",
      "총 질문 수: 5025개\n",
      "\n",
      "질문 샘플:\n",
      "1. 가장 신비한 매력이 있는 사람은?\n",
      "2. \"이 사람으로 한 번 살아보고 싶다\" 하는 사람은?\n",
      "3. 미래의 틱톡커는?\n",
      "4. 여기서 제일 특이한 친구는?\n",
      "5. 가장 지켜주고 싶은 사람은?\n",
      "\n",
      "📊 가장 인기있는 질문:\n",
      "• 처음 보는 사람과 가장 빨리 친해질 것 같은 사람은?: 1,996번 투표\n",
      "• 모든 사람과 잘 지낼 것 같은 사람은?: 1,986번 투표\n",
      "• 축제에서 공연을 제일 잘 할거 같은 사람은?: 1,984번 투표\n",
      "• 앞으로의 인생을 가장 재미있게 살것 같은 사람은?: 1,974번 투표\n",
      "• 반려동물과 가장 잘 지낼거 같은 사람은?: 1,956번 투표\n"
     ]
    }
   ],
   "source": [
    "# 질문 테이블과 연결하여 분석\n",
    "df_question = pd.read_parquet(\"gs://sprintda05_final_project/votes/polls_question.parquet\")\n",
    "\n",
    "print(\"❓ 질문 종류와 투표 패턴\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "print(f\"총 질문 수: {len(df_question)}개\")\n",
    "print(\"\\n질문 샘플:\")\n",
    "for i, question in enumerate(df_question['question_text'].head(5), 1):\n",
    "    print(f\"{i}. {question}\")\n",
    "\n",
    "# 질문별 투표 빈도\n",
    "if 'question_id' in df_vote.columns:\n",
    "    question_popularity = df_vote['question_id'].value_counts()\n",
    "    print(f\"\\n📊 가장 인기있는 질문:\")\n",
    "    \n",
    "    # 상위 5개 질문의 실제 내용\n",
    "    top_questions = question_popularity.head(5)\n",
    "    question_dict = df_question.set_index('id')['question_text'].to_dict()\n",
    "    \n",
    "    for question_id, count in top_questions.items():\n",
    "        if question_id in question_dict:\n",
    "            print(f\"• {question_dict[question_id]}: {count:,}번 투표\")\n",
    "        else:\n",
    "            print(f\"• 질문 ID {question_id}: {count:,}번 투표\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b57e9cc",
   "metadata": {},
   "source": [
    "### 결론 도출"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "5555260a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🎯 '질문을 보냈다'의 정확한 의미\n",
      "============================================================\n",
      "📋 분석 결과:\n",
      "• 총 투표 기록: 1,217,558건\n",
      "• 질문 관련 차단: 2,002건\n",
      "• 질문 관련 차단 비율: 10.3%\n",
      "\n",
      "🔍 과도한 투표 관계:\n",
      "• 10번 이상 투표한 사용자 쌍: 32621쌍\n",
      "• 최대 투표 횟수: 887번\n",
      "\n",
      "✅ 최종 결론:\n",
      "'질문을 보냄' = A가 특정 질문에서 B를 반복적으로 선택하는 투표 행위\n",
      "• 동일한 사람을 여러 질문에서 계속 선택하면 '질문을 많이 보낸다'고 인식\n",
      "• 받는 사람 입장에서는 '계속 질문이 온다'고 느끼게 됨\n",
      "\n",
      "📱 앱에서의 실제 흐름:\n",
      "1. A가 '가장 재밌을 것 같은 사람은?'에서 B 선택 (투표)\n",
      "2. B에게 알림: '누군가 당신을 선택했습니다' (= 질문을 받음)\n",
      "3. B가 A를 차단할 때: 'A가 나한테 질문을 보냄'이라고 인식\n"
     ]
    }
   ],
   "source": [
    "# 최종 결론 도출\n",
    "print(\"🎯 '질문을 보냈다'의 정확한 의미\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# 데이터 기반 결론\n",
    "vote_count = len(df_vote)\n",
    "question_blocks = len(df_block[df_block['reason'].str.contains('질문|보냄', na=False)])\n",
    "\n",
    "print(\"📋 분석 결과:\")\n",
    "print(f\"• 총 투표 기록: {vote_count:,}건\")\n",
    "print(f\"• 질문 관련 차단: {question_blocks:,}건\")\n",
    "print(f\"• 질문 관련 차단 비율: {question_blocks/len(df_block)*100:.1f}%\")\n",
    "\n",
    "# 사용자 쌍별 과도한 투표 확인\n",
    "user_pairs = df_vote.groupby(['user_id', 'chosen_user_id']).size()\n",
    "excessive_pairs = user_pairs[user_pairs > 10]  # 10번 이상\n",
    "\n",
    "print(f\"\\n🔍 과도한 투표 관계:\")\n",
    "print(f\"• 10번 이상 투표한 사용자 쌍: {len(excessive_pairs)}쌍\")\n",
    "if len(excessive_pairs) > 0:\n",
    "    print(f\"• 최대 투표 횟수: {excessive_pairs.max()}번\")\n",
    "\n",
    "print(f\"\\n✅ 최종 결론:\")\n",
    "if len(excessive_pairs) > 0:\n",
    "    print(\"'질문을 보냄' = A가 특정 질문에서 B를 반복적으로 선택하는 투표 행위\")\n",
    "    print(\"• 동일한 사람을 여러 질문에서 계속 선택하면 '질문을 많이 보낸다'고 인식\")\n",
    "    print(\"• 받는 사람 입장에서는 '계속 질문이 온다'고 느끼게 됨\")\n",
    "else:\n",
    "    print(\"'질문을 보냄' = 일반적인 투표 행위 (과도한 반복은 거의 없음)\")\n",
    "    \n",
    "print(f\"\\n📱 앱에서의 실제 흐름:\")\n",
    "print(\"1. A가 '가장 재밌을 것 같은 사람은?'에서 B 선택 (투표)\")\n",
    "print(\"2. B에게 알림: '누군가 당신을 선택했습니다' (= 질문을 받음)\")\n",
    "print(\"3. B가 A를 차단할 때: 'A가 나한테 질문을 보냄'이라고 인식\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d2135db",
   "metadata": {},
   "source": [
    "## 🚫 차단 메커니즘 분석\n",
    "\n",
    "### 의문점\n",
    "- 사용자가 **개별 질문/투표**를 차단할 수 있는가?\n",
    "- 개별 질문 차단 시 **해당 투표를 보낸 사용자 전체**가 차단되는가?\n",
    "- 아니면 **개별 질문만** 차단되는가?\n",
    "\n",
    "### 관련 테이블\n",
    "- `accounts_userquestionrecord.status`: **B(Blocked)** 상태 존재\n",
    "- `accounts_blockrecord`: 사용자 간 **전체 차단** 기록\n",
    "- `polls_questionreport`: 질문 자체에 대한 **신고** 기록"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee13cd6f",
   "metadata": {},
   "source": [
    "### 데이터 로드 및 차단 상태 확인"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "5c3cef7e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🔍 투표 기록의 차단 상태 분석\n",
      "==================================================\n",
      "📊 투표 상태별 분포:\n",
      "• C: Closed (닫힘) - 1,156,322건 (95.0%)\n",
      "• I: Initial (초성 열림) - 60,578건 (5.0%)\n",
      "• B: Blocked (차단됨) - 658건 (0.1%)\n",
      "\n",
      "🚫 차단된 개별 투표: 658건\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# 관련 테이블 로드\n",
    "df_vote = pd.read_parquet(\"gs://sprintda05_final_project/votes/accounts_userquestionrecord.parquet\")\n",
    "df_block = pd.read_parquet(\"gs://sprintda05_final_project/votes/accounts_blockrecord.parquet\")\n",
    "\n",
    "print(\"🔍 투표 기록의 차단 상태 분석\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "# status 컬럼 분석\n",
    "if 'status' in df_vote.columns:\n",
    "    status_counts = df_vote['status'].value_counts()\n",
    "    print(\"📊 투표 상태별 분포:\")\n",
    "    for status, count in status_counts.items():\n",
    "        pct = count / len(df_vote) * 100\n",
    "        status_meaning = {\n",
    "            'C': 'Closed (닫힘)',\n",
    "            'I': 'Initial (초성 열림)', \n",
    "            'B': 'Blocked (차단됨)'\n",
    "        }.get(status, f'알 수 없음 ({status})')\n",
    "        print(f\"• {status}: {status_meaning} - {count:,}건 ({pct:.1f}%)\")\n",
    "\n",
    "    blocked_votes = df_vote[df_vote['status'] == 'B']\n",
    "    print(f\"\\n🚫 차단된 개별 투표: {len(blocked_votes):,}건\")\n",
    "else:\n",
    "    print(\"❌ status 컬럼이 없습니다.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c56c2963",
   "metadata": {},
   "source": [
    "### 개별 투표 차단 vs 사용자 전체 차단 관계"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "49d53e93",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🔗 개별 투표 차단과 사용자 전체 차단의 관계\n",
      "============================================================\n",
      "차단된 개별 투표 수: 658건\n",
      "차단된 투표의 고유 (받은사람, 보낸사람) 쌍: 318쌍\n",
      "\n",
      "📊 중복 분석:\n",
      "• 개별 투표 차단 쌍: 318쌍\n",
      "• 사용자 전체 차단 쌍: 19,482쌍\n",
      "• 둘 다 해당하는 쌍: 49쌍\n",
      "• 중복률: 15.4%\n",
      "\n",
      "❌ 결론: 개별 투표 차단과 사용자 차단은 별개 기능\n"
     ]
    }
   ],
   "source": [
    "print(\"🔗 개별 투표 차단과 사용자 전체 차단의 관계\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "if 'status' in df_vote.columns:\n",
    "    # B(Blocked) 상태인 투표들\n",
    "    blocked_votes = df_vote[df_vote['status'] == 'B']\n",
    "    \n",
    "    if len(blocked_votes) > 0:\n",
    "        print(f\"차단된 개별 투표 수: {len(blocked_votes):,}건\")\n",
    "        \n",
    "        # 차단된 투표에서 (받은사람, 보낸사람) 쌍 추출\n",
    "        blocked_pairs = blocked_votes[['chosen_user_id', 'user_id']].drop_duplicates()\n",
    "        print(f\"차단된 투표의 고유 (받은사람, 보낸사람) 쌍: {len(blocked_pairs):,}쌍\")\n",
    "        \n",
    "        # 사용자 전체 차단 기록과 비교\n",
    "        user_block_pairs = df_block[['user_id', 'block_user_id']].copy()\n",
    "        user_block_pairs.columns = ['chosen_user_id', 'user_id']  # 컬럼명 맞춤\n",
    "        \n",
    "        # 개별 투표 차단 쌍이 사용자 전체 차단에도 있는지 확인\n",
    "        merged = blocked_pairs.merge(\n",
    "            user_block_pairs, \n",
    "            on=['chosen_user_id', 'user_id'], \n",
    "            how='inner'\n",
    "        )\n",
    "        \n",
    "        overlap_count = len(merged)\n",
    "        overlap_rate = overlap_count / len(blocked_pairs) * 100\n",
    "        \n",
    "        print(f\"\\n📊 중복 분석:\")\n",
    "        print(f\"• 개별 투표 차단 쌍: {len(blocked_pairs):,}쌍\")\n",
    "        print(f\"• 사용자 전체 차단 쌍: {len(user_block_pairs):,}쌍\")\n",
    "        print(f\"• 둘 다 해당하는 쌍: {overlap_count:,}쌍\")\n",
    "        print(f\"• 중복률: {overlap_rate:.1f}%\")\n",
    "        \n",
    "        if overlap_rate > 80:\n",
    "            print(\"\\n✅ 결론: 개별 투표 차단 시 해당 사용자도 전체 차단됨\")\n",
    "        elif overlap_rate > 20:\n",
    "            print(\"\\n⚠️  결론: 개별 투표 차단과 사용자 차단이 부분적으로 연동\")\n",
    "        else:\n",
    "            print(\"\\n❌ 결론: 개별 투표 차단과 사용자 차단은 별개 기능\")\n",
    "            \n",
    "    else:\n",
    "        print(\"❌ 차단된 개별 투표가 없습니다.\")\n",
    "else:\n",
    "    print(\"❌ status 컬럼을 확인할 수 없습니다.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3be540d",
   "metadata": {},
   "source": [
    "### 개별 투표 차단 패턴 분석"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "b90f1681",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🎯 개별 투표 차단 상세 패턴\n",
      "==================================================\n",
      "📤 개별 투표를 가장 많이 차단당한 사용자 (보낸 사람):\n",
      "• 사용자 850176: 75개 투표 차단당함\n",
      "• 사용자 881393: 43개 투표 차단당함\n",
      "• 사용자 850284: 24개 투표 차단당함\n",
      "• 사용자 877382: 23개 투표 차단당함\n",
      "• 사용자 959401: 22개 투표 차단당함\n",
      "\n",
      "📥 개별 투표를 가장 많이 차단한 사용자 (받은 사람):\n",
      "• 사용자 851717: 24개 투표 차단함\n",
      "• 사용자 874009: 22개 투표 차단함\n",
      "• 사용자 885409: 22개 투표 차단함\n",
      "• 사용자 895204: 21개 투표 차단함\n",
      "• 사용자 880093: 17개 투표 차단함\n",
      "\n",
      "🔄 동일 사용자 쌍의 다중 투표 차단:\n",
      "• 여러 투표가 차단된 쌍: 80쌍\n",
      "• 최대 차단 투표 수: 24개\n",
      "• 해석: 개별 투표를 여러 번 차단 → 사용자 전체 차단으로 이어질 가능성\n"
     ]
    }
   ],
   "source": [
    "print(\"🎯 개별 투표 차단 상세 패턴\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "if 'status' in df_vote.columns:\n",
    "    blocked_votes = df_vote[df_vote['status'] == 'B']\n",
    "    \n",
    "    if len(blocked_votes) > 0:\n",
    "        # 누가 가장 많이 개별 투표를 차단당했는지\n",
    "        blocked_senders = blocked_votes['user_id'].value_counts()\n",
    "        print(\"📤 개별 투표를 가장 많이 차단당한 사용자 (보낸 사람):\")\n",
    "        for user_id, count in blocked_senders.head(5).items():\n",
    "            print(f\"• 사용자 {user_id}: {count}개 투표 차단당함\")\n",
    "        \n",
    "        # 누가 가장 많이 개별 투표를 차단했는지  \n",
    "        blocked_receivers = blocked_votes['chosen_user_id'].value_counts()\n",
    "        print(f\"\\n📥 개별 투표를 가장 많이 차단한 사용자 (받은 사람):\")\n",
    "        for user_id, count in blocked_receivers.head(5).items():\n",
    "            print(f\"• 사용자 {user_id}: {count}개 투표 차단함\")\n",
    "        \n",
    "        # 동일 사용자 쌍에서 여러 투표가 차단되었는지\n",
    "        pair_blocks = blocked_votes.groupby(['chosen_user_id', 'user_id']).size()\n",
    "        multi_blocks = pair_blocks[pair_blocks > 1]\n",
    "        \n",
    "        print(f\"\\n🔄 동일 사용자 쌍의 다중 투표 차단:\")\n",
    "        print(f\"• 여러 투표가 차단된 쌍: {len(multi_blocks):,}쌍\")\n",
    "        if len(multi_blocks) > 0:\n",
    "            print(f\"• 최대 차단 투표 수: {multi_blocks.max()}개\")\n",
    "            print(\"• 해석: 개별 투표를 여러 번 차단 → 사용자 전체 차단으로 이어질 가능성\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08b03b8e",
   "metadata": {},
   "source": [
    "### 시간순 차단 패턴 분석"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "475d7cf5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⏰ 개별 투표 차단과 사용자 차단의 시간적 관계\n",
      "=======================================================\n",
      "동시에 발생한 차단 쌍: 259쌍\n",
      "평균 시간 차이: -195.7시간\n",
      "중간값 시간 차이: -106.7시간\n",
      "\n",
      "📊 1시간 이내 동시 차단: 3쌍 (1.2%)\n",
      "⚠️  개별 투표 차단과 사용자 차단이 시간차를 두고 발생\n"
     ]
    }
   ],
   "source": [
    "print(\"⏰ 개별 투표 차단과 사용자 차단의 시간적 관계\")\n",
    "print(\"=\" * 55)\n",
    "\n",
    "if 'status' in df_vote.columns and len(blocked_votes) > 0:\n",
    "    # 개별 투표 차단 시간 분석\n",
    "    blocked_votes_time = blocked_votes[['chosen_user_id', 'user_id', 'created_at']].copy()\n",
    "    blocked_votes_time['created_at'] = pd.to_datetime(blocked_votes_time['created_at'])\n",
    "    \n",
    "    # 사용자 전체 차단 시간\n",
    "    user_blocks_time = df_block[['user_id', 'block_user_id', 'created_at']].copy()\n",
    "    user_blocks_time['created_at'] = pd.to_datetime(user_blocks_time['created_at'])\n",
    "    user_blocks_time.columns = ['chosen_user_id', 'user_id', 'block_time']\n",
    "    \n",
    "    # 동일 사용자 쌍의 개별 투표 차단과 전체 차단 시간 비교\n",
    "    time_comparison = blocked_votes_time.merge(\n",
    "        user_blocks_time,\n",
    "        on=['chosen_user_id', 'user_id'],\n",
    "        how='inner'\n",
    "    )\n",
    "    \n",
    "    if len(time_comparison) > 0:\n",
    "        # 시간 차이 계산\n",
    "        time_comparison['time_diff'] = (\n",
    "            time_comparison['block_time'] - time_comparison['created_at']\n",
    "        ).dt.total_seconds() / 3600  # 시간 단위\n",
    "        \n",
    "        print(f\"동시에 발생한 차단 쌍: {len(time_comparison):,}쌍\")\n",
    "        print(f\"평균 시간 차이: {time_comparison['time_diff'].mean():.1f}시간\")\n",
    "        print(f\"중간값 시간 차이: {time_comparison['time_diff'].median():.1f}시간\")\n",
    "        \n",
    "        # 동시에 발생한 비율 (1시간 이내)\n",
    "        simultaneous = (time_comparison['time_diff'].abs() <= 1).sum()\n",
    "        simultaneous_rate = simultaneous / len(time_comparison) * 100\n",
    "        \n",
    "        print(f\"\\n📊 1시간 이내 동시 차단: {simultaneous}쌍 ({simultaneous_rate:.1f}%)\")\n",
    "        \n",
    "        if simultaneous_rate > 50:\n",
    "            print(\"✅ 개별 투표 차단과 사용자 차단이 거의 동시에 발생\")\n",
    "            print(\"   → 개별 투표 차단 시 자동으로 사용자 전체 차단되는 것으로 추정\")\n",
    "        else:\n",
    "            print(\"⚠️  개별 투표 차단과 사용자 차단이 시간차를 두고 발생\")\n",
    "    else:\n",
    "        print(\"❌ 동일 사용자 쌍의 시간 비교 데이터가 없습니다.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f546823a",
   "metadata": {},
   "source": [
    "### 최종 결론"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "ff0d50d5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🎯 차단 메커니즘 최종 결론\n",
      "==================================================\n",
      "📋 분석 결과 요약:\n",
      "• 개별 투표 차단 건수: 658건\n",
      "• 개별 투표 차단 쌍: 318쌍\n",
      "• 사용자 전체 차단 쌍: 19,482쌍\n",
      "• 중복률: 15.4%\n",
      "\n",
      "✅ 최종 결론:\n",
      "🔄 개별 투표 차단과 사용자 차단은 독립적 기능\n",
      "   • 투표만 차단하고 사용자는 차단하지 않을 수 있음\n",
      "   • 별도의 차단 옵션 존재\n"
     ]
    }
   ],
   "source": [
    "print(\"🎯 차단 메커니즘 최종 결론\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "# 데이터 기반 결론 도출\n",
    "if 'status' in df_vote.columns:\n",
    "    blocked_votes = df_vote[df_vote['status'] == 'B']\n",
    "    \n",
    "    if len(blocked_votes) > 0:\n",
    "        # 중복률 재계산\n",
    "        blocked_pairs = blocked_votes[['chosen_user_id', 'user_id']].drop_duplicates()\n",
    "        user_block_pairs = df_block[['user_id', 'block_user_id']].copy()\n",
    "        user_block_pairs.columns = ['chosen_user_id', 'user_id']\n",
    "        \n",
    "        merged = blocked_pairs.merge(user_block_pairs, on=['chosen_user_id', 'user_id'], how='inner')\n",
    "        overlap_rate = len(merged) / len(blocked_pairs) * 100 if len(blocked_pairs) > 0 else 0\n",
    "        \n",
    "        print(\"📋 분석 결과 요약:\")\n",
    "        print(f\"• 개별 투표 차단 건수: {len(blocked_votes):,}건\")\n",
    "        print(f\"• 개별 투표 차단 쌍: {len(blocked_pairs):,}쌍\")\n",
    "        print(f\"• 사용자 전체 차단 쌍: {len(user_block_pairs):,}쌍\")\n",
    "        print(f\"• 중복률: {overlap_rate:.1f}%\")\n",
    "        \n",
    "        print(f\"\\n✅ 최종 결론:\")\n",
    "        if overlap_rate > 80:\n",
    "            print(\"🔗 개별 투표 차단 → 해당 사용자 전체 자동 차단\")\n",
    "            print(\"   • 사용자가 특정 투표를 차단하면\")\n",
    "            print(\"   • 그 투표를 보낸 사용자 전체가 차단됨\")\n",
    "            print(\"   • 두 기능이 연동되어 작동\")\n",
    "        elif overlap_rate > 20:\n",
    "            print(\"🔀 개별 투표 차단과 사용자 차단이 부분적으로 연동\")\n",
    "            print(\"   • 일부 경우에만 연동\")\n",
    "            print(\"   • 사용자가 선택적으로 전체 차단 결정\")\n",
    "        else:\n",
    "            print(\"🔄 개별 투표 차단과 사용자 차단은 독립적 기능\")\n",
    "            print(\"   • 투표만 차단하고 사용자는 차단하지 않을 수 있음\")\n",
    "            print(\"   • 별도의 차단 옵션 존재\")\n",
    "            \n",
    "    else:\n",
    "        print(\"❌ 개별 투표 차단 데이터가 없어 분석 불가\")\n",
    "else:\n",
    "    print(\"❌ 투표 상태 데이터가 없어 분석 불가\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca52bf5a",
   "metadata": {},
   "source": [
    "# 🔍 데이터 품질 정의 - 1단계 (전체 데이터셋)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5783844f",
   "metadata": {},
   "source": [
    "## 📋 1단계: votes + hackle 전체 테이블 결측치 정의"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "f447fd19",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🔍 1단계: 전체 데이터셋 결측치 현황 분석\n",
      "======================================================================\n",
      "📊 분석 대상: votes 21개 + hackle 4개 = 총 25개 테이블\n",
      "\n",
      "🗳️  VOTES 데이터셋 분석\n",
      "==================================================\n",
      "\n",
      "📋 accounts_attendance (349,637행 × 3열)\n",
      "   ✅ 결측치 없음\n",
      "\n",
      "📋 accounts_blockrecord (19,482행 × 5열)\n",
      "   ✅ 결측치 없음\n",
      "\n",
      "📋 accounts_failpaymenthistory (163행 × 5열)\n",
      "   • productId: 107개 (65.6%)\n",
      "\n",
      "📋 accounts_friendrequest (17,147,175행 × 6열)\n",
      "   ✅ 결측치 없음\n",
      "\n",
      "📋 accounts_group (84,515행 × 4열)\n",
      "   ✅ 결측치 없음\n",
      "\n",
      "📋 accounts_nearbyschool (59,500행 × 4열)\n",
      "   ✅ 결측치 없음\n",
      "\n",
      "📋 accounts_paymenthistory (95,140행 × 5열)\n",
      "   ✅ 결측치 없음\n",
      "\n",
      "📋 accounts_user_contacts (5,063행 × 4열)\n",
      "   ✅ 결측치 없음\n",
      "\n",
      "📋 accounts_pointhistory (2,338,918행 × 5열)\n",
      "   • user_question_record_id: 2,992개 (0.1%)\n",
      "\n",
      "📋 accounts_school (5,951행 × 4열)\n",
      "   ✅ 결측치 없음\n",
      "\n",
      "📋 accounts_timelinereport (208행 × 6열)\n",
      "   ✅ 결측치 없음\n",
      "\n",
      "📋 accounts_user (677,085행 × 16열)\n",
      "   • gender: 2개 (0.0%)\n",
      "   • group_id: 3개 (0.0%)\n",
      "\n",
      "📋 accounts_userquestionrecord (1,217,558행 × 12열)\n",
      "   ✅ 결측치 없음\n",
      "\n",
      "📋 accounts_userwithdraw (70,764행 × 3열)\n",
      "   ✅ 결측치 없음\n",
      "\n",
      "📋 event_receipts (309행 × 5열)\n",
      "   ✅ 결측치 없음\n",
      "\n",
      "📋 events (3행 × 6열)\n",
      "   ✅ 결측치 없음\n",
      "\n",
      "📋 polls_question (5,025행 × 3열)\n",
      "   ✅ 결측치 없음\n",
      "\n",
      "📋 polls_questionpiece (1,265,476행 × 5열)\n",
      "   ✅ 결측치 없음\n",
      "\n",
      "📋 polls_questionreport (51,424행 × 5열)\n",
      "   ✅ 결측치 없음\n",
      "\n",
      "📋 polls_questionset (158,384행 × 6열)\n",
      "   ✅ 결측치 없음\n",
      "\n",
      "📋 polls_usercandidate (4,769,609행 × 4열)\n",
      "   ✅ 결측치 없음\n",
      "\n",
      "📱 HACKLE 데이터셋 분석\n",
      "==================================================\n",
      "\n",
      "📋 hackle_properties (525,350행 × 8열)\n",
      "   ✅ 결측치 없음\n",
      "\n",
      "📋 device_properties (252,380행 × 4열)\n",
      "   ✅ 결측치 없음\n",
      "\n",
      "📋 hackle_events (11,441,319행 × 11열)\n",
      "   • friend_count: 752,556개 (6.6%)\n",
      "   • votes_count: 754,554개 (6.6%)\n",
      "   • heart_balance: 728,643개 (6.4%)\n",
      "   • question_id: 10,991,835개 (96.1%)\n",
      "\n",
      "📋 user_properties (230,819행 × 5열)\n",
      "   ✅ 결측치 없음\n",
      "\n",
      "======================================================================\n",
      "📊 결측치 전체 요약\n",
      "======================================================================\n",
      "🔴 결측치 비율 TOP 15:\n",
      "• [hackle] hackle_events.question_id: 96.1% (10,991,835/11,441,319)\n",
      "• [votes] accounts_failpaymenthistory.productId: 65.6% (107/163)\n",
      "• [hackle] hackle_events.votes_count: 6.6% (754,554/11,441,319)\n",
      "• [hackle] hackle_events.friend_count: 6.6% (752,556/11,441,319)\n",
      "• [hackle] hackle_events.heart_balance: 6.4% (728,643/11,441,319)\n",
      "• [votes] accounts_pointhistory.user_question_record_id: 0.1% (2,992/2,338,918)\n",
      "• [votes] accounts_user.group_id: 0.0% (3/677,085)\n",
      "• [votes] accounts_user.gender: 0.0% (2/677,085)\n",
      "\n",
      "📋 데이터셋별 결측치 현황:\n",
      "• hackle: 1개 테이블에서 총 13,227,588개 결측치\n",
      "• votes: 3개 테이블에서 총 3,104개 결측치\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# votes 테이블 목록 (21개)\n",
    "votes_tables = [\n",
    "    'accounts_attendance', 'accounts_blockrecord', 'accounts_failpaymenthistory',\n",
    "    'accounts_friendrequest', 'accounts_group', 'accounts_nearbyschool', \n",
    "    'accounts_paymenthistory', 'accounts_user_contacts', 'accounts_pointhistory',\n",
    "    'accounts_school', 'accounts_timelinereport', 'accounts_user',\n",
    "    'accounts_userquestionrecord', 'accounts_userwithdraw', 'event_receipts',\n",
    "    'events', 'polls_question', 'polls_questionpiece', 'polls_questionreport',\n",
    "    'polls_questionset', 'polls_usercandidate'\n",
    "]\n",
    "\n",
    "# hackle 테이블 목록 (4개)\n",
    "hackle_tables = [\n",
    "    'hackle_properties', 'device_properties', 'hackle_events', 'user_properties'\n",
    "]\n",
    "\n",
    "print(\"🔍 1단계: 전체 데이터셋 결측치 현황 분석\")\n",
    "print(\"=\" * 70)\n",
    "print(f\"📊 분석 대상: votes {len(votes_tables)}개 + hackle {len(hackle_tables)}개 = 총 {len(votes_tables + hackle_tables)}개 테이블\")\n",
    "\n",
    "# 모든 테이블의 결측치 현황 수집\n",
    "missing_summary = []\n",
    "\n",
    "# votes 테이블 분석\n",
    "print(f\"\\n🗳️  VOTES 데이터셋 분석\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "for table_name in votes_tables:\n",
    "    try:\n",
    "        df = pd.read_parquet(f\"gs://sprintda05_final_project/votes/{table_name}.parquet\")\n",
    "        \n",
    "        print(f\"\\n📋 {table_name} ({df.shape[0]:,}행 × {df.shape[1]}열)\")\n",
    "        \n",
    "        # 결측치 계산\n",
    "        nulls = df.isnull().sum()\n",
    "        total_rows = len(df)\n",
    "        \n",
    "        # 결측치가 있는 컬럼만 출력\n",
    "        has_nulls = False\n",
    "        for col, null_count in nulls.items():\n",
    "            if null_count > 0:\n",
    "                null_pct = (null_count / total_rows) * 100\n",
    "                print(f\"   • {col}: {null_count:,}개 ({null_pct:.1f}%)\")\n",
    "                has_nulls = True\n",
    "                \n",
    "                missing_summary.append({\n",
    "                    'dataset': 'votes',\n",
    "                    'table': table_name,\n",
    "                    'column': col,\n",
    "                    'missing_count': null_count,\n",
    "                    'missing_pct': null_pct,\n",
    "                    'total_rows': total_rows\n",
    "                })\n",
    "        \n",
    "        if not has_nulls:\n",
    "            print(\"   ✅ 결측치 없음\")\n",
    "            \n",
    "    except Exception as e:\n",
    "        print(f\"   ❌ 로드 실패: {str(e)[:30]}...\")\n",
    "\n",
    "# hackle 테이블 분석  \n",
    "print(f\"\\n📱 HACKLE 데이터셋 분석\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "for table_name in hackle_tables:\n",
    "    try:\n",
    "        df = pd.read_parquet(f\"gs://sprintda05_final_project/hackle/{table_name}.parquet\")\n",
    "        \n",
    "        print(f\"\\n📋 {table_name} ({df.shape[0]:,}행 × {df.shape[1]}열)\")\n",
    "        \n",
    "        # 결측치 계산\n",
    "        nulls = df.isnull().sum()\n",
    "        total_rows = len(df)\n",
    "        \n",
    "        # 결측치가 있는 컬럼만 출력\n",
    "        has_nulls = False\n",
    "        for col, null_count in nulls.items():\n",
    "            if null_count > 0:\n",
    "                null_pct = (null_count / total_rows) * 100\n",
    "                print(f\"   • {col}: {null_count:,}개 ({null_pct:.1f}%)\")\n",
    "                has_nulls = True\n",
    "                \n",
    "                missing_summary.append({\n",
    "                    'dataset': 'hackle',\n",
    "                    'table': table_name,\n",
    "                    'column': col,\n",
    "                    'missing_count': null_count,\n",
    "                    'missing_pct': null_pct,\n",
    "                    'total_rows': total_rows\n",
    "                })\n",
    "        \n",
    "        if not has_nulls:\n",
    "            print(\"   ✅ 결측치 없음\")\n",
    "            \n",
    "    except Exception as e:\n",
    "        print(f\"   ❌ 로드 실패: {str(e)[:30]}...\")\n",
    "\n",
    "# 전체 요약\n",
    "print(f\"\\n\" + \"=\" * 70)\n",
    "print(\"📊 결측치 전체 요약\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "if missing_summary:\n",
    "    missing_df = pd.DataFrame(missing_summary)\n",
    "    \n",
    "    # 결측치 비율이 높은 순으로 정렬\n",
    "    print(\"🔴 결측치 비율 TOP 15:\")\n",
    "    top_missing = missing_df.nlargest(15, 'missing_pct')\n",
    "    \n",
    "    for _, row in top_missing.iterrows():\n",
    "        print(f\"• [{row['dataset']}] {row['table']}.{row['column']}: {row['missing_pct']:.1f}% ({row['missing_count']:,}/{row['total_rows']:,})\")\n",
    "    \n",
    "    # 데이터셋별 요약\n",
    "    print(f\"\\n📋 데이터셋별 결측치 현황:\")\n",
    "    dataset_summary = missing_df.groupby('dataset').agg({\n",
    "        'missing_count': 'sum',\n",
    "        'table': 'nunique'\n",
    "    }).reset_index()\n",
    "    \n",
    "    for _, row in dataset_summary.iterrows():\n",
    "        print(f\"• {row['dataset']}: {row['table']}개 테이블에서 총 {row['missing_count']:,}개 결측치\")\n",
    "        \n",
    "else:\n",
    "    print(\"✅ 모든 테이블에 결측치 없음!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d562e65",
   "metadata": {},
   "source": [
    "### 결측치 패턴 상세 분석"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "f96582ce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🔍 결측치 의미 상세 분석\n",
      "==================================================\n",
      "📱 hackle_events.question_id 결측 패턴:\n",
      "• 전체 이벤트: 11,441,319건\n",
      "• question_id 있음: 449,484건 (3.9%)\n",
      "• question_id 없음: 10,991,835건 (96.1%)\n",
      "\n",
      "📊 question_id가 있는 이벤트 타입:\n",
      "• skip_question: 449,484건\n",
      "\n",
      "📊 question_id가 없는 이벤트 타입 (상위 10개):\n",
      "• view_lab_tap: 1,266,665건\n",
      "• view_timeline_tap: 1,194,508건\n",
      "• $session_start: 1,036,852건\n",
      "• launch_app: 986,388건\n",
      "• click_question_open: 816,801건\n",
      "• click_bottom_navigation_questions: 769,163건\n",
      "• click_bottom_navigation_profile: 653,507건\n",
      "• $session_end: 649,658건\n",
      "• click_bottom_navigation_timeline: 536,051건\n",
      "• click_bottom_navigation_lab: 453,683건\n",
      "\n",
      "💳 accounts_failpaymenthistory.productId 결측 패턴:\n",
      "• 전체 실패 기록: 163건\n",
      "• productId 있음: 56건\n",
      "• productId 없음: 107건\n",
      "\n",
      "📱 플랫폼별 productId 결측:\n",
      "• A: 0/56 (0.0%)\n",
      "• I: 107/107 (100.0%)\n"
     ]
    }
   ],
   "source": [
    "# 결측치 패턴 상세 분석\n",
    "print(\"🔍 결측치 의미 상세 분석\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "# 1. hackle_events의 question_id 결측 패턴\n",
    "df_events = pd.read_parquet(\"gs://sprintda05_final_project/hackle/hackle_events.parquet\")\n",
    "\n",
    "print(\"📱 hackle_events.question_id 결측 패턴:\")\n",
    "question_null = df_events['question_id'].isnull()\n",
    "print(f\"• 전체 이벤트: {len(df_events):,}건\")\n",
    "print(f\"• question_id 있음: {(~question_null).sum():,}건 ({(~question_null).mean()*100:.1f}%)\")\n",
    "print(f\"• question_id 없음: {question_null.sum():,}건 ({question_null.mean()*100:.1f}%)\")\n",
    "\n",
    "# question_id가 있는 이벤트 타입들\n",
    "events_with_questions = df_events[~question_null]['event_key'].value_counts()\n",
    "print(f\"\\n📊 question_id가 있는 이벤트 타입:\")\n",
    "for event, count in events_with_questions.head(10).items():\n",
    "    print(f\"• {event}: {count:,}건\")\n",
    "\n",
    "# question_id가 없는 이벤트 타입들  \n",
    "events_without_questions = df_events[question_null]['event_key'].value_counts() \n",
    "print(f\"\\n📊 question_id가 없는 이벤트 타입 (상위 10개):\")\n",
    "for event, count in events_without_questions.head(10).items():\n",
    "    print(f\"• {event}: {count:,}건\")\n",
    "\n",
    "# 2. 결제 실패 productId 결측 패턴\n",
    "df_fail = pd.read_parquet(\"gs://sprintda05_final_project/votes/accounts_failpaymenthistory.parquet\")\n",
    "\n",
    "print(f\"\\n💳 accounts_failpaymenthistory.productId 결측 패턴:\")\n",
    "print(f\"• 전체 실패 기록: {len(df_fail):,}건\")\n",
    "print(f\"• productId 있음: {df_fail['productId'].notna().sum():,}건\")\n",
    "print(f\"• productId 없음: {df_fail['productId'].isna().sum():,}건\")\n",
    "\n",
    "# 플랫폼별 결측 패턴\n",
    "platform_missing = df_fail.groupby('phone_type')['productId'].apply(lambda x: x.isna().sum())\n",
    "platform_total = df_fail.groupby('phone_type').size()\n",
    "\n",
    "print(f\"\\n📱 플랫폼별 productId 결측:\")\n",
    "for platform in platform_missing.index:\n",
    "    missing = platform_missing[platform] \n",
    "    total = platform_total[platform]\n",
    "    pct = (missing / total) * 100\n",
    "    print(f\"• {platform}: {missing}/{total} ({pct:.1f}%)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f55425c4",
   "metadata": {},
   "source": [
    "## 중복값 현황 파악"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "38951573",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🔍 2단계: 중복값 현황 분석\n",
      "==================================================\n",
      "\n",
      "📋 accounts_user 중복 분석 (677,085행)\n",
      "----------------------------------------\n",
      "• 완전 중복 행: 0개 (0.00%)\n",
      "• ID 중복: 0개\n",
      "\n",
      "📋 accounts_userquestionrecord 중복 분석 (1,217,558행)\n",
      "----------------------------------------\n",
      "• 완전 중복 행: 0개 (0.00%)\n",
      "• (사용자, 질문) 중복 투표: 0개\n",
      "\n",
      "📋 accounts_blockrecord 중복 분석 (19,482행)\n",
      "----------------------------------------\n",
      "• 완전 중복 행: 0개 (0.00%)\n",
      "• (차단자, 피차단자) 중복: 977개\n",
      "\n",
      "📋 accounts_friendrequest 중복 분석 (17,147,175행)\n",
      "----------------------------------------\n",
      "• 완전 중복 행: 0개 (0.00%)\n",
      "\n",
      "📋 polls_question 중복 분석 (5,025행)\n",
      "----------------------------------------\n",
      "• 완전 중복 행: 0개 (0.00%)\n",
      "• 동일 질문 텍스트 중복: 1,122개\n",
      "\n",
      "📋 hackle_events 중복 분석 (11,441,319행)\n",
      "----------------------------------------\n",
      "• 완전 중복 행: 0개 (0.00%)\n",
      "• (세션, 시간, 이벤트) 중복: 195,860개\n",
      "\n",
      "==================================================\n",
      "📊 중복값 요약\n",
      "==================================================\n",
      "🔴 중복 비율 순:\n",
      "• accounts_user: 중복 없음\n",
      "• accounts_userquestionrecord: 중복 없음\n",
      "• accounts_blockrecord: 중복 없음\n",
      "• accounts_friendrequest: 중복 없음\n",
      "• polls_question: 중복 없음\n",
      "• hackle_events: 중복 없음\n"
     ]
    }
   ],
   "source": [
    "print(\"🔍 2단계: 중복값 현황 분석\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "# 주요 테이블들의 중복 패턴 확인\n",
    "tables_to_check = [\n",
    "    'accounts_user', 'accounts_userquestionrecord', 'accounts_blockrecord',\n",
    "    'accounts_friendrequest', 'polls_question', 'hackle_events'\n",
    "]\n",
    "\n",
    "duplicate_summary = []\n",
    "\n",
    "for table_name in tables_to_check:\n",
    "    try:\n",
    "        if table_name in ['hackle_events', 'hackle_properties', 'device_properties', 'user_properties']:\n",
    "            df = pd.read_parquet(f\"gs://sprintda05_final_project/hackle/{table_name}.parquet\")\n",
    "        else:\n",
    "            df = pd.read_parquet(f\"gs://sprintda05_final_project/votes/{table_name}.parquet\")\n",
    "        \n",
    "        print(f\"\\n📋 {table_name} 중복 분석 ({df.shape[0]:,}행)\")\n",
    "        print(\"-\" * 40)\n",
    "        \n",
    "        # 1. 전체 행 중복\n",
    "        total_duplicates = df.duplicated().sum()\n",
    "        duplicate_pct = (total_duplicates / len(df)) * 100\n",
    "        print(f\"• 완전 중복 행: {total_duplicates:,}개 ({duplicate_pct:.2f}%)\")\n",
    "        \n",
    "        # 2. 핵심 컬럼별 중복 (테이블별로 다르게)\n",
    "        if table_name == 'accounts_user':\n",
    "            # 사용자 테이블: ID 중복 확인\n",
    "            id_duplicates = df['id'].duplicated().sum()\n",
    "            print(f\"• ID 중복: {id_duplicates:,}개\")\n",
    "            \n",
    "        elif table_name == 'accounts_userquestionrecord':\n",
    "            # 투표 기록: 동일 사용자가 동일 질문에 여러 투표\n",
    "            vote_duplicates = df.duplicated(subset=['user_id', 'question_piece_id']).sum()\n",
    "            print(f\"• (사용자, 질문) 중복 투표: {vote_duplicates:,}개\")\n",
    "            \n",
    "        elif table_name == 'accounts_blockrecord':\n",
    "            # 차단 기록: 동일 차단 쌍\n",
    "            block_duplicates = df.duplicated(subset=['user_id', 'block_user_id']).sum()\n",
    "            print(f\"• (차단자, 피차단자) 중복: {block_duplicates:,}개\")\n",
    "            \n",
    "        elif table_name == 'polls_question':\n",
    "            # 질문: 동일 텍스트 중복\n",
    "            text_duplicates = df.duplicated(subset=['question_text']).sum()\n",
    "            print(f\"• 동일 질문 텍스트 중복: {text_duplicates:,}개\")\n",
    "            \n",
    "        elif table_name == 'hackle_events':\n",
    "            # 이벤트: 동일 세션+시간 중복\n",
    "            event_duplicates = df.duplicated(subset=['session_id', 'event_datetime', 'event_key']).sum()\n",
    "            print(f\"• (세션, 시간, 이벤트) 중복: {event_duplicates:,}개\")\n",
    "            \n",
    "            # 완전 동일한 이벤트 (모든 컬럼)\n",
    "            if total_duplicates > 0:\n",
    "                print(f\"• 완전 동일 이벤트: {total_duplicates:,}개\")\n",
    "        \n",
    "        # 요약 정보 저장\n",
    "        duplicate_summary.append({\n",
    "            'table': table_name,\n",
    "            'total_rows': len(df),\n",
    "            'duplicate_rows': total_duplicates,\n",
    "            'duplicate_pct': duplicate_pct\n",
    "        })\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"❌ {table_name} 분석 실패: {str(e)[:50]}...\")\n",
    "\n",
    "# 전체 요약\n",
    "print(f\"\\n\" + \"=\" * 50)\n",
    "print(\"📊 중복값 요약\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "if duplicate_summary:\n",
    "    duplicate_df = pd.DataFrame(duplicate_summary)\n",
    "    duplicate_df = duplicate_df.sort_values('duplicate_pct', ascending=False)\n",
    "    \n",
    "    print(\"🔴 중복 비율 순:\")\n",
    "    for _, row in duplicate_df.iterrows():\n",
    "        if row['duplicate_rows'] > 0:\n",
    "            print(f\"• {row['table']}: {row['duplicate_pct']:.3f}% ({row['duplicate_rows']:,}/{row['total_rows']:,})\")\n",
    "        else:\n",
    "            print(f\"• {row['table']}: 중복 없음\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71e2aad7",
   "metadata": {},
   "source": [
    "## 3단계: 데이터 일관성(Data Consistency) 정의"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2bf4e7cd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🔍 3단계: 전체 데이터 메모리 효율적 일관성 분석\n",
      "============================================================\n",
      "📥 1단계: 참조 기준 데이터 로드\n",
      "----------------------------------------\n",
      "✅ 사용자 ID 집합: 677,085개\n",
      "✅ 질문 ID 집합: 5,025개\n",
      "\n",
      "🔗 2단계: 참조 무결성 검사\n",
      "----------------------------------------\n",
      "• 투표 기록 참조 무결성 검사 중...\n",
      "  - 총 투표 기록: 1,217,558건\n",
      "    진행: 500,000/1,217,558 (41.1%)\n",
      "    진행: 1,000,000/1,217,558 (82.1%)\n",
      "  ✅ 투표 기록 검사 완료\n",
      "    - 사용자 참조 오류: 0개\n",
      "    - 질문 참조 오류: 0개\n",
      "\n",
      "• 차단 기록 참조 무결성 검사...\n",
      "  ✅ 차단 기록 검사 완료\n",
      "    - 총 차단 기록: 19,482건\n",
      "    - 사용자 참조 오류: 0개\n",
      "\n",
      "📊 3단계: 시간 데이터 일관성\n",
      "----------------------------------------\n",
      "• 사용자 가입 기간: 2023-03-29 03:44:14.047130 ~ 2024-05-09 08:31:17.710824\n",
      "• 미래 날짜: 0개\n",
      "• 포인트 범위: 0 ~ 885000006\n",
      "• 음수 포인트 사용자: 0명\n",
      "\n",
      "============================================================\n",
      "📋 전체 데이터 일관성 검사 결과\n",
      "============================================================\n",
      "✅ 주요 일관성 문제 없음\n",
      "\n",
      "💾 메모리 효율적 처리 완료!\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import gc  # 가비지 컬렉션\n",
    "\n",
    "print(\"🔍 3단계: 전체 데이터 메모리 효율적 일관성 분석\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# 1. 작은 테이블부터 처리하여 참조 기준 생성\n",
    "print(\"📥 1단계: 참조 기준 데이터 로드\")\n",
    "print(\"-\" * 40)\n",
    "\n",
    "# 사용자 ID 집합 생성\n",
    "user_ids = pd.read_parquet(\n",
    "    \"gs://sprintda05_final_project/votes/accounts_user.parquet\",\n",
    "    columns=['id']\n",
    ")['id'].values\n",
    "existing_users = set(user_ids)\n",
    "del user_ids\n",
    "gc.collect()\n",
    "print(f\"✅ 사용자 ID 집합: {len(existing_users):,}개\")\n",
    "\n",
    "# 질문 ID 집합 생성\n",
    "question_ids = pd.read_parquet(\n",
    "    \"gs://sprintda05_final_project/votes/polls_question.parquet\",\n",
    "    columns=['id']\n",
    ")['id'].values\n",
    "existing_questions = set(question_ids)\n",
    "del question_ids\n",
    "gc.collect()\n",
    "print(f\"✅ 질문 ID 집합: {len(existing_questions):,}개\")\n",
    "\n",
    "print(f\"\\n🔗 2단계: 참조 무결성 검사\")\n",
    "print(\"-\" * 40)\n",
    "\n",
    "# 투표 기록 - 청크 단위로 처리\n",
    "print(\"• 투표 기록 참조 무결성 검사 중...\")\n",
    "vote_user_errors = 0\n",
    "vote_question_errors = 0\n",
    "total_vote_records = 0\n",
    "\n",
    "# 청크 크기를 작게 설정\n",
    "chunk_size = 50000\n",
    "\n",
    "# 파일을 청크로 읽기\n",
    "vote_file = \"gs://sprintda05_final_project/votes/accounts_userquestionrecord.parquet\"\n",
    "parquet_file = pd.read_parquet(vote_file)\n",
    "\n",
    "# 전체 행 수 확인\n",
    "total_vote_records = len(parquet_file)\n",
    "print(f\"  - 총 투표 기록: {total_vote_records:,}건\")\n",
    "\n",
    "# 청크 단위로 처리\n",
    "for i in range(0, len(parquet_file), chunk_size):\n",
    "    chunk = parquet_file.iloc[i:i+chunk_size]\n",
    "    \n",
    "    # 사용자 참조 확인\n",
    "    chunk_users = set(chunk['user_id'].values) | set(chunk['chosen_user_id'].values)\n",
    "    orphaned_users = chunk_users - existing_users\n",
    "    vote_user_errors += len(orphaned_users)\n",
    "    \n",
    "    # 질문 참조 확인\n",
    "    chunk_questions = set(chunk['question_id'].values)\n",
    "    orphaned_questions = chunk_questions - existing_questions\n",
    "    vote_question_errors += len(orphaned_questions)\n",
    "    \n",
    "    # 진행상황 출력\n",
    "    processed = min(i + chunk_size, len(parquet_file))\n",
    "    if processed % (chunk_size * 10) == 0:  # 10청크마다 출력\n",
    "        print(f\"    진행: {processed:,}/{total_vote_records:,} ({processed/total_vote_records*100:.1f}%)\")\n",
    "\n",
    "del parquet_file\n",
    "gc.collect()\n",
    "\n",
    "print(f\"  ✅ 투표 기록 검사 완료\")\n",
    "print(f\"    - 사용자 참조 오류: {vote_user_errors:,}개\")\n",
    "print(f\"    - 질문 참조 오류: {vote_question_errors:,}개\")\n",
    "\n",
    "# 차단 기록 (작은 테이블이므로 전체 로드)\n",
    "print(f\"\\n• 차단 기록 참조 무결성 검사...\")\n",
    "df_block = pd.read_parquet(\"gs://sprintda05_final_project/votes/accounts_blockrecord.parquet\")\n",
    "\n",
    "block_users = set(df_block['user_id'].values) | set(df_block['block_user_id'].values)\n",
    "orphaned_block_users = block_users - existing_users\n",
    "\n",
    "print(f\"  ✅ 차단 기록 검사 완료\")\n",
    "print(f\"    - 총 차단 기록: {len(df_block):,}건\")\n",
    "print(f\"    - 사용자 참조 오류: {len(orphaned_block_users):,}개\")\n",
    "\n",
    "del df_block\n",
    "gc.collect()\n",
    "\n",
    "print(f\"\\n📊 3단계: 시간 데이터 일관성\")\n",
    "print(\"-\" * 40)\n",
    "\n",
    "# 시간 데이터 검사 (필요한 컬럼만)\n",
    "time_columns = ['created_at', 'point']\n",
    "df_user_time = pd.read_parquet(\n",
    "    \"gs://sprintda05_final_project/votes/accounts_user.parquet\",\n",
    "    columns=time_columns\n",
    ")\n",
    "\n",
    "# 시간 변환 및 분석\n",
    "df_user_time['created_at'] = pd.to_datetime(df_user_time['created_at'])\n",
    "min_time = df_user_time['created_at'].min()\n",
    "max_time = df_user_time['created_at'].max()\n",
    "\n",
    "print(f\"• 사용자 가입 기간: {min_time} ~ {max_time}\")\n",
    "\n",
    "# 미래 날짜 확인\n",
    "future_dates = (df_user_time['created_at'] > pd.Timestamp.now()).sum()\n",
    "print(f\"• 미래 날짜: {future_dates:,}개\")\n",
    "\n",
    "# 포인트 분석\n",
    "point_stats = df_user_time['point'].describe()\n",
    "negative_points = (df_user_time['point'] < 0).sum()\n",
    "\n",
    "print(f\"• 포인트 범위: {point_stats['min']:.0f} ~ {point_stats['max']:.0f}\")\n",
    "print(f\"• 음수 포인트 사용자: {negative_points:,}명\")\n",
    "\n",
    "del df_user_time\n",
    "gc.collect()\n",
    "\n",
    "# 최종 결과 요약\n",
    "print(f\"\\n\" + \"=\" * 60)\n",
    "print(\"📋 전체 데이터 일관성 검사 결과\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "issues = []\n",
    "if vote_user_errors > 0:\n",
    "    issues.append(f\"투표 기록 사용자 참조 오류: {vote_user_errors:,}개\")\n",
    "if vote_question_errors > 0:\n",
    "    issues.append(f\"투표 기록 질문 참조 오류: {vote_question_errors:,}개\")\n",
    "if len(orphaned_block_users) > 0:\n",
    "    issues.append(f\"차단 기록 사용자 참조 오류: {len(orphaned_block_users):,}개\")\n",
    "if future_dates > 0:\n",
    "    issues.append(f\"미래 날짜 사용자: {future_dates:,}명\")\n",
    "if negative_points > 0:\n",
    "    issues.append(f\"음수 포인트 사용자: {negative_points:,}명\")\n",
    "\n",
    "if issues:\n",
    "    print(\"🚨 발견된 일관성 문제:\")\n",
    "    for i, issue in enumerate(issues, 1):\n",
    "        print(f\"  {i}. {issue}\")\n",
    "else:\n",
    "    print(\"✅ 주요 일관성 문제 없음\")\n",
    "\n",
    "print(f\"\\n💾 메모리 효율적 처리 완료!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3182da1a",
   "metadata": {},
   "source": [
    "### 비즈니스 로직 일관성 검사"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8a8a7e28",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🔍 4단계: 비즈니스 로직 일관성 분석\n",
      "============================================================\n",
      "📋 1. 리스트 형태 컬럼 형식 일관성\n",
      "----------------------------------------\n",
      "\n",
      "• friend_id_list 형식 분석:\n",
      "  - NULL 값: 0개\n",
      "  - 샘플 값: ['[1292473, 913158, 1488461, 1064695, 1043565, 1274736]', '[833025, 832642, 982531, 879496, 838541, 837521, 833041, 832151, 1082907, 1426466, 1541413, 1577131, 837806, 834486, 834358, 1575225, 1576252, 837950, 1446852, 1577930, 841037, 1577938, 832340, 831958, 849624, 837338, 1577954, 849763, 862823, 1577703, 834415, 833009, 834289, 833011, 842865, 833013, 856050, 833017, 833018, 833022, 833023, 1580476, 1580855]', '[838785, 982531, 882567, 879496, 838541, 836496, 833041, 837521, 836498, 832920, 1082907, 1426466, 1541413, 837806, 834486, 834358, 1239225, 1575225, 837950, 874050, 1446852, 841037, 834643, 832340, 836693, 849624, 837338, 831962, 832986, 849763, 874212, 832740, 832614, 862823, 840046, 834415, 856050, 832894, 1577131, 1577703, 1577930, 1577938, 1577954, 1578661, 1579185, 1579656, 1580105, 1580329, 1437875, 1580855, 1581251]']\n",
      "  - 리스트 길이 범위: 0 ~ 1373\n",
      "  - 평균 길이: 53.3\n",
      "\n",
      "• block_user_id_list 형식 분석:\n",
      "  - NULL 값: 0개\n",
      "  - 샘플 값: ['[]', '[]', '[]']\n",
      "  - 리스트 길이 범위: 0 ~ 178\n",
      "  - 평균 길이: 0.0\n",
      "\n",
      "• hide_user_id_list 형식 분석:\n",
      "  - NULL 값: 0개\n",
      "  - 샘플 값: ['[]', '[]', '[]']\n",
      "  - 리스트 길이 범위: 0 ~ 3557\n",
      "  - 평균 길이: 0.8\n",
      "\n",
      "📋 2. 출석 데이터 형식 일관성\n",
      "----------------------------------------\n",
      "• 출석 기록 수: 349,637개\n",
      "• attendance_date_list 샘플:\n",
      "  1. [\"2023-05-27\", \"2023-05-28\", \"2023-05-29\", \"2023-05-30\", \"2023-06-03\", \"2023-06-06\", \"2023-06-12\", \"2023-06-15\", \"2023-07-10\", \"2023-07-31\", \"2023-09-12\", \"2023-09-14\", \"2023-09-19\"]\n",
      "  2. [\"2023-05-27\", \"2023-05-29\", \"2023-05-30\", \"2023-06-02\", \"2023-06-03\", \"2023-06-05\", \"2023-06-07\", \"2023-06-08\", \"2023-06-10\", \"2023-06-11\", \"2023-06-15\", \"2023-06-16\", \"2023-06-17\", \"2023-06-18\", \"2023-06-19\", \"2023-06-20\", \"2023-06-21\", \"2023-06-22\", \"2023-06-23\", \"2023-06-27\", \"2023-07-01\", \"2023-07-04\", \"2023-07-08\", \"2023-07-10\", \"2023-07-15\", \"2023-07-26\", \"2023-08-01\", \"2023-08-02\", \"2023-08-03\", \"2023-08-05\", \"2023-08-14\", \"2023-08-21\", \"2023-08-22\"]\n",
      "  3. [\"2023-05-27\", \"2023-05-29\", \"2023-05-30\", \"2023-05-31\", \"2023-06-01\", \"2023-06-02\", \"2023-06-06\", \"2023-06-07\", \"2023-06-14\"]\n",
      "• 출석일 수 범위: 0 ~ 310\n",
      "• 평균 출석일 수: 6.4\n",
      "\n",
      "📋 3. 비즈니스 규칙 일관성\n",
      "----------------------------------------\n",
      "• 자기 자신 참조 규칙 확인:\n",
      "  - 자기 자신에게 투표: 1,959건\n",
      "  - 자기 자신에게 친구요청: 0건\n",
      "  - 자기 자신 차단: 33건\n",
      "\n",
      "📋 4. 날짜 논리 일관성\n",
      "----------------------------------------\n",
      "• 수정일 < 생성일인 친구요청: 0건\n",
      "• 수정일 = 생성일인 친구요청: 3,938,451건 (미처리 요청)\n",
      "\n",
      "============================================================\n",
      "📋 비즈니스 로직 일관성 검사 결과\n",
      "============================================================\n",
      "🚨 발견된 비즈니스 로직 문제:\n",
      "  1. 자기 자신에게 투표: 1,959건\n",
      "  2. 자기 자신 차단: 33건\n",
      "\n",
      "🎯 4단계 데이터 형식 및 비즈니스 로직 검사 완료!\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import ast\n",
    "\n",
    "print(\"🔍 4단계: 비즈니스 로직 일관성 분석\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "print(\"📋 1. 리스트 형태 컬럼 형식 일관성\")\n",
    "print(\"-\" * 40)\n",
    "\n",
    "# 1. accounts_user의 리스트 컬럼들\n",
    "df_user = pd.read_parquet(\n",
    "    \"gs://sprintda05_final_project/votes/accounts_user.parquet\",\n",
    "    columns=['id', 'friend_id_list', 'block_user_id_list', 'hide_user_id_list']\n",
    ")\n",
    "\n",
    "list_columns = ['friend_id_list', 'block_user_id_list', 'hide_user_id_list']\n",
    "\n",
    "for col in list_columns:\n",
    "    print(f\"\\n• {col} 형식 분석:\")\n",
    "    \n",
    "    # NULL 값 확인\n",
    "    null_count = df_user[col].isnull().sum()\n",
    "    print(f\"  - NULL 값: {null_count:,}개\")\n",
    "    \n",
    "    # 빈 리스트 vs 실데이터 확인\n",
    "    non_null = df_user[col].dropna()\n",
    "    if len(non_null) > 0:\n",
    "        # 첫 몇 개 샘플 확인\n",
    "        samples = non_null.head(3).tolist()\n",
    "        print(f\"  - 샘플 값: {samples}\")\n",
    "        \n",
    "        # 리스트 길이 분포\n",
    "        try:\n",
    "            if isinstance(non_null.iloc[0], str):\n",
    "                # 문자열로 저장된 리스트 파싱\n",
    "                lengths = non_null.apply(lambda x: len(ast.literal_eval(x)) if x.strip() != '' else 0)\n",
    "            else:\n",
    "                # 실제 리스트\n",
    "                lengths = non_null.apply(len)\n",
    "            \n",
    "            print(f\"  - 리스트 길이 범위: {lengths.min()} ~ {lengths.max()}\")\n",
    "            print(f\"  - 평균 길이: {lengths.mean():.1f}\")\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"  - 형식 분석 실패: {str(e)[:30]}\")\n",
    "\n",
    "del df_user\n",
    "\n",
    "print(f\"\\n📋 2. 출석 데이터 형식 일관성\")\n",
    "print(\"-\" * 40)\n",
    "\n",
    "# 2. accounts_attendance의 날짜 리스트\n",
    "df_attendance = pd.read_parquet(\"gs://sprintda05_final_project/votes/accounts_attendance.parquet\")\n",
    "\n",
    "print(f\"• 출석 기록 수: {len(df_attendance):,}개\")\n",
    "print(f\"• attendance_date_list 샘플:\")\n",
    "\n",
    "# 첫 몇 개 샘플 확인\n",
    "for i, sample in enumerate(df_attendance['attendance_date_list'].head(3)):\n",
    "    print(f\"  {i+1}. {sample}\")\n",
    "\n",
    "# 출석일 수 분포\n",
    "try:\n",
    "    attendance_lengths = df_attendance['attendance_date_list'].apply(\n",
    "        lambda x: len(ast.literal_eval(x)) if pd.notna(x) and x.strip() != '' else 0\n",
    "    )\n",
    "    print(f\"• 출석일 수 범위: {attendance_lengths.min()} ~ {attendance_lengths.max()}\")\n",
    "    print(f\"• 평균 출석일 수: {attendance_lengths.mean():.1f}\")\n",
    "except Exception as e:\n",
    "    print(f\"• 출석일 분석 실패: {str(e)[:30]}\")\n",
    "\n",
    "del df_attendance\n",
    "\n",
    "print(f\"\\n📋 3. 비즈니스 규칙 일관성\")\n",
    "print(\"-\" * 40)\n",
    "\n",
    "# 3. 자기 자신 관련 규칙 확인\n",
    "print(\"• 자기 자신 참조 규칙 확인:\")\n",
    "\n",
    "# 투표에서 자기 자신 선택 확인\n",
    "df_vote_self = pd.read_parquet(\n",
    "    \"gs://sprintda05_final_project/votes/accounts_userquestionrecord.parquet\",\n",
    "    columns=['user_id', 'chosen_user_id']\n",
    ")\n",
    "\n",
    "self_votes = (df_vote_self['user_id'] == df_vote_self['chosen_user_id']).sum()\n",
    "print(f\"  - 자기 자신에게 투표: {self_votes:,}건\")\n",
    "\n",
    "del df_vote_self\n",
    "\n",
    "# 친구 요청에서 자기 자신에게 요청 확인\n",
    "df_friend_self = pd.read_parquet(\n",
    "    \"gs://sprintda05_final_project/votes/accounts_friendrequest.parquet\",\n",
    "    columns=['send_user_id', 'receive_user_id']\n",
    ")\n",
    "\n",
    "self_friend_requests = (df_friend_self['send_user_id'] == df_friend_self['receive_user_id']).sum()\n",
    "print(f\"  - 자기 자신에게 친구요청: {self_friend_requests:,}건\")\n",
    "\n",
    "del df_friend_self\n",
    "\n",
    "# 차단에서 자기 자신 차단 확인\n",
    "df_block_self = pd.read_parquet(\n",
    "    \"gs://sprintda05_final_project/votes/accounts_blockrecord.parquet\",\n",
    "    columns=['user_id', 'block_user_id']\n",
    ")\n",
    "\n",
    "self_blocks = (df_block_self['user_id'] == df_block_self['block_user_id']).sum()\n",
    "print(f\"  - 자기 자신 차단: {self_blocks:,}건\")\n",
    "\n",
    "del df_block_self\n",
    "\n",
    "print(f\"\\n📋 4. 날짜 논리 일관성\")\n",
    "print(\"-\" * 40)\n",
    "\n",
    "# 4. 친구 요청의 생성일 vs 수정일\n",
    "df_friend_time = pd.read_parquet(\n",
    "    \"gs://sprintda05_final_project/votes/accounts_friendrequest.parquet\",\n",
    "    columns=['created_at', 'updated_at']\n",
    ")\n",
    "\n",
    "df_friend_time['created_at'] = pd.to_datetime(df_friend_time['created_at'])\n",
    "df_friend_time['updated_at'] = pd.to_datetime(df_friend_time['updated_at'])\n",
    "\n",
    "# 수정일이 생성일보다 빠른 경우\n",
    "invalid_dates = (df_friend_time['updated_at'] < df_friend_time['created_at']).sum()\n",
    "print(f\"• 수정일 < 생성일인 친구요청: {invalid_dates:,}건\")\n",
    "\n",
    "# 동일한 날짜\n",
    "same_dates = (df_friend_time['updated_at'] == df_friend_time['created_at']).sum()\n",
    "print(f\"• 수정일 = 생성일인 친구요청: {same_dates:,}건 (미처리 요청)\")\n",
    "\n",
    "del df_friend_time\n",
    "\n",
    "# 최종 요약\n",
    "print(f\"\\n\" + \"=\" * 60)\n",
    "print(\"📋 비즈니스 로직 일관성 검사 결과\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "logic_issues = []\n",
    "\n",
    "if self_votes > 0:\n",
    "    logic_issues.append(f\"자기 자신에게 투표: {self_votes:,}건\")\n",
    "if self_friend_requests > 0:\n",
    "    logic_issues.append(f\"자기 자신에게 친구요청: {self_friend_requests:,}건\")\n",
    "if self_blocks > 0:\n",
    "    logic_issues.append(f\"자기 자신 차단: {self_blocks:,}건\")\n",
    "if invalid_dates > 0:\n",
    "    logic_issues.append(f\"날짜 논리 오류: {invalid_dates:,}건\")\n",
    "\n",
    "if logic_issues:\n",
    "    print(\"🚨 발견된 비즈니스 로직 문제:\")\n",
    "    for i, issue in enumerate(logic_issues, 1):\n",
    "        print(f\"  {i}. {issue}\")\n",
    "else:\n",
    "    print(\"✅ 주요 비즈니스 로직 문제 없음\")\n",
    "\n",
    "print(f\"\\n🎯 4단계 데이터 형식 및 비즈니스 로직 검사 완료!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "bcc617e8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🔧 5단계: 데이터 전처리 전략 수립\n",
      "==================================================\n",
      "📋 1. 비즈니스 로직 이슈 처리 전략\n",
      "----------------------------------------\n",
      "🎯 자기 자신 투표 (1,959건) 처리 방법:\n",
      "  옵션 1: 제거 → 분석에서 제외\n",
      "  옵션 2: 유지 → '자기 선택' 패턴으로 별도 분석\n",
      "  옵션 3: 플래그 → is_self_vote 컬럼 추가\n",
      "  💡 권장: 옵션 3 (자기 선택 행동도 의미 있는 데이터)\n",
      "\n",
      "🚫 자기 자신 차단 (33건) 처리 방법:\n",
      "  옵션 1: 제거 → 시스템 오류로 간주\n",
      "  옵션 2: 유지 → 특수 케이스로 분석\n",
      "  💡 권장: 옵션 1 (자기 차단은 비논리적)\n",
      "\n",
      "📋 2. 리스트 컬럼 전처리 전략\n",
      "----------------------------------------\n",
      "🔄 문자열 → 리스트 변환 필요 컬럼:\n",
      "  • friend_id_list: '[1,2,3]' → [1,2,3]\n",
      "  • block_user_id_list: '[]' → []\n",
      "  • hide_user_id_list: '[1,2]' → [1,2]\n",
      "  • attendance_date_list: '[\"2023-05-27\"]' → ['2023-05-27']\n",
      "\n",
      "💡 변환 방법:\n",
      "  ast.literal_eval() 사용 또는 json.loads() 활용\n",
      "\n",
      "📋 3. 분석별 전처리 전략\n",
      "----------------------------------------\n",
      "🔍 네트워크 분석용:\n",
      "  • friend_id_list → 네트워크 엣지 생성\n",
      "  • 자기 자신 투표 → 자기 중심성 지표\n",
      "\n",
      "📊 사용자 세그먼트 분석용:\n",
      "  • 출석일 수 → 활성도 지표\n",
      "  • 친구 수 → 사교성 지표\n",
      "  • 포인트 → 참여도 지표\n",
      "\n",
      "⏰ 시계열 분석용:\n",
      "  • attendance_date_list → 일별 출석 이벤트\n",
      "  • created_at → 가입 시점 추이\n",
      "\n",
      "📋 4. 메모리 효율적 전처리\n",
      "----------------------------------------\n",
      "💾 대용량 데이터 처리 방법:\n",
      "  • 청크 단위 처리\n",
      "  • 필요한 컬럼만 로드\n",
      "  • 전처리 후 캐시 저장\n",
      "  • 분석별 데이터 마트 생성\n",
      "\n",
      "==================================================\n",
      "🎯 전처리 우선순위 제안\n",
      "==================================================\n",
      "1️⃣ 필수 전처리:\n",
      "  • 리스트 컬럼 파싱\n",
      "  • 자기 자신 차단 제거\n",
      "  • 날짜 컬럼 datetime 변환\n",
      "\n",
      "2️⃣ 선택적 전처리:\n",
      "  • 자기 자신 투표 플래그 추가\n",
      "  • 이상치 포인트 확인\n",
      "  • iOS 결제 데이터 분리\n",
      "\n",
      "3️⃣ 분석별 전처리:\n",
      "  • 네트워크 분석: 엣지 리스트 생성\n",
      "  • 시계열 분석: 이벤트 데이터 재구성\n",
      "  • 사용자 분석: 특성 지표 계산\n"
     ]
    }
   ],
   "source": [
    "print(\"🔧 5단계: 데이터 전처리 전략 수립\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "print(\"📋 1. 비즈니스 로직 이슈 처리 전략\")\n",
    "print(\"-\" * 40)\n",
    "\n",
    "print(\"🎯 자기 자신 투표 (1,959건) 처리 방법:\")\n",
    "print(\"  옵션 1: 제거 → 분석에서 제외\")\n",
    "print(\"  옵션 2: 유지 → '자기 선택' 패턴으로 별도 분석\")\n",
    "print(\"  옵션 3: 플래그 → is_self_vote 컬럼 추가\")\n",
    "print(\"  💡 권장: 옵션 3 (자기 선택 행동도 의미 있는 데이터)\")\n",
    "\n",
    "print(f\"\\n🚫 자기 자신 차단 (33건) 처리 방법:\")\n",
    "print(\"  옵션 1: 제거 → 시스템 오류로 간주\")\n",
    "print(\"  옵션 2: 유지 → 특수 케이스로 분석\")\n",
    "print(\"  💡 권장: 옵션 1 (자기 차단은 비논리적)\")\n",
    "\n",
    "print(f\"\\n📋 2. 리스트 컬럼 전처리 전략\")\n",
    "print(\"-\" * 40)\n",
    "\n",
    "print(\"🔄 문자열 → 리스트 변환 필요 컬럼:\")\n",
    "print(\"  • friend_id_list: '[1,2,3]' → [1,2,3]\")\n",
    "print(\"  • block_user_id_list: '[]' → []\")\n",
    "print(\"  • hide_user_id_list: '[1,2]' → [1,2]\")\n",
    "print(\"  • attendance_date_list: '[\\\"2023-05-27\\\"]' → ['2023-05-27']\")\n",
    "\n",
    "print(f\"\\n💡 변환 방법:\")\n",
    "print(\"  ast.literal_eval() 사용 또는 json.loads() 활용\")\n",
    "\n",
    "print(f\"\\n📋 3. 분석별 전처리 전략\")\n",
    "print(\"-\" * 40)\n",
    "\n",
    "print(\"🔍 네트워크 분석용:\")\n",
    "print(\"  • friend_id_list → 네트워크 엣지 생성\")\n",
    "print(\"  • 자기 자신 투표 → 자기 중심성 지표\")\n",
    "\n",
    "print(f\"\\n📊 사용자 세그먼트 분석용:\")\n",
    "print(\"  • 출석일 수 → 활성도 지표\")\n",
    "print(\"  • 친구 수 → 사교성 지표\")\n",
    "print(\"  • 포인트 → 참여도 지표\")\n",
    "\n",
    "print(f\"\\n⏰ 시계열 분석용:\")\n",
    "print(\"  • attendance_date_list → 일별 출석 이벤트\")\n",
    "print(\"  • created_at → 가입 시점 추이\")\n",
    "\n",
    "print(f\"\\n📋 4. 메모리 효율적 전처리\")\n",
    "print(\"-\" * 40)\n",
    "\n",
    "print(\"💾 대용량 데이터 처리 방법:\")\n",
    "print(\"  • 청크 단위 처리\")\n",
    "print(\"  • 필요한 컬럼만 로드\")\n",
    "print(\"  • 전처리 후 캐시 저장\")\n",
    "print(\"  • 분석별 데이터 마트 생성\")\n",
    "\n",
    "print(f\"\\n\" + \"=\" * 50)\n",
    "print(\"🎯 전처리 우선순위 제안\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "print(\"1️⃣ 필수 전처리:\")\n",
    "print(\"  • 리스트 컬럼 파싱\")\n",
    "print(\"  • 자기 자신 차단 제거\")\n",
    "print(\"  • 날짜 컬럼 datetime 변환\")\n",
    "\n",
    "print(f\"\\n2️⃣ 선택적 전처리:\")\n",
    "print(\"  • 자기 자신 투표 플래그 추가\")\n",
    "print(\"  • 이상치 포인트 확인\")\n",
    "print(\"  • iOS 결제 데이터 분리\")\n",
    "\n",
    "print(f\"\\n3️⃣ 분석별 전처리:\")\n",
    "print(\"  • 네트워크 분석: 엣지 리스트 생성\")\n",
    "print(\"  • 시계열 분석: 이벤트 데이터 재구성\")\n",
    "print(\"  • 사용자 분석: 특성 지표 계산\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0e88f6a",
   "metadata": {},
   "source": [
    "# 📱 hackle_events 이벤트 분석\n",
    "\n",
    "## 해결할 의문점들\n",
    "1. **이벤트 발생 시점**: 언제 어떤 이벤트가 많이 발생하는가?\n",
    "2. **세션 구분 기준**: session_start/end 패턴으로 세션 정의 파악\n",
    "3. **사용자 여정**: 일반적인 앱 사용 플로우와 이벤트 순서\n",
    "\n",
    "## 분석 전략\n",
    "- 메모리 효율을 위한 청크/샘플 처리\n",
    "- 시간 패턴 → 세션 패턴 → 여정 패턴 순서로 분석"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1cf0ea3a",
   "metadata": {},
   "source": [
    "### 기본 이벤트 현황 파악"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8ab317e2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🔍 hackle_events 기본 현황 분석\n",
      "==================================================\n",
      "📊 기본 정보:\n",
      "• 총 이벤트 수: 11,441,319건\n",
      "• 기간: 2023-07-18 00:00:00 ~ 2023-08-10 23:59:59\n",
      "• 총 세션 수: 253,616개\n",
      "• 이벤트 종류: 44개\n",
      "\n",
      "📈 상위 10개 이벤트 타입:\n",
      "• view_lab_tap: 1,266,665건 (11.1%)\n",
      "• view_timeline_tap: 1,194,508건 (10.4%)\n",
      "• $session_start: 1,036,852건 (9.1%)\n",
      "• launch_app: 986,388건 (8.6%)\n",
      "• click_question_open: 816,801건 (7.1%)\n",
      "• click_bottom_navigation_questions: 769,163건 (6.7%)\n",
      "• click_bottom_navigation_profile: 653,507건 (5.7%)\n",
      "• $session_end: 649,658건 (5.7%)\n",
      "• click_bottom_navigation_timeline: 536,051건 (4.7%)\n",
      "• skip_question: 454,981건 (4.0%)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from datetime import datetime, timedelta\n",
    "import gc\n",
    "\n",
    "print(\"🔍 hackle_events 기본 현황 분석\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "# 메모리 효율을 위해 필요한 컬럼만 로드\n",
    "essential_cols = ['event_id', 'event_datetime', 'event_key', 'session_id']\n",
    "df_events = pd.read_parquet(\n",
    "    \"gs://sprintda05_final_project/hackle/hackle_events.parquet\",\n",
    "    columns=essential_cols\n",
    ")\n",
    "\n",
    "print(f\"📊 기본 정보:\")\n",
    "print(f\"• 총 이벤트 수: {len(df_events):,}건\")\n",
    "print(f\"• 기간: {df_events['event_datetime'].min()} ~ {df_events['event_datetime'].max()}\")\n",
    "print(f\"• 총 세션 수: {df_events['session_id'].nunique():,}개\")\n",
    "print(f\"• 이벤트 종류: {df_events['event_key'].nunique():,}개\")\n",
    "\n",
    "# 상위 이벤트 타입\n",
    "print(f\"\\n📈 상위 10개 이벤트 타입:\")\n",
    "top_events = df_events['event_key'].value_counts().head(10)\n",
    "for event, count in top_events.items():\n",
    "    pct = count / len(df_events) * 100\n",
    "    print(f\"• {event}: {count:,}건 ({pct:.1f}%)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa3c3104",
   "metadata": {},
   "source": [
    "### 이벤트 발생 시간 패턴 분석"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "60c8ba4c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "⏰ 이벤트 발생 시간 패턴 분석\n",
      "==================================================\n",
      "🕐 시간대별 이벤트 발생:\n",
      "•  0시: 728,577건 (6.4%)\n",
      "•  1시: 529,583건 (4.6%)\n",
      "•  2시: 333,545건 (2.9%)\n",
      "•  3시: 194,836건 (1.7%)\n",
      "•  4시: 106,583건 (0.9%)\n",
      "•  5시: 65,042건 (0.6%)\n",
      "•  6시: 68,386건 (0.6%)\n",
      "•  7시: 140,467건 (1.2%)\n",
      "•  8시: 215,217건 (1.9%)\n",
      "•  9시: 235,846건 (2.1%)\n",
      "• 10시: 302,296건 (2.6%)\n",
      "• 11시: 346,129건 (3.0%)\n",
      "• 12시: 381,429건 (3.3%)\n",
      "• 13시: 385,423건 (3.4%)\n",
      "• 14시: 388,929건 (3.4%)\n",
      "• 15시: 396,789건 (3.5%)\n",
      "• 16시: 439,773건 (3.8%)\n",
      "• 17시: 793,125건 (6.9%)\n",
      "• 18시: 992,813건 (8.7%)\n",
      "• 19시: 843,456건 (7.4%)\n",
      "• 20시: 1,207,583건 (10.6%)\n",
      "• 21시: 864,239건 (7.6%)\n",
      "• 22시: 755,223건 (6.6%)\n",
      "• 23시: 726,030건 (6.3%)\n",
      "\n",
      "📊 피크 시간: 20시 (1,207,583건)\n",
      "📊 최저 시간: 5시 (65,042건)\n",
      "\n",
      "📅 요일별 이벤트 발생:\n",
      "• 월요일: 1,157,929건 (10.1%)\n",
      "• 화요일: 1,588,087건 (13.9%)\n",
      "• 수요일: 1,345,594건 (11.8%)\n",
      "• 목요일: 1,809,901건 (15.8%)\n",
      "• 금요일: 1,896,656건 (16.6%)\n",
      "• 토요일: 1,786,289건 (15.6%)\n",
      "• 일요일: 1,856,863건 (16.2%)\n",
      "\n",
      "📈 일별 이벤트 통계:\n",
      "• 평균 일일 이벤트: 476,722건\n",
      "• 최대 일일 이벤트: 806,121건\n",
      "• 최소 일일 이벤트: 250,096건\n"
     ]
    }
   ],
   "source": [
    "print(f\"\\n⏰ 이벤트 발생 시간 패턴 분석\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "# 날짜/시간 파싱\n",
    "df_events['event_datetime'] = pd.to_datetime(df_events['event_datetime'])\n",
    "df_events['hour'] = df_events['event_datetime'].dt.hour\n",
    "df_events['day_of_week'] = df_events['event_datetime'].dt.day_name()\n",
    "df_events['date'] = df_events['event_datetime'].dt.date\n",
    "\n",
    "# 1. 시간대별 이벤트 발생 패턴\n",
    "print(\"🕐 시간대별 이벤트 발생:\")\n",
    "hourly_events = df_events['hour'].value_counts().sort_index()\n",
    "for hour, count in hourly_events.items():\n",
    "    pct = count / len(df_events) * 100\n",
    "    print(f\"• {hour:2d}시: {count:,}건 ({pct:.1f}%)\")\n",
    "\n",
    "peak_hour = hourly_events.idxmax()\n",
    "low_hour = hourly_events.idxmin()\n",
    "print(f\"\\n📊 피크 시간: {peak_hour}시 ({hourly_events[peak_hour]:,}건)\")\n",
    "print(f\"📊 최저 시간: {low_hour}시 ({hourly_events[low_hour]:,}건)\")\n",
    "\n",
    "# 2. 요일별 패턴\n",
    "print(f\"\\n📅 요일별 이벤트 발생:\")\n",
    "daily_events = df_events['day_of_week'].value_counts()\n",
    "day_order = ['Monday', 'Tuesday', 'Wednesday', 'Thursday', 'Friday', 'Saturday', 'Sunday']\n",
    "daily_events = daily_events.reindex(day_order)\n",
    "\n",
    "for day, count in daily_events.items():\n",
    "    pct = count / len(df_events) * 100\n",
    "    day_kr = {'Monday': '월', 'Tuesday': '화', 'Wednesday': '수', 'Thursday': '목', \n",
    "              'Friday': '금', 'Saturday': '토', 'Sunday': '일'}[day]\n",
    "    print(f\"• {day_kr}요일: {count:,}건 ({pct:.1f}%)\")\n",
    "\n",
    "# 3. 일별 이벤트 추이\n",
    "daily_count = df_events.groupby('date').size()\n",
    "print(f\"\\n📈 일별 이벤트 통계:\")\n",
    "print(f\"• 평균 일일 이벤트: {daily_count.mean():,.0f}건\")\n",
    "print(f\"• 최대 일일 이벤트: {daily_count.max():,}건\")\n",
    "print(f\"• 최소 일일 이벤트: {daily_count.min():,}건\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db8587b3",
   "metadata": {},
   "source": [
    "### 세션 패턴 분석"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b16eb83a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔗 세션 패턴 분석\n",
      "==================================================\n",
      "• 세션 관련 이벤트: 1,686,510건\n",
      "• session_start: 1,036,852건\n",
      "• session_end: 649,658건\n",
      "\n",
      "📊 세션 지속시간 분석 (샘플 1000개):\n",
      "• 평균 세션 시간: 17054.0분\n",
      "• 중간값 세션 시간: 18889.9분\n",
      "• 최대 세션 시간: 34546.8분\n",
      "• 평균 세션당 이벤트: 314.0개\n",
      "\n",
      "⏱️ 세션 시간 분포:\n",
      "• 60분 이상: 836개 (83.6%)\n",
      "• 1-5분: 70개 (7.0%)\n",
      "• 1분 미만: 47개 (4.7%)\n",
      "• 5-15분: 26개 (2.6%)\n",
      "• 30-60분: 13개 (1.3%)\n",
      "• 15-30분: 6개 (0.6%)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(f\"\\n🔗 세션 패턴 분석\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "# 세션 관련 이벤트 추출\n",
    "session_events = df_events[df_events['event_key'].isin(['$session_start', '$session_end'])]\n",
    "print(f\"• 세션 관련 이벤트: {len(session_events):,}건\")\n",
    "\n",
    "# 세션 시작/종료 이벤트 수\n",
    "session_counts = session_events['event_key'].value_counts()\n",
    "print(f\"• session_start: {session_counts.get('$session_start', 0):,}건\")\n",
    "print(f\"• session_end: {session_counts.get('$session_end', 0):,}건\")\n",
    "\n",
    "# 세션별 분석 (샘플)\n",
    "print(f\"\\n📊 세션 지속시간 분석 (샘플 1000개):\")\n",
    "\n",
    "# 메모리 절약을 위해 샘플 세션만 분석\n",
    "sample_sessions = df_events['session_id'].unique()[:1000]\n",
    "sample_events = df_events[df_events['session_id'].isin(sample_sessions)]\n",
    "\n",
    "session_durations = []\n",
    "session_event_counts = []\n",
    "\n",
    "for session_id in sample_sessions:\n",
    "    session_data = sample_events[sample_events['session_id'] == session_id].sort_values('event_datetime')\n",
    "    \n",
    "    if len(session_data) > 1:\n",
    "        # 세션 지속시간 계산\n",
    "        start_time = session_data['event_datetime'].min()\n",
    "        end_time = session_data['event_datetime'].max()\n",
    "        duration = (end_time - start_time).total_seconds() / 60  # 분 단위\n",
    "        session_durations.append(duration)\n",
    "        \n",
    "        # 세션 내 이벤트 수\n",
    "        session_event_counts.append(len(session_data))\n",
    "\n",
    "if session_durations:\n",
    "    durations = pd.Series(session_durations)\n",
    "    event_counts = pd.Series(session_event_counts)\n",
    "    \n",
    "    print(f\"• 평균 세션 시간: {durations.mean():.1f}분\")\n",
    "    print(f\"• 중간값 세션 시간: {durations.median():.1f}분\")\n",
    "    print(f\"• 최대 세션 시간: {durations.max():.1f}분\")\n",
    "    print(f\"• 평균 세션당 이벤트: {event_counts.mean():.1f}개\")\n",
    "    \n",
    "    # 세션 시간 분포\n",
    "    print(f\"\\n⏱️ 세션 시간 분포:\")\n",
    "    duration_ranges = pd.cut(durations, bins=[0, 1, 5, 15, 30, 60, float('inf')], \n",
    "                           labels=['1분 미만', '1-5분', '5-15분', '15-30분', '30-60분', '60분 이상'])\n",
    "    for range_name, count in duration_ranges.value_counts().items():\n",
    "        pct = count / len(durations) * 100\n",
    "        print(f\"• {range_name}: {count}개 ({pct:.1f}%)\")\n",
    "\n",
    "# 메모리 정리\n",
    "del sample_events, session_events\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9c0c985",
   "metadata": {},
   "source": [
    "### 사용자 여정 패턴 분석"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f7adf09d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🗺️ 사용자 여정 패턴 분석\n",
      "==================================================\n",
      "📱 일반적인 앱 사용 플로우 분석 (샘플 100개 세션):\n",
      "🔝 가장 일반적인 앱 시작 패턴 (첫 3개 이벤트):\n",
      " 1. $session_start → launch_app → $session_end\n",
      "    (12회, 12.0%)\n",
      " 2. launch_app → $session_start → $session_end\n",
      "    (12회, 12.0%)\n",
      " 3. $session_end → launch_app → $session_start\n",
      "    (8회, 8.0%)\n",
      " 4. launch_app → $session_end → $session_start\n",
      "    (6회, 6.0%)\n",
      " 5. $session_end → $session_start → launch_app\n",
      "    (6회, 6.0%)\n",
      " 6. launch_app → $session_start → launch_app\n",
      "    (5회, 5.0%)\n",
      " 7. launch_app → $session_start → click_appbar_alarm_center\n",
      "    (5회, 5.0%)\n",
      " 8. $session_start → launch_app → click_question_start\n",
      "    (4회, 4.0%)\n",
      " 9. launch_app → $session_start → click_bottom_navigation_questions\n",
      "    (4회, 4.0%)\n",
      "10. launch_app → $session_start → view_signup\n",
      "    (4회, 4.0%)\n",
      "\n",
      "🔄 이벤트 전환 패턴 분석 (샘플):\n",
      "🔗 가장 빈번한 이벤트 전환:\n",
      " 1. view_timeline_tap → launch_app (1회)\n",
      " 2. click_question_start → click_question_start (1회)\n",
      " 3. view_questions_tap → click_bottom_navigation_questions (1회)\n",
      " 4. $session_start → view_profile_tap (1회)\n",
      " 5. view_profile_tap → click_bottom_navigation_profile (1회)\n",
      " 6. click_bottom_navigation_profile → skip_question (1회)\n",
      " 7. skip_question → click_question_open (1회)\n",
      " 8. click_question_open → skip_question (1회)\n",
      " 9. view_lab_tap → view_timeline_tap (1회)\n",
      "10. click_bottom_navigation_lab → click_random_ask_shuffle (1회)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "26"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(f\"\\n🗺️ 사용자 여정 패턴 분석\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "# 사용자 여정 분석을 위한 샘플 데이터\n",
    "print(\"📱 일반적인 앱 사용 플로우 분석 (샘플 100개 세션):\")\n",
    "\n",
    "# 100개 세션의 이벤트 시퀀스 분석\n",
    "sample_sessions_small = df_events['session_id'].unique()[:100]\n",
    "journey_patterns = []\n",
    "\n",
    "for session_id in sample_sessions_small:\n",
    "    session_data = df_events[df_events['session_id'] == session_id].sort_values('event_datetime')\n",
    "    event_sequence = session_data['event_key'].tolist()\n",
    "    \n",
    "    if len(event_sequence) >= 3:  # 최소 3개 이벤트 이상\n",
    "        # 첫 3개 이벤트 패턴\n",
    "        first_three = ' → '.join(event_sequence[:3])\n",
    "        journey_patterns.append(first_three)\n",
    "\n",
    "# 가장 일반적인 사용자 여정 패턴\n",
    "if journey_patterns:\n",
    "    common_journeys = pd.Series(journey_patterns).value_counts().head(10)\n",
    "    \n",
    "    print(\"🔝 가장 일반적인 앱 시작 패턴 (첫 3개 이벤트):\")\n",
    "    for i, (pattern, count) in enumerate(common_journeys.items(), 1):\n",
    "        pct = count / len(journey_patterns) * 100\n",
    "        print(f\"{i:2d}. {pattern}\")\n",
    "        print(f\"    ({count}회, {pct:.1f}%)\")\n",
    "\n",
    "# 이벤트 전환 패턴 분석\n",
    "print(f\"\\n🔄 이벤트 전환 패턴 분석 (샘플):\")\n",
    "\n",
    "# 이벤트 쌍 전환 패턴\n",
    "transition_pairs = []\n",
    "sample_data = df_events.head(10000).sort_values(['session_id', 'event_datetime'])\n",
    "\n",
    "for session_id in sample_data['session_id'].unique()[:50]:\n",
    "    session_events = sample_data[sample_data['session_id'] == session_id]['event_key'].tolist()\n",
    "    \n",
    "    for i in range(len(session_events) - 1):\n",
    "        from_event = session_events[i]\n",
    "        to_event = session_events[i + 1]\n",
    "        transition_pairs.append(f\"{from_event} → {to_event}\")\n",
    "\n",
    "if transition_pairs:\n",
    "    top_transitions = pd.Series(transition_pairs).value_counts().head(10)\n",
    "    \n",
    "    print(\"🔗 가장 빈번한 이벤트 전환:\")\n",
    "    for i, (transition, count) in enumerate(top_transitions.items(), 1):\n",
    "        print(f\"{i:2d}. {transition} ({count}회)\")\n",
    "\n",
    "# 메모리 정리\n",
    "del df_events\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f20d594",
   "metadata": {},
   "source": [
    "### 세션 문제 상세 분석"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f51acd08",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🔍 세션 문제 상세 분석\n",
      "==================================================\n",
      "📊 세션 완성도 분석:\n",
      "세션 상태별 분포:\n",
      "• 정상 (시작+종료): 929개 (92.9%)\n",
      "• 시작만 있음: 71개 (7.1%)\n",
      "\n",
      "⏰ 정상 세션 시간 재계산 (929개):\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_8229/2263042957.py:54: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  session_data['event_datetime'] = pd.to_datetime(session_data['event_datetime'])\n",
      "/tmp/ipykernel_8229/2263042957.py:54: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  session_data['event_datetime'] = pd.to_datetime(session_data['event_datetime'])\n",
      "/tmp/ipykernel_8229/2263042957.py:54: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  session_data['event_datetime'] = pd.to_datetime(session_data['event_datetime'])\n",
      "/tmp/ipykernel_8229/2263042957.py:54: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  session_data['event_datetime'] = pd.to_datetime(session_data['event_datetime'])\n",
      "/tmp/ipykernel_8229/2263042957.py:54: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  session_data['event_datetime'] = pd.to_datetime(session_data['event_datetime'])\n",
      "/tmp/ipykernel_8229/2263042957.py:54: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  session_data['event_datetime'] = pd.to_datetime(session_data['event_datetime'])\n",
      "/tmp/ipykernel_8229/2263042957.py:54: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  session_data['event_datetime'] = pd.to_datetime(session_data['event_datetime'])\n",
      "/tmp/ipykernel_8229/2263042957.py:54: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  session_data['event_datetime'] = pd.to_datetime(session_data['event_datetime'])\n",
      "/tmp/ipykernel_8229/2263042957.py:54: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  session_data['event_datetime'] = pd.to_datetime(session_data['event_datetime'])\n",
      "/tmp/ipykernel_8229/2263042957.py:54: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  session_data['event_datetime'] = pd.to_datetime(session_data['event_datetime'])\n",
      "/tmp/ipykernel_8229/2263042957.py:54: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  session_data['event_datetime'] = pd.to_datetime(session_data['event_datetime'])\n",
      "/tmp/ipykernel_8229/2263042957.py:54: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  session_data['event_datetime'] = pd.to_datetime(session_data['event_datetime'])\n",
      "/tmp/ipykernel_8229/2263042957.py:54: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  session_data['event_datetime'] = pd.to_datetime(session_data['event_datetime'])\n",
      "/tmp/ipykernel_8229/2263042957.py:54: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  session_data['event_datetime'] = pd.to_datetime(session_data['event_datetime'])\n",
      "/tmp/ipykernel_8229/2263042957.py:54: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  session_data['event_datetime'] = pd.to_datetime(session_data['event_datetime'])\n",
      "/tmp/ipykernel_8229/2263042957.py:54: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  session_data['event_datetime'] = pd.to_datetime(session_data['event_datetime'])\n",
      "/tmp/ipykernel_8229/2263042957.py:54: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  session_data['event_datetime'] = pd.to_datetime(session_data['event_datetime'])\n",
      "/tmp/ipykernel_8229/2263042957.py:54: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  session_data['event_datetime'] = pd.to_datetime(session_data['event_datetime'])\n",
      "/tmp/ipykernel_8229/2263042957.py:54: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  session_data['event_datetime'] = pd.to_datetime(session_data['event_datetime'])\n",
      "/tmp/ipykernel_8229/2263042957.py:54: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  session_data['event_datetime'] = pd.to_datetime(session_data['event_datetime'])\n",
      "/tmp/ipykernel_8229/2263042957.py:54: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  session_data['event_datetime'] = pd.to_datetime(session_data['event_datetime'])\n",
      "/tmp/ipykernel_8229/2263042957.py:54: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  session_data['event_datetime'] = pd.to_datetime(session_data['event_datetime'])\n",
      "/tmp/ipykernel_8229/2263042957.py:54: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  session_data['event_datetime'] = pd.to_datetime(session_data['event_datetime'])\n",
      "/tmp/ipykernel_8229/2263042957.py:54: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  session_data['event_datetime'] = pd.to_datetime(session_data['event_datetime'])\n",
      "/tmp/ipykernel_8229/2263042957.py:54: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  session_data['event_datetime'] = pd.to_datetime(session_data['event_datetime'])\n",
      "/tmp/ipykernel_8229/2263042957.py:54: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  session_data['event_datetime'] = pd.to_datetime(session_data['event_datetime'])\n",
      "/tmp/ipykernel_8229/2263042957.py:54: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  session_data['event_datetime'] = pd.to_datetime(session_data['event_datetime'])\n",
      "/tmp/ipykernel_8229/2263042957.py:54: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  session_data['event_datetime'] = pd.to_datetime(session_data['event_datetime'])\n",
      "/tmp/ipykernel_8229/2263042957.py:54: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  session_data['event_datetime'] = pd.to_datetime(session_data['event_datetime'])\n",
      "/tmp/ipykernel_8229/2263042957.py:54: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  session_data['event_datetime'] = pd.to_datetime(session_data['event_datetime'])\n",
      "/tmp/ipykernel_8229/2263042957.py:54: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  session_data['event_datetime'] = pd.to_datetime(session_data['event_datetime'])\n",
      "/tmp/ipykernel_8229/2263042957.py:54: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  session_data['event_datetime'] = pd.to_datetime(session_data['event_datetime'])\n",
      "/tmp/ipykernel_8229/2263042957.py:54: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  session_data['event_datetime'] = pd.to_datetime(session_data['event_datetime'])\n",
      "/tmp/ipykernel_8229/2263042957.py:54: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  session_data['event_datetime'] = pd.to_datetime(session_data['event_datetime'])\n",
      "/tmp/ipykernel_8229/2263042957.py:54: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  session_data['event_datetime'] = pd.to_datetime(session_data['event_datetime'])\n",
      "/tmp/ipykernel_8229/2263042957.py:54: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  session_data['event_datetime'] = pd.to_datetime(session_data['event_datetime'])\n",
      "/tmp/ipykernel_8229/2263042957.py:54: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  session_data['event_datetime'] = pd.to_datetime(session_data['event_datetime'])\n",
      "/tmp/ipykernel_8229/2263042957.py:54: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  session_data['event_datetime'] = pd.to_datetime(session_data['event_datetime'])\n",
      "/tmp/ipykernel_8229/2263042957.py:54: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  session_data['event_datetime'] = pd.to_datetime(session_data['event_datetime'])\n",
      "/tmp/ipykernel_8229/2263042957.py:54: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  session_data['event_datetime'] = pd.to_datetime(session_data['event_datetime'])\n",
      "/tmp/ipykernel_8229/2263042957.py:54: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  session_data['event_datetime'] = pd.to_datetime(session_data['event_datetime'])\n",
      "/tmp/ipykernel_8229/2263042957.py:54: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  session_data['event_datetime'] = pd.to_datetime(session_data['event_datetime'])\n",
      "/tmp/ipykernel_8229/2263042957.py:54: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  session_data['event_datetime'] = pd.to_datetime(session_data['event_datetime'])\n",
      "/tmp/ipykernel_8229/2263042957.py:54: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  session_data['event_datetime'] = pd.to_datetime(session_data['event_datetime'])\n",
      "/tmp/ipykernel_8229/2263042957.py:54: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  session_data['event_datetime'] = pd.to_datetime(session_data['event_datetime'])\n",
      "/tmp/ipykernel_8229/2263042957.py:54: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  session_data['event_datetime'] = pd.to_datetime(session_data['event_datetime'])\n",
      "/tmp/ipykernel_8229/2263042957.py:54: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  session_data['event_datetime'] = pd.to_datetime(session_data['event_datetime'])\n",
      "/tmp/ipykernel_8229/2263042957.py:54: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  session_data['event_datetime'] = pd.to_datetime(session_data['event_datetime'])\n",
      "/tmp/ipykernel_8229/2263042957.py:54: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  session_data['event_datetime'] = pd.to_datetime(session_data['event_datetime'])\n",
      "/tmp/ipykernel_8229/2263042957.py:54: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  session_data['event_datetime'] = pd.to_datetime(session_data['event_datetime'])\n",
      "/tmp/ipykernel_8229/2263042957.py:54: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  session_data['event_datetime'] = pd.to_datetime(session_data['event_datetime'])\n",
      "/tmp/ipykernel_8229/2263042957.py:54: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  session_data['event_datetime'] = pd.to_datetime(session_data['event_datetime'])\n",
      "/tmp/ipykernel_8229/2263042957.py:54: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  session_data['event_datetime'] = pd.to_datetime(session_data['event_datetime'])\n",
      "/tmp/ipykernel_8229/2263042957.py:54: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  session_data['event_datetime'] = pd.to_datetime(session_data['event_datetime'])\n",
      "/tmp/ipykernel_8229/2263042957.py:54: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  session_data['event_datetime'] = pd.to_datetime(session_data['event_datetime'])\n",
      "/tmp/ipykernel_8229/2263042957.py:54: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  session_data['event_datetime'] = pd.to_datetime(session_data['event_datetime'])\n",
      "/tmp/ipykernel_8229/2263042957.py:54: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  session_data['event_datetime'] = pd.to_datetime(session_data['event_datetime'])\n",
      "/tmp/ipykernel_8229/2263042957.py:54: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  session_data['event_datetime'] = pd.to_datetime(session_data['event_datetime'])\n",
      "/tmp/ipykernel_8229/2263042957.py:54: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  session_data['event_datetime'] = pd.to_datetime(session_data['event_datetime'])\n",
      "/tmp/ipykernel_8229/2263042957.py:54: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  session_data['event_datetime'] = pd.to_datetime(session_data['event_datetime'])\n",
      "/tmp/ipykernel_8229/2263042957.py:54: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  session_data['event_datetime'] = pd.to_datetime(session_data['event_datetime'])\n",
      "/tmp/ipykernel_8229/2263042957.py:54: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  session_data['event_datetime'] = pd.to_datetime(session_data['event_datetime'])\n",
      "/tmp/ipykernel_8229/2263042957.py:54: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  session_data['event_datetime'] = pd.to_datetime(session_data['event_datetime'])\n",
      "/tmp/ipykernel_8229/2263042957.py:54: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  session_data['event_datetime'] = pd.to_datetime(session_data['event_datetime'])\n",
      "/tmp/ipykernel_8229/2263042957.py:54: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  session_data['event_datetime'] = pd.to_datetime(session_data['event_datetime'])\n",
      "/tmp/ipykernel_8229/2263042957.py:54: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  session_data['event_datetime'] = pd.to_datetime(session_data['event_datetime'])\n",
      "/tmp/ipykernel_8229/2263042957.py:54: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  session_data['event_datetime'] = pd.to_datetime(session_data['event_datetime'])\n",
      "/tmp/ipykernel_8229/2263042957.py:54: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  session_data['event_datetime'] = pd.to_datetime(session_data['event_datetime'])\n",
      "/tmp/ipykernel_8229/2263042957.py:54: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  session_data['event_datetime'] = pd.to_datetime(session_data['event_datetime'])\n",
      "/tmp/ipykernel_8229/2263042957.py:54: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  session_data['event_datetime'] = pd.to_datetime(session_data['event_datetime'])\n",
      "/tmp/ipykernel_8229/2263042957.py:54: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  session_data['event_datetime'] = pd.to_datetime(session_data['event_datetime'])\n",
      "/tmp/ipykernel_8229/2263042957.py:54: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  session_data['event_datetime'] = pd.to_datetime(session_data['event_datetime'])\n",
      "/tmp/ipykernel_8229/2263042957.py:54: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  session_data['event_datetime'] = pd.to_datetime(session_data['event_datetime'])\n",
      "/tmp/ipykernel_8229/2263042957.py:54: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  session_data['event_datetime'] = pd.to_datetime(session_data['event_datetime'])\n",
      "/tmp/ipykernel_8229/2263042957.py:54: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  session_data['event_datetime'] = pd.to_datetime(session_data['event_datetime'])\n",
      "/tmp/ipykernel_8229/2263042957.py:54: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  session_data['event_datetime'] = pd.to_datetime(session_data['event_datetime'])\n",
      "/tmp/ipykernel_8229/2263042957.py:54: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  session_data['event_datetime'] = pd.to_datetime(session_data['event_datetime'])\n",
      "/tmp/ipykernel_8229/2263042957.py:54: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  session_data['event_datetime'] = pd.to_datetime(session_data['event_datetime'])\n",
      "/tmp/ipykernel_8229/2263042957.py:54: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  session_data['event_datetime'] = pd.to_datetime(session_data['event_datetime'])\n",
      "/tmp/ipykernel_8229/2263042957.py:54: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  session_data['event_datetime'] = pd.to_datetime(session_data['event_datetime'])\n",
      "/tmp/ipykernel_8229/2263042957.py:54: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  session_data['event_datetime'] = pd.to_datetime(session_data['event_datetime'])\n",
      "/tmp/ipykernel_8229/2263042957.py:54: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  session_data['event_datetime'] = pd.to_datetime(session_data['event_datetime'])\n",
      "/tmp/ipykernel_8229/2263042957.py:54: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  session_data['event_datetime'] = pd.to_datetime(session_data['event_datetime'])\n",
      "/tmp/ipykernel_8229/2263042957.py:54: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  session_data['event_datetime'] = pd.to_datetime(session_data['event_datetime'])\n",
      "/tmp/ipykernel_8229/2263042957.py:54: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  session_data['event_datetime'] = pd.to_datetime(session_data['event_datetime'])\n",
      "/tmp/ipykernel_8229/2263042957.py:54: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  session_data['event_datetime'] = pd.to_datetime(session_data['event_datetime'])\n",
      "/tmp/ipykernel_8229/2263042957.py:54: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  session_data['event_datetime'] = pd.to_datetime(session_data['event_datetime'])\n",
      "/tmp/ipykernel_8229/2263042957.py:54: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  session_data['event_datetime'] = pd.to_datetime(session_data['event_datetime'])\n",
      "/tmp/ipykernel_8229/2263042957.py:54: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  session_data['event_datetime'] = pd.to_datetime(session_data['event_datetime'])\n",
      "/tmp/ipykernel_8229/2263042957.py:54: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  session_data['event_datetime'] = pd.to_datetime(session_data['event_datetime'])\n",
      "/tmp/ipykernel_8229/2263042957.py:54: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  session_data['event_datetime'] = pd.to_datetime(session_data['event_datetime'])\n",
      "/tmp/ipykernel_8229/2263042957.py:54: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  session_data['event_datetime'] = pd.to_datetime(session_data['event_datetime'])\n",
      "/tmp/ipykernel_8229/2263042957.py:54: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  session_data['event_datetime'] = pd.to_datetime(session_data['event_datetime'])\n",
      "/tmp/ipykernel_8229/2263042957.py:54: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  session_data['event_datetime'] = pd.to_datetime(session_data['event_datetime'])\n",
      "/tmp/ipykernel_8229/2263042957.py:54: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  session_data['event_datetime'] = pd.to_datetime(session_data['event_datetime'])\n",
      "/tmp/ipykernel_8229/2263042957.py:54: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  session_data['event_datetime'] = pd.to_datetime(session_data['event_datetime'])\n",
      "/tmp/ipykernel_8229/2263042957.py:54: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  session_data['event_datetime'] = pd.to_datetime(session_data['event_datetime'])\n",
      "/tmp/ipykernel_8229/2263042957.py:54: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  session_data['event_datetime'] = pd.to_datetime(session_data['event_datetime'])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "• 평균 세션 시간: 7.2분\n",
      "• 중간값: 0.7분\n",
      "• 90분위수: 5.9분\n",
      "\n",
      "📊 정상 세션 시간 분포:\n",
      "• 1-5분: 10개 (31.2%)\n",
      "• 1분 미만: 5개 (15.6%)\n",
      "• 5-15분: 4개 (12.5%)\n",
      "• 15-30분: 1개 (3.1%)\n",
      "• 60분 이상: 1개 (3.1%)\n",
      "• 30-60분: 0개 (0.0%)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_8229/2263042957.py:54: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  session_data['event_datetime'] = pd.to_datetime(session_data['event_datetime'])\n",
      "/tmp/ipykernel_8229/2263042957.py:54: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  session_data['event_datetime'] = pd.to_datetime(session_data['event_datetime'])\n"
     ]
    }
   ],
   "source": [
    "print(\"🔍 세션 문제 상세 분석\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "# 세션 시작/종료 불균형 분석\n",
    "df_events = pd.read_parquet(\n",
    "    \"gs://sprintda05_final_project/hackle/hackle_events.parquet\",\n",
    "    columns=['session_id', 'event_datetime', 'event_key']\n",
    ")\n",
    "\n",
    "print(\"📊 세션 완성도 분석:\")\n",
    "\n",
    "# 각 세션별 시작/종료 이벤트 확인\n",
    "session_analysis = []\n",
    "unique_sessions = df_events['session_id'].unique()[:1000]  # 샘플 1000개\n",
    "\n",
    "for session_id in unique_sessions:\n",
    "    session_data = df_events[df_events['session_id'] == session_id]\n",
    "    \n",
    "    has_start = '$session_start' in session_data['event_key'].values\n",
    "    has_end = '$session_end' in session_data['event_key'].values\n",
    "    total_events = len(session_data)\n",
    "    \n",
    "    session_analysis.append({\n",
    "        'session_id': session_id,\n",
    "        'has_start': has_start,\n",
    "        'has_end': has_end,\n",
    "        'total_events': total_events,\n",
    "        'status': f\"{'S' if has_start else ''}{'E' if has_end else ''}\"\n",
    "    })\n",
    "\n",
    "analysis_df = pd.DataFrame(session_analysis)\n",
    "status_counts = analysis_df['status'].value_counts()\n",
    "\n",
    "print(\"세션 상태별 분포:\")\n",
    "for status, count in status_counts.items():\n",
    "    pct = count / len(analysis_df) * 100\n",
    "    status_meaning = {\n",
    "        'SE': '정상 (시작+종료)',\n",
    "        'S': '시작만 있음',\n",
    "        'E': '종료만 있음', \n",
    "        '': '시작/종료 없음'\n",
    "    }.get(status, f'기타({status})')\n",
    "    print(f\"• {status_meaning}: {count}개 ({pct:.1f}%)\")\n",
    "\n",
    "# 올바른 세션 시간 계산 (시작+종료 있는 것만)\n",
    "normal_sessions = analysis_df[analysis_df['status'] == 'SE']['session_id'].tolist()\n",
    "\n",
    "if normal_sessions:\n",
    "    print(f\"\\n⏰ 정상 세션 시간 재계산 ({len(normal_sessions)}개):\")\n",
    "    \n",
    "    durations = []\n",
    "    for session_id in normal_sessions[:100]:  # 100개만 샘플\n",
    "        session_data = df_events[df_events['session_id'] == session_id]\n",
    "        session_data['event_datetime'] = pd.to_datetime(session_data['event_datetime'])\n",
    "        \n",
    "        start_events = session_data[session_data['event_key'] == '$session_start']\n",
    "        end_events = session_data[session_data['event_key'] == '$session_end']\n",
    "        \n",
    "        if len(start_events) > 0 and len(end_events) > 0:\n",
    "            start_time = start_events['event_datetime'].min()\n",
    "            end_time = end_events['event_datetime'].max()\n",
    "            duration = (end_time - start_time).total_seconds() / 60\n",
    "            \n",
    "            if 0 <= duration <= 300:  # 5시간 이하만 (이상치 제외)\n",
    "                durations.append(duration)\n",
    "    \n",
    "    if durations:\n",
    "        durations = pd.Series(durations)\n",
    "        print(f\"• 평균 세션 시간: {durations.mean():.1f}분\")\n",
    "        print(f\"• 중간값: {durations.median():.1f}분\")\n",
    "        print(f\"• 90분위수: {durations.quantile(0.9):.1f}분\")\n",
    "        \n",
    "        # 세션 시간 분포 (재계산)\n",
    "        duration_ranges = pd.cut(durations, \n",
    "                               bins=[0, 1, 5, 15, 30, 60, float('inf')],\n",
    "                               labels=['1분 미만', '1-5분', '5-15분', '15-30분', '30-60분', '60분 이상'])\n",
    "        print(f\"\\n📊 정상 세션 시간 분포:\")\n",
    "        for range_name, count in duration_ranges.value_counts().items():\n",
    "            pct = count / len(durations) * 100\n",
    "            print(f\"• {range_name}: {count}개 ({pct:.1f}%)\")\n",
    "\n",
    "del df_events"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9382481",
   "metadata": {},
   "source": [
    "### 실제 사용자 여정 재분석"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e0805e45",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🗺️ 실제 사용자 여정 재분석\n",
      "==================================================\n",
      "📱 정상 세션의 앱 사용 플로우:\n",
      "• 분석 대상 정상 세션: 464개\n",
      "\n",
      "🔝 실제 사용자 행동 패턴 (시스템 이벤트 제외):\n",
      " 1. launch_app → click_question_start → skip_question\n",
      "    (5회, 10.0%)\n",
      " 2. launch_app → launch_app → launch_app\n",
      "    (4회, 8.0%)\n",
      " 3. launch_app → launch_app → view_login\n",
      "    (3회, 6.0%)\n",
      " 4. launch_app → view_signup → view_signup\n",
      "    (3회, 6.0%)\n",
      " 5. launch_app → click_bottom_navigation_questions → click_bottom_navigation_questions\n",
      "    (3회, 6.0%)\n",
      " 6. launch_app → launch_app → click_question_start\n",
      "    (3회, 6.0%)\n",
      " 7. launch_app → click_bottom_navigation_questions → click_bottom_navigation_timeline\n",
      "    (2회, 4.0%)\n",
      " 8. launch_app → launch_app → click_question_open\n",
      "    (2회, 4.0%)\n",
      " 9. launch_app → click_bottom_navigation_profile → view_lab_tap\n",
      "    (2회, 4.0%)\n",
      "10. launch_app → click_question_open → click_question_open\n",
      "    (2회, 4.0%)\n",
      "\n",
      "📊 주요 기능 이용 순서:\n",
      " 1. view_timeline_tap → view_lab_tap (2014회)\n",
      " 2. click_question_open → click_question_open (1866회)\n",
      " 3. view_lab_tap → view_timeline_tap (1647회)\n",
      " 4. view_lab_tap → view_lab_tap (1339회)\n",
      " 5. launch_app → launch_app (1132회)\n",
      " 6. launch_app → view_timeline_tap (854회)\n",
      " 7. view_lab_tap → click_bottom_navigation_questions (791회)\n",
      " 8. view_lab_tap → launch_app (773회)\n",
      " 9. view_timeline_tap → click_bottom_navigation_questions (764회)\n",
      "10. click_bottom_navigation_questions → view_timeline_tap (662회)\n"
     ]
    }
   ],
   "source": [
    "print(f\"\\n🗺️ 실제 사용자 여정 재분석\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "# 정상적인 세션만으로 여정 분석\n",
    "df_events = pd.read_parquet(\n",
    "    \"gs://sprintda05_final_project/hackle/hackle_events.parquet\",\n",
    "    columns=['session_id', 'event_datetime', 'event_key']\n",
    ")\n",
    "\n",
    "print(\"📱 정상 세션의 앱 사용 플로우:\")\n",
    "\n",
    "# 시작과 종료가 모두 있는 세션만 필터링\n",
    "normal_session_ids = []\n",
    "sample_sessions = df_events['session_id'].unique()[:500]\n",
    "\n",
    "for session_id in sample_sessions:\n",
    "    session_data = df_events[df_events['session_id'] == session_id]\n",
    "    has_start = '$session_start' in session_data['event_key'].values\n",
    "    has_end = '$session_end' in session_data['event_key'].values\n",
    "    \n",
    "    if has_start and has_end and len(session_data) >= 5:  # 최소 5개 이벤트\n",
    "        normal_session_ids.append(session_id)\n",
    "\n",
    "print(f\"• 분석 대상 정상 세션: {len(normal_session_ids)}개\")\n",
    "\n",
    "if len(normal_session_ids) >= 50:\n",
    "    journey_patterns = []\n",
    "    \n",
    "    for session_id in normal_session_ids[:50]:\n",
    "        session_data = df_events[df_events['session_id'] == session_id].sort_values('event_datetime')\n",
    "        \n",
    "        # 세션 시작 후 실제 첫 행동들\n",
    "        events = session_data['event_key'].tolist()\n",
    "        \n",
    "        # $session_start 제외하고 실제 사용자 행동만\n",
    "        user_actions = [e for e in events if not e.startswith('$')]\n",
    "        \n",
    "        if len(user_actions) >= 3:\n",
    "            first_actions = ' → '.join(user_actions[:3])\n",
    "            journey_patterns.append(first_actions)\n",
    "    \n",
    "    if journey_patterns:\n",
    "        common_journeys = pd.Series(journey_patterns).value_counts().head(10)\n",
    "        \n",
    "        print(f\"\\n🔝 실제 사용자 행동 패턴 (시스템 이벤트 제외):\")\n",
    "        for i, (pattern, count) in enumerate(common_journeys.items(), 1):\n",
    "            pct = count / len(journey_patterns) * 100\n",
    "            print(f\"{i:2d}. {pattern}\")\n",
    "            print(f\"    ({count}회, {pct:.1f}%)\")\n",
    "\n",
    "# 기능별 이용 패턴\n",
    "print(f\"\\n📊 주요 기능 이용 순서:\")\n",
    "main_functions = ['launch_app', 'view_timeline_tap', 'view_lab_tap', \n",
    "                 'click_question_open', 'click_bottom_navigation_questions']\n",
    "\n",
    "function_transitions = []\n",
    "for session_id in normal_session_ids[:100]:\n",
    "    session_data = df_events[df_events['session_id'] == session_id].sort_values('event_datetime')\n",
    "    events = session_data['event_key'].tolist()\n",
    "    \n",
    "    # 주요 기능들 간의 전환만 추출\n",
    "    main_events = [e for e in events if e in main_functions]\n",
    "    \n",
    "    for i in range(len(main_events) - 1):\n",
    "        transition = f\"{main_events[i]} → {main_events[i+1]}\"\n",
    "        function_transitions.append(transition)\n",
    "\n",
    "if function_transitions:\n",
    "    top_function_transitions = pd.Series(function_transitions).value_counts().head(10)\n",
    "    \n",
    "    for i, (transition, count) in enumerate(top_function_transitions.items(), 1):\n",
    "        print(f\"{i:2d}. {transition} ({count}회)\")\n",
    "\n",
    "del df_events"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6a7a37c",
   "metadata": {},
   "source": [
    "### 세션 구분 기준 명확히 파악"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "765839c1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🔍 세션 구분 기준 명확히 분석\n",
      "============================================================\n",
      "📊 1. 세션 ID 생성 패턴 분석\n",
      "----------------------------------------\n",
      "세션 ID 샘플:\n",
      " 1. 4OzYh3seq3VKytpSn5pvQkZNQii1\n",
      " 2. 8QXy31PQxbW9qLzq0Y1dhR8Ypm52\n",
      " 3. 6bcea65d-9f40-46fc-888c-700fe707483f\n",
      " 4. XVYNT6zfhFWqIg9omwg2AHDjTLx2\n",
      " 5. XFB2SPiGfjbVhvJ3Q3DBsaT3m2B3\n",
      " 6. LztzUUFoRxdqTSPgQrX3MAAyNkM2\n",
      " 7. d2b3ca43-4716-4852-b0e2-334848eb66f4\n",
      " 8. 414540BA-1980-4371-BF37-5BFA71158C4D\n",
      " 9. AOMLgbQlhNUGnyvbsrdtbnUcOOc2\n",
      "10. 94860349-d46f-4e98-8505-e96877376cee\n",
      "\n",
      "세션 ID 길이 분포:\n",
      "• 28자리: 7,558,915개\n",
      "• 36자리: 3,882,404개\n",
      "\n",
      "📊 2. 세션 시작/종료 이벤트 상세 분석\n",
      "----------------------------------------\n",
      "세션 내 시작 이벤트 개수:\n",
      "• 1개: 44세션\n",
      "• 2개: 142세션\n",
      "• 3개: 142세션\n",
      "• 4개: 89세션\n",
      "• 5개: 59세션\n",
      "• 6개: 47세션\n",
      "• 7개: 47세션\n",
      "• 8개: 29세션\n",
      "• 9개: 34세션\n",
      "• 10개: 28세션\n",
      "• 11개: 13세션\n",
      "• 12개: 8세션\n",
      "• 13개: 13세션\n",
      "• 14개: 21세션\n",
      "• 15개: 13세션\n",
      "• 16개: 10세션\n",
      "• 17개: 6세션\n",
      "• 18개: 4세션\n",
      "• 19개: 5세션\n",
      "• 20개: 6세션\n",
      "• 21개: 8세션\n",
      "• 22개: 4세션\n",
      "• 23개: 7세션\n",
      "• 24개: 8세션\n",
      "• 25개: 11세션\n",
      "• 26개: 4세션\n",
      "• 27개: 5세션\n",
      "• 28개: 4세션\n",
      "• 29개: 6세션\n",
      "• 30개: 3세션\n",
      "• 31개: 5세션\n",
      "• 32개: 5세션\n",
      "• 33개: 7세션\n",
      "• 34개: 4세션\n",
      "• 35개: 4세션\n",
      "• 36개: 4세션\n",
      "• 37개: 5세션\n",
      "• 38개: 6세션\n",
      "• 39개: 4세션\n",
      "• 40개: 3세션\n",
      "• 41개: 2세션\n",
      "• 42개: 3세션\n",
      "• 43개: 5세션\n",
      "• 44개: 3세션\n",
      "• 45개: 4세션\n",
      "• 46개: 5세션\n",
      "• 47개: 2세션\n",
      "• 48개: 1세션\n",
      "• 49개: 2세션\n",
      "• 50개: 2세션\n",
      "• 52개: 2세션\n",
      "• 53개: 1세션\n",
      "• 54개: 2세션\n",
      "• 55개: 1세션\n",
      "• 57개: 3세션\n",
      "• 58개: 2세션\n",
      "• 59개: 2세션\n",
      "• 60개: 3세션\n",
      "• 61개: 1세션\n",
      "• 62개: 1세션\n",
      "• 63개: 2세션\n",
      "• 64개: 1세션\n",
      "• 65개: 2세션\n",
      "• 66개: 1세션\n",
      "• 67개: 1세션\n",
      "• 68개: 2세션\n",
      "• 69개: 2세션\n",
      "• 70개: 3세션\n",
      "• 72개: 1세션\n",
      "• 73개: 2세션\n",
      "• 74개: 1세션\n",
      "• 75개: 2세션\n",
      "• 76개: 1세션\n",
      "• 77개: 2세션\n",
      "• 79개: 1세션\n",
      "• 82개: 1세션\n",
      "• 83개: 1세션\n",
      "• 85개: 1세션\n",
      "• 86개: 3세션\n",
      "• 87개: 2세션\n",
      "• 88개: 3세션\n",
      "• 89개: 1세션\n",
      "• 92개: 1세션\n",
      "• 94개: 1세션\n",
      "• 95개: 2세션\n",
      "• 98개: 1세션\n",
      "• 101개: 3세션\n",
      "• 104개: 1세션\n",
      "• 105개: 1세션\n",
      "• 106개: 1세션\n",
      "• 110개: 1세션\n",
      "• 113개: 1세션\n",
      "• 116개: 2세션\n",
      "• 117개: 2세션\n",
      "• 121개: 1세션\n",
      "• 124개: 1세션\n",
      "• 125개: 1세션\n",
      "• 126개: 1세션\n",
      "• 127개: 1세션\n",
      "• 130개: 1세션\n",
      "• 131개: 2세션\n",
      "• 133개: 1세션\n",
      "• 134개: 1세션\n",
      "• 138개: 1세션\n",
      "• 141개: 1세션\n",
      "• 143개: 1세션\n",
      "• 145개: 1세션\n",
      "• 150개: 1세션\n",
      "• 151개: 1세션\n",
      "• 153개: 1세션\n",
      "• 154개: 1세션\n",
      "• 157개: 1세션\n",
      "• 163개: 1세션\n",
      "• 164개: 1세션\n",
      "• 166개: 1세션\n",
      "• 170개: 1세션\n",
      "• 173개: 1세션\n",
      "• 178개: 1세션\n",
      "• 184개: 1세션\n",
      "• 202개: 1세션\n",
      "• 205개: 1세션\n",
      "• 210개: 1세션\n",
      "• 223개: 1세션\n",
      "• 227개: 1세션\n",
      "• 271개: 1세션\n",
      "• 284개: 1세션\n",
      "\n",
      "세션 내 종료 이벤트 개수:\n",
      "• 0개: 71세션\n",
      "• 1개: 216세션\n",
      "• 2개: 135세션\n",
      "• 3개: 71세션\n",
      "• 4개: 55세션\n",
      "• 5개: 47세션\n",
      "• 6개: 27세션\n",
      "• 7개: 31세션\n",
      "• 8개: 19세션\n",
      "• 9개: 14세션\n",
      "• 10개: 8세션\n",
      "• 11개: 18세션\n",
      "• 12개: 15세션\n",
      "• 13개: 8세션\n",
      "• 14개: 9세션\n",
      "• 15개: 5세션\n",
      "• 16개: 5세션\n",
      "• 17개: 7세션\n",
      "• 18개: 6세션\n",
      "• 19개: 5세션\n",
      "• 20개: 9세션\n",
      "• 21개: 5세션\n",
      "• 22개: 8세션\n",
      "• 23개: 9세션\n",
      "• 24개: 3세션\n",
      "• 25개: 4세션\n",
      "• 26개: 5세션\n",
      "• 27개: 4세션\n",
      "• 28개: 7세션\n",
      "• 29개: 5세션\n",
      "• 30개: 4세션\n",
      "• 31개: 4세션\n",
      "• 32개: 5세션\n",
      "• 33개: 4세션\n",
      "• 34개: 1세션\n",
      "• 35개: 8세션\n",
      "• 36개: 4세션\n",
      "• 37개: 5세션\n",
      "• 38개: 3세션\n",
      "• 39개: 2세션\n",
      "• 40개: 6세션\n",
      "• 41개: 3세션\n",
      "• 42개: 3세션\n",
      "• 43개: 2세션\n",
      "• 44개: 2세션\n",
      "• 45개: 5세션\n",
      "• 46개: 1세션\n",
      "• 47개: 1세션\n",
      "• 48개: 2세션\n",
      "• 49개: 2세션\n",
      "• 51개: 1세션\n",
      "• 52개: 1세션\n",
      "• 53개: 2세션\n",
      "• 54개: 2세션\n",
      "• 55개: 2세션\n",
      "• 56개: 1세션\n",
      "• 57개: 2세션\n",
      "• 58개: 3세션\n",
      "• 59개: 1세션\n",
      "• 60개: 3세션\n",
      "• 61개: 1세션\n",
      "• 62개: 1세션\n",
      "• 63개: 1세션\n",
      "• 65개: 2세션\n",
      "• 66개: 4세션\n",
      "• 68개: 3세션\n",
      "• 70개: 1세션\n",
      "• 71개: 1세션\n",
      "• 72개: 4세션\n",
      "• 74개: 2세션\n",
      "• 75개: 1세션\n",
      "• 78개: 1세션\n",
      "• 81개: 2세션\n",
      "• 82개: 1세션\n",
      "• 84개: 3세션\n",
      "• 86개: 3세션\n",
      "• 87개: 2세션\n",
      "• 88개: 1세션\n",
      "• 90개: 1세션\n",
      "• 92개: 1세션\n",
      "• 94개: 2세션\n",
      "• 95개: 1세션\n",
      "• 98개: 1세션\n",
      "• 99개: 2세션\n",
      "• 104개: 3세션\n",
      "• 109개: 1세션\n",
      "• 111개: 1세션\n",
      "• 113개: 1세션\n",
      "• 115개: 2세션\n",
      "• 116개: 1세션\n",
      "• 120개: 1세션\n",
      "• 123개: 2세션\n",
      "• 124개: 1세션\n",
      "• 127개: 1세션\n",
      "• 129개: 3세션\n",
      "• 132개: 1세션\n",
      "• 133개: 1세션\n",
      "• 137개: 1세션\n",
      "• 140개: 1세션\n",
      "• 142개: 1세션\n",
      "• 144개: 1세션\n",
      "• 149개: 1세션\n",
      "• 151개: 2세션\n",
      "• 153개: 1세션\n",
      "• 156개: 1세션\n",
      "• 162개: 1세션\n",
      "• 163개: 1세션\n",
      "• 166개: 1세션\n",
      "• 170개: 1세션\n",
      "• 173개: 1세션\n",
      "• 178개: 1세션\n",
      "• 184개: 1세션\n",
      "• 202개: 1세션\n",
      "• 204개: 1세션\n",
      "• 209개: 1세션\n",
      "• 224개: 1세션\n",
      "• 227개: 1세션\n",
      "• 270개: 1세션\n",
      "• 285개: 1세션\n",
      "\n",
      "📊 3. 세션 간 시간 간격 분석\n",
      "----------------------------------------\n",
      "동일 사용자 연속 세션 간 시간 간격:\n",
      "• 평균: 373.6분\n",
      "• 중간값: 151.0분\n",
      "• 최소: 0.1분\n",
      "• 25분위: 23.6분\n",
      "• 75분위: 535.7분\n",
      "\n",
      "세션 간격 분포:\n",
      "• 3시간 이상: 36개 (41.4%)\n",
      "• 1-3시간: 20개 (23.0%)\n",
      "• 5-15분: 10개 (11.5%)\n",
      "• 15-30분: 10개 (11.5%)\n",
      "• 30-60분: 6개 (6.9%)\n",
      "• 1-5분: 3개 (3.4%)\n",
      "• 1분 미만: 2개 (2.3%)\n",
      "\n",
      "📊 4. launch_app과 세션 시작의 관계\n",
      "----------------------------------------\n",
      "launch_app과 $session_start 순서:\n",
      "• 거의 동시: 189개 (100.0%)\n",
      "\n",
      "============================================================\n",
      "🎯 세션 구분 기준 결론\n",
      "============================================================\n"
     ]
    }
   ],
   "source": [
    "print(\"🔍 세션 구분 기준 명확히 분석\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# 세션 패턴 상세 분석\n",
    "df_events = pd.read_parquet(\n",
    "    \"gs://sprintda05_final_project/hackle/hackle_events.parquet\",\n",
    "    columns=['session_id', 'event_datetime', 'event_key']\n",
    ")\n",
    "\n",
    "df_events['event_datetime'] = pd.to_datetime(df_events['event_datetime'])\n",
    "\n",
    "print(\"📊 1. 세션 ID 생성 패턴 분석\")\n",
    "print(\"-\" * 40)\n",
    "\n",
    "# 세션 ID 샘플 확인\n",
    "sample_session_ids = df_events['session_id'].unique()[:10]\n",
    "print(\"세션 ID 샘플:\")\n",
    "for i, session_id in enumerate(sample_session_ids, 1):\n",
    "    print(f\"{i:2d}. {session_id}\")\n",
    "\n",
    "# 세션 ID 길이와 패턴\n",
    "session_id_lengths = df_events['session_id'].astype(str).str.len().value_counts()\n",
    "print(f\"\\n세션 ID 길이 분포:\")\n",
    "for length, count in session_id_lengths.head().items():\n",
    "    print(f\"• {length}자리: {count:,}개\")\n",
    "\n",
    "print(f\"\\n📊 2. 세션 시작/종료 이벤트 상세 분석\")\n",
    "print(\"-\" * 40)\n",
    "\n",
    "# 동일 세션 내 시작/종료 이벤트 개수\n",
    "session_start_end_counts = []\n",
    "sample_sessions = df_events['session_id'].unique()[:1000]\n",
    "\n",
    "for session_id in sample_sessions:\n",
    "    session_data = df_events[df_events['session_id'] == session_id]\n",
    "    \n",
    "    start_count = (session_data['event_key'] == '$session_start').sum()\n",
    "    end_count = (session_data['event_key'] == '$session_end').sum()\n",
    "    total_events = len(session_data)\n",
    "    \n",
    "    session_start_end_counts.append({\n",
    "        'session_id': session_id,\n",
    "        'start_count': start_count,\n",
    "        'end_count': end_count,\n",
    "        'total_events': total_events\n",
    "    })\n",
    "\n",
    "counts_df = pd.DataFrame(session_start_end_counts)\n",
    "\n",
    "print(\"세션 내 시작 이벤트 개수:\")\n",
    "start_dist = counts_df['start_count'].value_counts().sort_index()\n",
    "for count, sessions in start_dist.items():\n",
    "    print(f\"• {count}개: {sessions}세션\")\n",
    "\n",
    "print(f\"\\n세션 내 종료 이벤트 개수:\")\n",
    "end_dist = counts_df['end_count'].value_counts().sort_index()\n",
    "for count, sessions in end_dist.items():\n",
    "    print(f\"• {count}개: {sessions}세션\")\n",
    "\n",
    "print(f\"\\n📊 3. 세션 간 시간 간격 분석\")\n",
    "print(\"-\" * 40)\n",
    "\n",
    "# 동일 사용자의 연속 세션 간 시간 간격 분석 (hackle_properties 필요)\n",
    "try:\n",
    "    df_properties = pd.read_parquet(\n",
    "        \"gs://sprintda05_final_project/hackle/hackle_properties.parquet\",\n",
    "        columns=['session_id', 'user_id']\n",
    "    )\n",
    "    \n",
    "    # 세션과 사용자 매핑\n",
    "    session_user_map = df_properties.set_index('session_id')['user_id'].to_dict()\n",
    "    \n",
    "    # 사용자별 세션 시간 분석\n",
    "    user_sessions = {}\n",
    "    for session_id in sample_sessions[:500]:\n",
    "        if session_id in session_user_map:\n",
    "            user_id = session_user_map[session_id]\n",
    "            session_data = df_events[df_events['session_id'] == session_id]\n",
    "            \n",
    "            if len(session_data) > 0:\n",
    "                session_start_time = session_data['event_datetime'].min()\n",
    "                \n",
    "                if user_id not in user_sessions:\n",
    "                    user_sessions[user_id] = []\n",
    "                user_sessions[user_id].append({\n",
    "                    'session_id': session_id,\n",
    "                    'start_time': session_start_time\n",
    "                })\n",
    "    \n",
    "    # 동일 사용자의 연속 세션 간격\n",
    "    session_gaps = []\n",
    "    for user_id, sessions in user_sessions.items():\n",
    "        if len(sessions) >= 2:\n",
    "            # 시간순 정렬\n",
    "            sessions_sorted = sorted(sessions, key=lambda x: x['start_time'])\n",
    "            \n",
    "            for i in range(len(sessions_sorted) - 1):\n",
    "                current_session = sessions_sorted[i]\n",
    "                next_session = sessions_sorted[i + 1]\n",
    "                \n",
    "                gap_minutes = (next_session['start_time'] - current_session['start_time']).total_seconds() / 60\n",
    "                session_gaps.append(gap_minutes)\n",
    "    \n",
    "    if session_gaps:\n",
    "        gaps_series = pd.Series(session_gaps)\n",
    "        print(f\"동일 사용자 연속 세션 간 시간 간격:\")\n",
    "        print(f\"• 평균: {gaps_series.mean():.1f}분\")\n",
    "        print(f\"• 중간값: {gaps_series.median():.1f}분\")\n",
    "        print(f\"• 최소: {gaps_series.min():.1f}분\")\n",
    "        print(f\"• 25분위: {gaps_series.quantile(0.25):.1f}분\")\n",
    "        print(f\"• 75분위: {gaps_series.quantile(0.75):.1f}분\")\n",
    "        \n",
    "        # 간격 분포\n",
    "        gap_ranges = pd.cut(gaps_series, \n",
    "                           bins=[0, 1, 5, 15, 30, 60, 180, float('inf')],\n",
    "                           labels=['1분 미만', '1-5분', '5-15분', '15-30분', '30-60분', '1-3시간', '3시간 이상'])\n",
    "        \n",
    "        print(f\"\\n세션 간격 분포:\")\n",
    "        for range_name, count in gap_ranges.value_counts().items():\n",
    "            pct = count / len(session_gaps) * 100\n",
    "            print(f\"• {range_name}: {count}개 ({pct:.1f}%)\")\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"❌ 사용자별 세션 분석 실패: {str(e)[:50]}...\")\n",
    "\n",
    "print(f\"\\n📊 4. launch_app과 세션 시작의 관계\")\n",
    "print(\"-\" * 40)\n",
    "\n",
    "# launch_app과 $session_start의 시간 관계\n",
    "launch_session_patterns = []\n",
    "\n",
    "for session_id in sample_sessions[:200]:\n",
    "    session_data = df_events[df_events['session_id'] == session_id].sort_values('event_datetime')\n",
    "    \n",
    "    launch_events = session_data[session_data['event_key'] == 'launch_app']\n",
    "    start_events = session_data[session_data['event_key'] == '$session_start']\n",
    "    \n",
    "    if len(launch_events) > 0 and len(start_events) > 0:\n",
    "        first_launch = launch_events['event_datetime'].min()\n",
    "        first_start = start_events['event_datetime'].min()\n",
    "        \n",
    "        time_diff = (first_start - first_launch).total_seconds()\n",
    "        \n",
    "        if -300 <= time_diff <= 300:  # 5분 이내\n",
    "            if time_diff < -1:\n",
    "                pattern = \"session_start가 먼저\"\n",
    "            elif time_diff > 1:\n",
    "                pattern = \"launch_app이 먼저\"\n",
    "            else:\n",
    "                pattern = \"거의 동시\"\n",
    "            \n",
    "            launch_session_patterns.append(pattern)\n",
    "\n",
    "if launch_session_patterns:\n",
    "    pattern_counts = pd.Series(launch_session_patterns).value_counts()\n",
    "    print(\"launch_app과 $session_start 순서:\")\n",
    "    for pattern, count in pattern_counts.items():\n",
    "        pct = count / len(launch_session_patterns) * 100\n",
    "        print(f\"• {pattern}: {count}개 ({pct:.1f}%)\")\n",
    "\n",
    "print(f\"\\n\" + \"=\" * 60)\n",
    "print(\"🎯 세션 구분 기준 결론\")\n",
    "print(\"=\" * 60)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
